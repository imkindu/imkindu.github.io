<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[MongileFS分布式文件存储系统]]></title>
    <url>%2F2017%2F11%2F11%2Flinux%2FMogileFS%2F</url>
    <content type="text"><![CDATA[MogileFS是一个开源的分布式文件存储系统，由LiveJournal旗下的Danga Interactive公司开发。Danga团队开发了包括 Memcached、MogileFS、Perlbal 等多个知名的开源项目。目前使用MogileFS 的公司非常多，如日本排名先前的几个互联公司及国内的yupoo(又拍)、digg、豆瓣、1号店、大众点评、搜狗和安居客等，分别为所在的组织或公司管理着海量的图片。 MogileFS由3个部分组成：(1)server：主要包括mogilefsd和mogstored两个应用程序。mogilefsd实现的是tracker，它通过数据库来保存元数据信息，包括站点domain、class、host等；mogstored是存储节点(store node)，它其实是个WebDAV服务，默认监听在7500端口，接受客户端的文件存储请求。在MogileFS安装完后，要运行mogadm工具将所有的store node注册到mogilefsd的数据库里，mogilefsd会对这些节点进行管理和监控。(2) utils（工具集）：主要是MogileFS的一些管理工具，例如mogadm等。(3)客户端API：MogileFS的客户端API很多，例如Perl、PHP、Java、Python等，用这个模块可以编写客户端程序，实现文件的备份管理功能等。 初始化数据库 mogdbsetup –help tracker节点 修改配置文件 vim /etc/mogilefs/mogilefsd.conf]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>MongileFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql日志]]></title>
    <url>%2F2017%2F11%2F10%2Fmysql%2Fmysql%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[mysql日志 日志 查询日志：general_log 慢查询日志：log_show_queries 错误日志：log_error，log_warings 二进制日志：binlog 中继日志：relay_log 事务日志：innodb_log 1、日志查询 记录查询语句，日志存储位置 文件：file 表：table（mysql.general_log） general_log=(on|off) general_log_file=HOSTNAME.log log_output={FILE|TABLE|NONE} # 查询日志查询记录是否开启 MariaDB [(none)]&gt; show global variables like &apos;general%&apos;; +------------------+--------------+ | Variable_name | Value | +------------------+--------------+ | general_log | OFF | | general_log_file | centos20.log | +------------------+--------------+ 2 rows in set (0.00 sec) # 开启日志查询记录 MariaDB [(none)]&gt; set @@global.general_log=on; 2、慢查询日志 慢查询：运行时间超出指定时长的查询 long_query_time 存储位置 文件：FILE 表：TABLE，mysql.slow_log log_slow_queries={ON|OFF} slow_query_log={ON|OFF} slow_query_log_file= log_output={FILE|TABLE|NONE} log_slow_filter= # 慢查询过滤器 admin,filesort,filesort_on_disk,full_join,full_scan,query_cache,query_cache_miss,tmp_table,tmp_table_on_disk log_slow_rate_limit log_slow_verbosity MariaDB [(none)]&gt; show global variables like &apos;%slow%&apos;\G *************************** 1. row *************************** Variable_name: log_slow_filter Value: admin,filesort,filesort_on_disk,full_join,full_scan,query_cache,query_cache_miss,tmp_table,tmp_table_on_disk *************************** 2. row *************************** Variable_name: log_slow_queries Value: OFF *************************** 3. row *************************** Variable_name: log_slow_rate_limit Value: 1 *************************** 4. row *************************** Variable_name: log_slow_verbosity Value: *************************** 5. row *************************** Variable_name: slow_launch_time Value: 2 *************************** 6. row *************************** Variable_name: slow_query_log Value: OFF *************************** 7. row *************************** Variable_name: slow_query_log_file Value: centos20-slow.log 7 rows in set (0.00 sec) a) 查询慢查询时间定义 MariaDB [(none)]&gt; show global variables like &apos;long_query_time&apos;\G *************************** 1. row *************************** Variable_name: long_query_time Value: 10.000000 1 row in set (0.00 sec) b) 3、错误日志 记录如下几类信息： (1) mysqld启动和关闭过程中输出的信息； (2) mysqld运行中产生的错误信息； (3) event scheduler运行时产生的信息； (4) 主从复制架构中，从服务器复制线程启动时产生的日志； log_error= /var/log/mariadb/mariadb.log|OFF log_warnings={ON|OFF} 4、二进制日志 用于记录引起数据改变或存在引起数据改变的潜在可能性的语句（STATEMENT）或改变后的结果（ROW），也可能是二者混合； 功用：“重放”]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git commit规范]]></title>
    <url>%2F2017%2F11%2F09%2Fgit%2Fgit%20commit%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[以前公司使用SVN和自己使用git提交写注释时，都是随手瞎写的，主要是备注给自己看的，但是接触到linux command这种命令行格式之后，觉得太low，也不太方便查看和查找。 commit message好处 可读性好，清晰，不必深入看代码即可了解当前commit的作用。 为 Code Reviewing做准备 方便跟踪工程历史 让其他的开发者在运行 git blame 的时候想跪谢 提高项目的整体质量，提高个人工程素质 commit message格式 每次提交，Commit message 都包括三个部分：header，body 和 footer。 12345&lt;type&gt;(&lt;scope&gt;) : &lt;subject&gt;&lt;BLANK LINE&gt;&lt;body&gt;&lt;BLANK LINE&gt;&lt;footer&gt; 其中，header 是必需的，body 和 footer 可以省略。不管是哪一个部分，任何一行都不得超过72个字符（或100个字符）。这是为了避免自动换行影响美观。 Header Header部分只有一行，包括三个字段：type（必需）、scope（可选）和subject（必需）。 type 用于说明 commit 的类别，只允许使用下面7个标识。 feat：新功能（feature） fix：修补bug docs：文档（documentation） style： 格式（不影响代码运行的变动） refactor：重构（即不是新增功能，也不是修改bug的代码变动） test：增加测试 chore：构建过程或辅助工具的变动 如果type为feat和fix，则该 commit 将肯定出现在 Change log 之中。其他情况（docs、chore、style、refactor、test）由你决定，要不要放入 Change log，建议是不要。 scope scope用于说明 commit 影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同。 例如在Angular，可以是$location, $browser, $compile, $rootScope, ngHref, ngClick, ngView等。 如果你的修改影响了不止一个scope，你可以使用*代替。 subject subject是 commit 目的的简短描述，不超过50个字符。 其他注意事项： 以动词开头，使用第一人称现在时，比如change，而不是changed或changes第一个字母小写结尾不加句号（.） git log查看12345[imkindu@ubuntu dev01]$ git commit dev01.txt -m "feat text : dev02二次提交简短描述修改内容" 12345678910[imkindu@ubuntu dev01]$ git logcommit efbe85c6c49859f2d1b6615880c3b341f828271dAuthor: imkindu &lt;imkindu@163.com&gt;Date: Thu Nov 9 18:24:16 2017 +0800 feat text : dev02二次提交 简短描述 修改内容 git log搜索12345678910[imkindu@ubuntu dev01]$ git log dev01-02 --grep featcommit efbe85c6c49859f2d1b6615880c3b341f828271dAuthor: imkindu &lt;imkindu@163.com&gt;Date: Thu Nov 9 18:24:16 2017 +0800 feat text : dev02二次提交 简短描述 修改内容]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git常用命令]]></title>
    <url>%2F2017%2F11%2F09%2Fgit%2Fgit%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[经常会使用git，但是原先开发时经常使用的是客户端管理工具，没有使用命令，导致对git的工作模式不是很了解，特整理下以备查询。 Workspace：工作区 Index / Stage：暂存区 Repository：仓库区（或本地仓库） Remote ：远程仓库 查看帮助1234567891011121314151617181920212223242526272829303132333435363738394041用法：git [--version] [--help] [-C &lt;path&gt;] [-c name=value] [--exec-path[=&lt;path&gt;]] [--html-path] [--man-path] [--info-path] [-p | --paginate | --no-pager] [--no-replace-objects] [--bare] [--git-dir=&lt;path&gt;] [--work-tree=&lt;path&gt;] [--namespace=&lt;name&gt;] &lt;command&gt; [&lt;args&gt;]这些是各种场合常见的 Git 命令：开始一个工作区（参见：git help tutorial） clone 克隆一个仓库到一个新目录 init 创建一个空的 Git 仓库或重新初始化一个已存在的仓库在当前变更上工作（参见：git help everyday） add 添加文件内容至索引 mv 移动或重命名一个文件、目录或符号链接 reset 重置当前 HEAD 到指定状态 rm 从工作区和索引中删除文件检查历史和状态（参见：git help revisions） bisect 通过二分查找定位引入 bug 的提交 grep 输出和模式匹配的行 log 显示提交日志 show 显示各种类型的对象 status 显示工作区状态扩展、标记和调校您的历史记录 branch 列出、创建或删除分支 checkout 切换分支或恢复工作区文件 commit 记录变更到仓库 diff 显示提交之间、提交和工作区之间等的差异 merge 合并两个或更多开发历史 rebase 本地提交转移至更新后的上游分支中 tag 创建、列出、删除或校验一个 GPG 签名的标签对象协同（参见：git help workflows） fetch 从另外一个仓库下载对象和引用 pull 获取并整合另外的仓库或一个本地分支 push 更新远程引用和相关的对象命令 &apos;git help -a&apos; 和 &apos;git help -g&apos; 显示可用的子命令和一些概念帮助。查看 &apos;git help &lt;命令&gt;&apos; 或 &apos;git help &lt;概念&gt;&apos; 以获取给定子命令或概念的帮助。 新建仓库1234567891011# 在当前目录新建一个Git代码库$ git init# 新建裸仓库，--bare 只放记录，不放数据$ git init --bare [project-name]# 新建一个目录，将其初始化为Git代码库$ git init [project-name]# 下载一个项目和它的整个代码历史$ git clone [url] 配置 Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。 123456789# 显示当前的Git配置$ git config --list# 编辑Git配置文件$ git config -e [--global]# 设置提交代码时的用户信息$ git config [--global] user.name "[name]"$ git config [--global] user.email "[email address]" 增加、删除文件123456789101112131415161718192021# 添加指定文件到暂存区$ git add [file1] [file2] ...# 添加指定目录到暂存区，包括子目录$ git add [dir]# 添加当前目录的所有文件到暂存区$ git add .# 添加每个变化前，都会要求确认# 对于同一个文件的多处变化，可以实现分次提交$ git add -p# 删除工作区文件，并且将这次删除放入暂存区$ git rm [file1] [file2] ...# 停止追踪指定文件，但该文件会保留在工作区$ git rm --cached [file]# 改名文件，并且将这个改名放入暂存区$ git mv [file-original] [file-renamed] 代码提交123456789101112131415161718# 提交暂存区到仓库区$ git commit -m [message]# 提交暂存区的指定文件到仓库区$ git commit [file1] [file2] ... -m [message]# 提交工作区自上次commit之后的变化，直接到仓库区$ git commit -a# 提交时显示所有diff信息$ git commit -v# 使用一次新的commit，替代上一次提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message]# 重做上一次commit，并包括指定文件的新变化$ git commit --amend [file1] [file2] ... 分支123456789101112131415161718192021222324252627282930313233343536373839404142# 列出所有本地分支$ git branch# 列出所有远程分支$ git branch -r# 列出所有本地分支和远程分支$ git branch -a# 新建一个分支，但依然停留在当前分支$ git branch [branch-name]# 新建一个分支，并切换到该分支$ git checkout -b [branch]# 新建一个分支，指向指定commit$ git branch [branch] [commit]# 新建一个分支，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区$ git checkout [branch-name]# 切换到上一个分支$ git checkout -# 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支$ git merge [branch]# 选择一个commit，合并进当前分支$ git cherry-pick [commit]# 删除分支$ git branch -d [branch-name]# 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote/branch] 标签1234567891011121314151617181920212223242526# 列出所有tag$ git tag# 新建一个tag在当前commit$ git tag [tag]# 新建一个tag在指定commit$ git tag [tag] [commit]# 删除本地tag$ git tag -d [tag]# 删除远程tag$ git push origin :refs/tags/[tagName]# 查看tag信息$ git show [tag]# 提交指定tag$ git push [remote] [tag]# 提交所有tag$ git push [remote] --tags# 新建一个分支，指向某个tag$ git checkout -b [branch] [tag] 查看信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# 显示有变更的文件$ git status# 显示当前分支的版本历史$ git log# 显示commit历史，以及每次commit发生变更的文件$ git log --stat# 搜索提交历史，根据关键词$ git log -S [keyword]# 显示某个commit之后的所有变动，每个commit占据一行$ git log [tag] HEAD --pretty=format:%s# 显示某个commit之后的所有变动，其"提交说明"必须符合搜索条件$ git log [tag] HEAD --grep feature# 显示某个文件的版本历史，包括文件改名$ git log --follow [file]$ git whatchanged [file]# 显示指定文件相关的每一次diff$ git log -p [file]# 显示过去5次提交$ git log -5 --pretty --oneline# 显示所有提交过的用户，按提交次数排序$ git shortlog -sn# 显示指定文件是什么人在什么时间修改过$ git blame [file]# 显示暂存区和工作区的差异$ git diff# 显示暂存区和上一个commit的差异$ git diff --cached [file]# 显示工作区与当前分支最新commit之间的差异$ git diff HEAD# 显示两次提交之间的差异$ git diff [first-branch]...[second-branch]# 显示今天你写了多少行代码$ git diff --shortstat "@&#123;0 day ago&#125;"# 显示某次提交的元数据和内容变化$ git show [commit]# 显示某次提交发生变化的文件$ git show --name-only [commit]# 显示某次提交时，某个文件的内容$ git show [commit]:[filename]# 显示当前分支的最近几次提交$ git reflog 远程同步1234567891011121314151617181920212223# 下载远程仓库的所有变动$ git fetch [remote]# 显示所有远程仓库$ git remote -v# 显示某个远程仓库的信息$ git remote show [remote]# 增加一个新的远程仓库，并命名$ git remote add [shortname] [url]# 取回远程仓库的变化，并与本地分支合并$ git pull [remote] [branch]# 上传本地指定分支到远程仓库$ git push [remote] [branch]# 强行推送当前分支到远程仓库，即使有冲突$ git push [remote] --force# 推送所有分支到远程仓库$ git push [remote] --all 撤销12345678910111213141516171819202122232425262728293031# 恢复暂存区的指定文件到工作区$ git checkout [file]# 恢复某个commit的指定文件到暂存区和工作区$ git checkout [commit] [file]# 恢复暂存区的所有文件到工作区$ git checkout .# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变$ git reset [file]# 重置暂存区与工作区，与上一次commit保持一致$ git reset --hard# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变$ git reset [commit]# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致$ git reset --hard [commit]# 重置当前HEAD为指定commit，但保持暂存区和工作区不变$ git reset --keep [commit]# 新建一个commit，用来撤销指定commit# 后者的所有变化都将被前者抵消，并且应用到当前分支$ git revert [commit]# 暂时将未提交的变化移除，稍后再移入$ git stash$ git stash pop 其他12# 生成一个可供发布的压缩包$ git archive]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库 垂直拆分和水平拆分]]></title>
    <url>%2F2017%2F11%2F08%2Fmysql%2F%E5%9E%82%E7%9B%B4%E6%8B%86%E5%88%86%E5%92%8C%E6%B0%B4%E5%B9%B3%E6%8B%86%E5%88%86%2F</url>
    <content type="text"><![CDATA[当我们使用读写分离、缓存后，数据库的压力还是很大的时候，这就需要使用到数据库拆分了。 数据库拆分简单来说，就是指通过某种特定的条件，按照某个维度，将我们存放在同一个数据库中的数据分散存放到多个数据库（主机）上面以达到分散单库（主机）负载的效果。 切分模式： 垂直（纵向）拆分、水平拆分。 垂直拆分 垂直(纵向)拆分：是指按功能模块拆分，比如分为订单库、商品库、用户库…这种方式多个数据库之间的表结构不同。 优点： 拆分后业务清晰，拆分规则明确。 系统之间整合或扩展容易。 数据维护简单。 缺点： 部分业务表无法join，只能通过接口方式解决，提高了系统复杂度。 受每种业务不同的限制存在单库性能瓶颈，不易数据扩展跟性能提高。 事务处理复杂。 水平拆分 垂直拆分后遇到单机瓶颈，可以使用水平拆分。相对于垂直拆分的区别是：垂直拆分是把不同的表拆到不同的数据库中，而水平拆分是把同一个表拆到不同的数据库中。 相对于垂直拆分，水平拆分不是将表的数据做分类，而是按照某个字段的某种规则来分散到多个库之中，每个表中包含一部分数据。简单来说，我们可以将数据的水平切分理解为是按照数据行的切分，就是将表中 的某些行切分到一个数据库，而另外的某些行又切分到其他的数据库中，主要有分表，分库两种模式，如图： 优点： 不存在单库大数据，高并发的性能瓶颈。 对应用透明，应用端改造较少。 按照合理拆分规则拆分，join操作基本避免跨库。 提高了系统的稳定性跟负载能力。 缺点： 拆分规则难以抽象。 分片事务一致性难以解决。 数据多次扩展难度跟维护量极大。 跨库join性能较差。 拆分原则 尽量不拆分，架构是进化而来，不是一蹴而就。(SOA) 最大可能的找到最合适的切分维度。 由于数据库中间件对数据Join 实现的优劣难以把握，而且实现高性能难度极大，业务读取 尽量少使用多表Join -尽量通过数据冗余，分组避免数据垮库多表join。 尽量避免分布式事务。 单表拆分到数据1000万以内。 切分方案 范围、枚举、时间、取模、哈希、指定等]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>垂直拆分</tag>
        <tag>水平拆分</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat redis-session-manager]]></title>
    <url>%2F2017%2F11%2F07%2Fjava%2Ftomcat-redis-session-manager%2F</url>
    <content type="text"><![CDATA[分布式web server集群部署后需要实现session共享，针对 tomcat 服务器的实现方案多种多样，比如 tomcat cluster session 广播、nginx IP hash策略、nginx sticky module等方案，本文主要介绍了使用 redis 服务器进行 session 统一存储管理的共享方案。 github提供了多个版本的redis-sessiom-manager版本，大致思路都一致，需要特别注意版本区别和配置文件编写。 https://github.com/search?utf8=%E2%9C%93&amp;q=tomcat-redis-session-manager&amp;type= 架构图 jar依赖包添加redis session集群依赖的jar包到 TOMCAT_BASE/lib 目录下 tomcat-redis-session-manager-${VERSION}.jar jedis-2.5.2.jar commons-pool2-2.2.jar jar包下载 : https://pan.baidu.com/s/1bokMOVH 将下载jar类库包放入tomcat/lib/ 配置context.xml12345678910111213 &lt;!-- host="192.168.159.129" Redis地址 --&gt;&lt;!-- port="6379" Redis端口 --&gt;&lt;!-- password="123456" Redis密码 --&gt;&lt;!-- database="0" 存储Session的Redis库编号 --&gt;&lt;!-- maxInactiveInterval="60" Session失效的间隔（秒） --&gt;&lt;Valve className="com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve" /&gt; &lt;Manager className="com.orangefunction.tomcat.redissessions.RedisSessionManager" host="192.168.159.129" port="6379" password="123456" database="0" maxInactiveInterval="60" /&gt; 属性解释host : redis服务器地址 port : redis服务器的端口号 database : 要使用的redis数据库索引 maxInactiveInterval : session最大空闲超时时间，如果不填则使用tomcat的超时时长，一般tomcat默认为1800 即半个小时 sessionPersistPolicies : session保存策略，除了默认的策略还可以选择的策略有： [SAVE_ON_CHANGE] : 每次 session.setAttribute() 、 session.removeAttribute() 触发都会保存. 注意：此功能无法检测已经存在redis的特定属性的变化， 权衡：这种策略会略微降低会话的性能，任何改变都会保存到redis中. [ALWAYS_SAVE_AFTER_REQUEST]: 每一个request请求后都强制保存，无论是否检测到变化. 注意：对于更改一个已经存储在redis中的会话属性，该选项特别有用. 权衡：如果不是所有的request请求都要求改变会话属性的话不推荐使用，因为会增加并发竞争的情况。 sentinelMaster : redis集群主节点名称（Redis集群是以分片(Sharding)加主从的方式搭建，满足可扩展性的要求） sentinels : redis集群列表配置(类似zookeeper，通过多个Sentinel来提高系统的可用性) connectionPoolMaxTotal connectionPoolMaxIdle jedis最大能够保持idel状态的连接数 connectionPoolMinIdle 与connectionPoolMaxIdle相反 maxWaitMillis jedis池没有对象返回时，最大等待时间 minEvictableIdleTimeMillis softMinEvictableIdleTimeMillis numTestsPerEvictionRun testOnCreate testOnBorrow jedis调用borrowObject方法时，是否进行有效检查 testOnReturn jedis调用returnObject方法时，是否进行有效检查 testWhileIdle timeBetweenEvictionRunsMillis evictionPolicyClassName blockWhenExhausted jmxEnabled jmxNameBase jmxNamePrefix]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
        <tag>java</tag>
        <tag>redis-session-manager</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[memcached简介]]></title>
    <url>%2F2017%2F11%2F06%2Fmemcached%2Fmemcached%2F</url>
    <content type="text"><![CDATA[高效缓存 memcached[root@centos55 ~]# rpm -ql memcached/etc/rc.d/init.d/memcached/etc/sysconfig/memcached/usr/bin/memcached/usr/bin/memcached-tool/usr/share/doc/memcached-1.4.4/usr/share/doc/memcached-1.4.4/AUTHORS/usr/share/doc/memcached-1.4.4/CONTRIBUTORS/usr/share/doc/memcached-1.4.4/COPYING/usr/share/doc/memcached-1.4.4/ChangeLog/usr/share/doc/memcached-1.4.4/NEWS/usr/share/doc/memcached-1.4.4/README/usr/share/doc/memcached-1.4.4/protocol.txt/usr/share/doc/memcached-1.4.4/readme.txt/usr/share/doc/memcached-1.4.4/threads.txt/usr/share/man/man1/memcached.1.gz/var/run/memcached [root@centos55 ~]# memcached -helpmemcached 1.4.4-p TCP port number to listen on (default: 11211)-U UDP port number to listen on (default: 11211, 0 is off)-s UNIX socket path to listen on (disables network support)-a access mask for UNIX socket, in octal (default: 0700)-l interface to listen on (default: INADDR_ANY, all addresses)-d run as a daemon-r maximize core file limit-u assume identity of (only when run as root)-m max memory to use for items in megabytes (default: 64 MB)-M return error on memory exhausted (rather than removing items)-c max simultaneous connections (default: 1024)-k lock down all paged memory. Note that there is a limit on how much memory you may lock. Trying to allocate more than that would fail, so be sure you set the limit correctly for the user you started the daemon with (not for -u user; under sh this is done with ‘ulimit -S -l NUM_KB’).-v verbose (print errors/warnings while in event loop)-vv very verbose (also print client commands/reponses)-vvv extremely verbose (also print internal state transitions)-h print this help and exit-i print memcached and libevent license # 显示许可证-P save PID in , only used with -d option-f chunk size growth factor (default: 1.25)-n minimum space allocated for key+value+flags (default: 48)-L Try to use large memory pages (if available). Increasing the memory page size could reduce the number of TLB misses and improve the performance. In order to get large pages from the OS, memcached will allocate the total item-cache in one large chunk.-D Use as the delimiter between key prefixes and IDs. This is used for per-prefix stats reporting. The default is “:” (colon). If this option is specified, stats collection is turned on automatically; if not, then it may be turned on by sending the “stats detail on” command to the server.-t number of threads to use (default: 4) # 线程数-R Maximum number of requests per event, limits the number of requests process for a given connection to prevent starvation (default: 20)-C Disable use of CAS-b Set the backlog queue limit (default: 1024)-B Binding protocol - one of ascii, binary, or auto (default) # 二进制格式-I Override the size of each slab page. Adjusts max item size (default: 1mb, min: 1k, max: 128m) memcached-toolmemcached-tool [mode] Usage: memcached-tool [mode] memcached-tool 10.0.0.5:11211 display # shows slabs memcached-tool 10.0.0.5:11211 # same. (default is display) memcached-tool 10.0.0.5:11211 stats # shows general stats memcached-tool 10.0.0.5:11211 dump # dumps keys and values MODES display Print slab class statistics. This is the default mode if no mode is specified. The printed columns are: # Number of the slab class. Item_Size The amount of space each chunk uses. One item uses one chunk of the appropriate size. Max_age Age of the oldest item in the LRU. Pages Total number of pages allocated to the slab class. Count Number of items presently stored in this class. Expired items are not automatically excluded. Full? Yes if there are no free chunks at the end of the last allocated page. Evicted Number of times an item had to be evicted from the LRU before it expired. Evict_Time Seconds since the last access for the most recent item evicted from this class. OOM Number of times the underlying slab class was unable to store a new item. stats Print general-purpose statistics of the daemon. Each line contains the name of the statistic and its value. dump Make a partial dump of the cache written in the add statements of the memcached protocol. /usr/share/doc/memcached-1.4.4/protocol.txt 查看命令 memcached session manager]]></content>
      <categories>
        <category>memcached</category>
      </categories>
      <tags>
        <tag>memcached</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat集群]]></title>
    <url>%2F2017%2F11%2F05%2Fjava%2Ftomcat%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[tomcat默认使用普通用户启动，而非管理员，启动端口是8080，在企业中，一般不直接对外提供服务，前端使用apache或者nginx做代理。 环境准备 为做tomcat集群环境，特先准备好两台tomcat服务器和一台apache、nginx服务器 安装solo Solo 是款专业、简约、稳定、极速的 Java 开源博客系统，http://b3log.org/ tomcat-solo虚拟机123&lt;Host name="solo.imkindu.cn" appBase="webapps/solo" unpackWARs="true" autoDeploy="true" &gt; &lt;Context path="/" docBase="ROOT" /&gt;&lt;/Host&gt; latke.properties 配置solo时，需要修改latke.properties对用浏览器使用地址，否则容易出现样式等问题。 1234567#### Server ##### Browser visit protocolserverScheme=http# Browser visit domain nameserverHost=solo.imkindu.cn# Browser visit port, 80 as usual, THIS IS NOT SERVER LISTEN PORT!serverPort=80 local.properties solo默认使用H2数据库，但是个人不是很熟悉，特配置改成存入mariadb 1234567#### MySQL runtime ####runtimeDatabase=MYSQLjdbc.username=rootjdbc.password=rootjdbc.driver=com.mysql.jdbc.Driverjdbc.URL=jdbc:mysql://192.168.56.55:3306/solo?useUnicode=yes&amp;characterEncoding=utf8jdbc.pool=druid session集群 利用solo做集群会话保持之前，先来聊聊session集群的几种模式。 session会话保持主要有三种模式： 123456789101112131415161718192021session sticky 会话绑定 source_ip nginx : ip_hash haproxy : source lvs : sh cookie nginx : hash haproxy : cookie session cluster 会话集群 tomcat deltamanager httpd + tomcat cluster httpd : mod_proxy, mod_proxy_http, mod_proxy_balancer httpd + tomcat cluster httpd : mod_proxy, mod_proxy_ajp, mod_proxy_balancer httpd + tomcat cluster httpd : mod_jk nginx + tomcat cluster session server 会话服务器 memcached, redis apache代理 使用apache代理，主要使用到了httpd的proxy_module、proxy_httpd_module、proxy_ajp_module、proxy_balacer_module几个模块 123456789101112[root@centos71 conf.d]# httpd -M | egrep proxy proxy_module (shared) proxy_ajp_module (shared) proxy_balancer_module (shared) proxy_connect_module (shared) proxy_express_module (shared) proxy_fcgi_module (shared) proxy_fdpass_module (shared) proxy_ftp_module (shared) proxy_http_module (shared) proxy_scgi_module (shared) proxy_wstunnel_module (shared) apache指令说明关于如上apache指令的说明： ProxyPreserveHost {On|Off} ：如果启用此功能，代理会将用户请求报文中的Host:行发送给后端的服务器，而不再使用ProxyPass指定的服务器地址。如果想在反向代理中支持虚拟主机，则需要开启此项，否则就无需打开此功能。 ProxyVia {On|Off|Full|Block} ：用于控制在http首部是否使用Via:，主要用于在多级代理中控制代理请求的流向。默认为Off，即不启用此功能；On表示每个请求和响应报文均添加Via:；Full表示每个Via:行都会添加当前apache服务器的版本号信息；Block表示每个代理请求报文中的Via：都会被移除。 ProxyRequests {On|Off} ：是否开启apache正向代理的功能；启用此项时为了代理http协议必须启用mod_proxy_http模块。同时，如果为apache设置了ProxyPass，则必须将ProxyRequests设置为Off。 ProxyPass [path] !|url [key=value key=value ...]] ：将后端服务器某URL与当前服务器的某虚拟路径关联起来作为提供服务的路径，path为当前服务器上的某虚拟路径，url为后端服务器上某URL路径。使用此指令时必须将ProxyRequests的值设置为Off。需要注意的是，如果path以“/”结尾，则对应的url也必须以“/”结尾，反之亦然。 ProxyPassReverse ：用于让apache调整HTTP重定向响应报文中的Location、Content-Location及URI标签所对应的URL，在反向代理环境中必须使用此指令避免重定向报文绕过proxy服务器。 另外，mod_proxy模块在httpd2.1的版本之后支持与后端服务器的连接池功能，连接在按需创建在可以保存至连接池中以备进一步使用。连接池大小或其它设定可以通过在ProxyPass中使用key=value的方式定义。常用的key如下所示： ◇ min：连接池的最小容量，此值与实际连接个数无关，仅表示连接池最小要初始化的空间大小。◇ max：连接池的最大容量，每个MPM都有自己独立的容量；都值与MPM本身有关，如Prefork的总是为1，而其它的则取决于ThreadsPerChild指令的值。◇ loadfactor：用于负载均衡集群配置中，定义对应后端服务器的权重，取值范围为1-100。◇ retry：当apache将请求发送至后端服务器得到错误响应时等待多长时间以后再重试。单位是秒钟。 如果Proxy指定是以balancer://开头，即用于负载均衡集群时 其还可以接受一些特殊的参数，如下所示： ◇lbmethod：apache实现负载均衡的调度方法，默认是byrequests，即基于权重将统计请求个数进行调度，bytraffic则执行基于权重的流量计数调度，bybusyness通过考量每个后端服务器的当前负载进行调度。◇ maxattempts：放弃请求之前实现故障转移的次数，默认为1，其最大值不应该大于总的节点数。◇ nofailover：取值为On或Off，设置为On时表示后端服务器故障时，用户的session将损坏；因此，在后端服务器不支持session复制时可将其设置为On。◇ stickysession：调度器的sticky session的名字，根据web程序语言的不同，其值为JSESSIONID或PHPSESSIONID。 上述指令除了能在banlancer://或ProxyPass中设定之外，也可使用ProxySet指令直接进行设置，如： 12345&lt;Proxy balancer://hotcluster&gt;BalancerMember http://www1.magedu.com:8080 loadfactor=1BalancerMember http://www2.magedu.com:8080 loadfactor=2ProxySet lbmethod=bytraffic&lt;/Proxy&gt; 使用http协议直接代理tomcat1234567891011121314&lt;VirtualHost *:80&gt; ServerName solo.imkindu.cn ProxyVia On ProxyRequests Off # 关闭正向代理 ProxyPreserveHost On # host主机名 &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / http://192.168.56.52:8080/ ProxyPassReverse / http://192.168.56.52:8080/ &lt;Location /&gt; Require all granted &lt;/Location&gt;&lt;/VirtualHost&gt; 使用ajp协议代理tomcat 使用apache2.4和ajp协议代理tomcat需要使用到httpd的 proxy_ajp_module 使用httpd -M查看是否编译了proxy_ajp_module 12[root@centos71 conf.d]# httpd -M | grep --color proxy_ajp_module proxy_ajp_module (shared) 1234567891011121314&lt;VirtualHost *:80&gt; ServerName solo.imkindu.cn ProxyVia On ProxyRequests Off # 关闭正向代理 ProxyPreserveHost On # host主机名 &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / ajp://172.18.56.52:8009/ # tomcat ajp默认使用8009端口 ProxyPassReverse / ajp://172.18.56.52:8009/ &lt;Location /&gt; Require all granted &lt;/Location&gt;&lt;/VirtualHost&gt; apache负载均衡tomcat 使用apache 负载调度tomcat 需要使用到 mod_proxy_balacer模块 详细手册查看 ： http://httpd.apache.org/docs/2.4/mod/mod_proxy_balancer.html 参数详解 &lt;proxy&gt; 应用于代理资源的指令的容器 如果Proxy指定是以balancer://开头，即用于负载均衡集群 Description: Container for directives applied to proxied resourcesSyntax: Proxy wildcard-url … ProxyContext: server config, virtual hostStatus: ExtensionModule: mod_proxy BalancerMember Add a member to a load balancing group 添加成员 Syntax: BalancerMember [balancerurl] url [key=value [key=value …]] 可以添加额外参数参数详解 ： http://httpd.apache.org/docs/2.4/mod/mod_proxy.html#proxypass 参数 解释 loadfactor 权重 1-100 route Route of the worker when used inside load balancer. The route is a value appended to session id.后台tomcat的engine 可以添加一个 jvmRoute=”Tomcat52” 与之对应 Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot; jvmRoute=&quot;Tomcat52&quot; 其还可以接受一些特殊的参数，如下所示： ◇ lbmethod ：apache实现负载均衡的调度方法，默认是byrequests，即基于权重将统计请求个数进行调度，bytraffic则执行基于权重的流量计数调度，bybusyness通过考量每个后端服务器的当前负载进行调度。◇ maxattempts ：放弃请求之前实现故障转移的次数，默认为1，其最大值不应该大于总的节点数。◇ nofailover：取值为On或Off，设置为On时表示后端服务器故障时，用户的session将损坏；因此，在后端服务器不支持session复制时可将其设置为On。◇ stickysession：调度器的sticky session的名字，根据web程序语言的不同，其值为JSESSIONID或PHPSESSIONID。 123456789101112131415161718192021&lt;proxy balancer://tomcat&gt; BalancerMember http://192.168.56.51:8080 loadfactor=1 route=Tomcat51 BalancerMember http://192.168.56.52:8080 loadfactor=1 route=Tomcat52 ProxySet lbmethod=byrequests # 添加调度算法 &lt;/proxy&gt;&lt;VirtualHost *:80&gt; #ServerName solo.imkindu.cn ServerName 172.18.56.71 ProxyVia On ProxyRequests Off # 关闭反代 ProxyPreserveHost On # host主机名 &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / balancer://tomcat/ ProxyPassReverse / balance://tomcat/ &lt;Location /&gt; Require all granted &lt;/Location&gt;&lt;/VirtualHost&gt; 负载tomcat并保持会话 stickysession：调度器的sticky session的名字，根据web程序语言的不同，其值为JSESSIONID或PHPSESSIONID。利用stickysession和route保持会话。 1234567891011121314151617181920212223# 注释Header add Set-Cookie "ROUTEID=.%&#123;BALANCER_WORKER_ROUTE&#125;e; path=/" env=BALANCER_ROUTE_CHANGED&lt;proxy balancer://tomcat&gt; BalancerMember http://192.168.56.51:8080 loadfactor=1 route=Tomcat51 BalancerMember http://192.168.56.52:8080 loadfactor=1 route=Tomcat52 ProxySet stickysession=ROUTEID # stickysession 利用route标识保持session会话&lt;/proxy&gt;&lt;VirtualHost *:80&gt; #ServerName solo.imkindu.cn ServerName 172.18.56.71 ProxyVia On ProxyRequests Off # 关闭反代 ProxyPreserveHost On # host主机名 &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / balancer://tomcat/ ProxyPassReverse / balance://tomcat/ &lt;Location /&gt; Require all granted &lt;/Location&gt;&lt;/VirtualHost&gt; balancer管理页面 httpd2.4负载均衡模块balancer自带了一个balancer-manager管理界面，可以通过此界面查看负载情况，并设置单个后台backend等。 详细参考查看httpd官方proxy_balancer模块 ： http://httpd.apache.org/docs/2.4/mod/mod_proxy_balancer.html 12345678910111213141516171819202122232425Header add Set-Cookie "ROUTEID=.%&#123;BALANCER_WORKER_ROUTE&#125;e; path=/" env=BALANCER_ROUTE_CHANGED&lt;proxy balancer://tomcat&gt; BalancerMember http://192.168.56.51:8080 loadfactor=1 route=Tomcat51 BalancerMember http://192.168.56.52:8080 loadfactor=1 route=Tomcat52 ProxySet stickysession=ROUTEID&lt;/proxy&gt;&lt;VirtualHost *:80&gt; ServerName solo.imkindu.cn ProxyVia On ProxyRequests Off ProxyPreserveHost On # host主机名 &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / balancer://tomcat/ ProxyPassReverse / balance://tomcat/ &lt;Location /&gt; Require all granted &lt;/Location&gt; &lt;Location "/balancer-manager"&gt; # balancer-manager SetHandler balancer-manager # ProxyPass ! # 不使用代理 Require all granted &lt;/Location&gt;&lt;/VirtualHost&gt; nginx代理tomcat 一般真正使用的还是nginx前端负载均衡，后端在tomcat服务器上再次使用Nginx代理到本机的tomcat，这样充分发挥调度器、nginx的动静分离、Tomcat只处理jsp，保证了各自模块的高效性能。 nginx直接代理到tomcat8080nginx代理服务器配置 123456789server &#123; listen 80; server_name solo.imkindu.cn; location / &#123; proxy_pass http://192.168.56.52:8080/; proxy_set_header Host $host:$server_port; proxy_set_header X-Real_IP $remote_addr; &#125;&#125; nginx代理本机tomcat 通过nginx代理服务器代理到 tomcat服务器上的nginx，再次转发到tomcat tomcat上nginx配置： 12345678910111213upstream solo &#123; server localhost:8080 ;&#125;server &#123; listen 80; server_name solo.imkindu.cn; location / &#123; proxy_pass http://solo$request_uri; proxy_set_header Host $host:$server_port; proxy_set_header X-Real_IP $remote_addr; &#125;&#125; session cluster session 集群，其主要工作原理是：将多台后端数据服务器作为一个session集群，常用的有deltamanager这种将任意一节点的会话信息同步到其他所有节点，保证不论前台调度器将请求调度到哪台服务器都可以获取会话信息，BackupManager模式：将多台服务器分为多个小组，其中小组之间的多个服务器同步会话信息，不用同步到所有节点，当小组任意节点挂了之后，去其他小组节点获取会话信息。 deltaManager tomcat默认的集群会话管理器——DeltaManager。它主要用于集群中各个节点之间会话状态的同步维护。DeltaManager的职责是将某节点的会话该变同步到集群内其他成员节点上，它属于全节点复制模式，所谓全节点复制是指集群中某个节点的状态变化后需要同步到集群中剩余的节点，非全节点方式可能只是同步到其中某个或若干节点。 查看帮助：Clustering http://tomcat.apache.org/tomcat-7.0-doc/cluster-howto.html 1、使用deltamanager这种session集群模式，需要在server.xml中配置对应多播地址、监听端口等，deltamanager可以配置在 &lt;Engine&gt; or &lt;Host&gt;中。 注意 ：官方文档配置文件中 ClusterListener 两行没有闭合标签”/“ 12345678910111213141516171819202122232425262728293031323334&lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" channelSendOptions="8"&gt; &lt;Manager className="org.apache.catalina.ha.session.DeltaManager" expireSessionsOnShutdown="false" notifyListenersOnReplication="true"/&gt; &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt; &lt;Membership className="org.apache.catalina.tribes.membership.McastService" address="228.0.56.71" port="45564" frequency="500" dropTime="3000"/&gt; &lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver" address="192.168.56.51" port="4000" autoBind="100" selectorTimeout="5000" maxThreads="6"/&gt; &lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt; &lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt; &lt;/Sender&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt; &lt;/Channel&gt; &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=""/&gt; &lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt; &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener" /&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener" /&gt;&lt;/Cluster&gt; 选项解释： Membership ：MemberShip组件自动检索发现集群里的新节点或已经停止工作的节点，并发出相应的通知。默认使用组播（Multicast）实现。 Receiver ：负责监听接收其他节点传送过来的数据。默认使用non-blocking TCP Server sockets。 Sender ： 发送数据给其他节点。管理从一个节点发送到另外一个节点的出站连接和数据信息，允许信息并行发送。默认使用TCP Client Sockets。 2、确保web.xml有&lt;distributable/&gt;标签 Make sure your web.xml has the element 1234567&lt;web-app xmlns="http://java.sun.com/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd" version="3.0"&gt;&lt;distributable/&gt; # 添加这个标签即可 查看效果： 无论请求调度到哪一台，每台服务器都保存了所有session会话信息。 BackupManager backupManager同deltaManager，只不过是将Manager换成了BackupManager，然后定义多个小组，每个小组节点使用同一个多播地址，虽然backupmanager比deltamanager效率上提高了，但是想想有一个问题，当前端调度器将请求调度到了另外一台小组成员外的节点，那不就是获取不到会话信息了。当集群中的节点数量很多并且部署着不同应用时，可以使用BackupManager，BackManager仅向部署了当前应用的节点拷贝Session。但是到目前为止BackupManager并未经过大规模测试，可靠性不及DeltaManager。 12345678910111213141516171819202122232425262728293031323334&lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" channelSendOptions="8"&gt; &lt;Manager className="org.apache.catalina.ha.session.BackupManager" # 注意这里更换为BackupManager expireSessionsOnShutdown="false" notifyListenersOnReplication="true"/&gt; &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt; &lt;Membership className="org.apache.catalina.tribes.membership.McastService" address="228.0.56.71" port="45564" frequency="500" dropTime="3000"/&gt; &lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver" address="192.168.56.51" port="4000" autoBind="100" selectorTimeout="5000" maxThreads="6"/&gt; &lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt; &lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt; &lt;/Sender&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt; &lt;/Channel&gt; &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=""/&gt; &lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt; &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener" /&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener" /&gt;&lt;/Cluster&gt; session server 在企业中用的最多的应该还是session server服务器这种模式吧，配置也将为简单，其原理就是：将多个节点的会话信息同一保存至一台session服务器，常见的有将多个节点session保存至同一台memcached中，这样前台调度器和backend server都不会做任何配置了。而且memcached是基于内存缓存的，非常高效。 MSM tomcat会话存入memcached需要依赖于第三方类库，在github上有第三方提供，使用量最高的是magro/memcached-session-manager。 https://github.com/magro/memcached-session-manager MSM(memcached-session-manager)支持tomcat6和tomcat7 ，利用Value（Tomcat 阀对Request进行跟踪。Request请求到来时，从memcached加载session，Request请求结束时，将tomcat session更新至memcached，以达到session共享之目的，支持sticky和 non-sticky 模式。 Sticky 模式：tomcat session为主session， memcached为备session。Request请求到来时， 从memcached加载备session到tomcat (仅当tomcat jvmroute发生变化时，否则直接取tomcat session)；Request请求结束时，将tomcat session更新至memcached，以达到主备同步之目的。 Non-Sticky模式：tomcat session为中转session， memcached1为主session，memcached 2为备session。Request请求到来时，从memcached2加载备session到tomcat，当容器中还是没有session 则从memcached1加载主session到tomcat，这种情况是只有一个memcached节点，或者有memcached1出错时，Request请求结束时，将tomcat session更新至主memcached1和备memcached2，并且清除tomcat session 。以达到主备同步之目的。 SetupAndConfiguration wiki page MSM提供了wiki，示例解释了多样性将tomcat的session存入memcached或者redis。wiki page 地址 ：https://github.com/magro/memcached-session-manager/wiki/SetupAndConfiguration Configure tomcat The configuration of tomcat requires two things: you need to drop some jars in your $CATALINA_HOME/lib/ and WEB-INF/lib/ directories and you have to configure the memcached session manager in the related element (e.g. in META-INF/context.xml inside the application files). Add memcached-session-manager jars to tomcat tomcat的lib目录如果是Yum安装的在/usr/share/java/tomcat/ 12345678910[ root@centos51 conf ]# ll /usr/share/tomcat/total 8drwxr-xr-x 2 root root 4096 Oct 21 06:32 binlrwxrwxrwx 1 root tomcat 11 Oct 21 06:32 conf -&gt; /etc/tomcatlrwxrwxrwx 1 root tomcat 22 Oct 21 06:32 lib -&gt; /usr/share/java/tomcat # 类库目录lrwxrwxrwx 1 root tomcat 15 Oct 21 06:32 logs -&gt; /var/log/tomcat-rw-r--r-- 1 tomcat tomcat 3952 Oct 22 19:39 solo.loglrwxrwxrwx 1 root tomcat 22 Oct 21 06:32 temp -&gt; /var/cache/tomcat/templrwxrwxrwx 1 root tomcat 23 Oct 21 06:32 webapps -&gt; /var/lib/tomcat/webappslrwxrwxrwx 1 root tomcat 22 Oct 21 06:32 work -&gt; /var/cache/tomcat/work Add custom serializers to your webapp 因为memcached只支持字符串这种可流式化数据,对于session对象这种数据，需要一些序列化工具，类似于咱们php经常弄的json_encode一样，将对象转换成字符串。常用的序列化工具有： kryo-serializer: msm-kryo-serializer, kryo-serializers-0.34+, kryo-3.x, minlog, reflectasm, asm-5.x, objenesis-2.xjavolution-serializer: msm-javolution-serializer, javolution-5.4.3.1xstream-serializer: msm-xstream-serializer, xstream, xmlpull, xpp3_minflexjson-serializer: msm-flexjson-serializer, flexjson Configure Update the &lt;Context&gt; element (in META-INF/context.xml or what else you choose for context definition, please check the related tomcat documentation for this) so that it contains the Manager configuration for the memcached-session-manager, like in the examples below. github上提供了多个示例。 http://mvnrepository.com/artifact/joda-time/joda-time/1.6.2 javolution序列化工具 123456789101112131415161718&lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true" &gt; &lt;Context path="/" docBase="ROOT" reloadable="true"&gt; &lt;Manager className="de.javakaffee.web.msm.MemcachedBackupSessionManager" memcachedNodes="n1:172.18.56.51:11211,n2:172.18.56.52:11211" failoverNodes="n2" # sticky="false" # 这里需要特别注意，最好不好加 sessionBackupAsync= "false" sessionBackupTimeout= "100" copyCollectionsForSerialization="true" requestUriIgnorePattern=".*\.(ico|png|gif|jpg|css|js)$" transcoderFactoryClass="de.javakaffee.web.msm.serializer.javolution.JavolutionTranscoderFactory" /&gt; &lt;/Context&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log." suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt;&lt;/Host&gt; Example for non-sticky sessions + kryo 1234567891011&lt;Context&gt; ... &lt;Manager className="de.javakaffee.web.msm.MemcachedBackupSessionManager" memcachedNodes="n1:host1.yourdomain.com:11211,n2:host2.yourdomain.com:11211" sticky="false" sessionBackupAsync="false" lockingMode="uriPattern:/path1|/path2" requestUriIgnorePattern=".*\.(ico|png|gif|jpg|css|js)$" transcoderFactoryClass="de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory" /&gt;&lt;/Context&gt;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat]]></title>
    <url>%2F2017%2F11%2F04%2Fjava%2Ftomcat%2F</url>
    <content type="text"><![CDATA[Tomcat是Apache 软件基金会（Apache Software Foundation）的Jakarta 项目中的一个核心项目，由Apache、Sun 和其他一些公司及个人共同开发而成。由于有了Sun 的参与和支持，最新的Servlet 和JSP 规范总是能在Tomcat 中得到体现，Tomcat 5支持最新的Servlet 2.4 和JSP 2.0 规范。因为Tomcat 技术先进、性能稳定，而且免费，因而深受Java 爱好者的喜爱并得到了部分软件开发商的认可，成为目前比较流行的Web 应用服务器。 java简介 Java是一门面向对象编程语言，不仅吸收了C++语言的各种优点，还摒弃了C++里难以理解的多继承、指针等概念，因此Java语言具有功能强大和简单易用两个特征。Java语言作为静态面向对象编程语言的代表，极好地实现了面向对象理论，允许程序员以优雅的思维方式进行复杂的编程。 java 现在主要分为三大分支:J2SE、J2EE、J2ME，Java可以编写桌面应用程序、Web应用程序、分布式系统和嵌入式系统应用程序等。从java概念图可以看出，java是一个较为庞大的体系，包含了JDK 和 JVM等等。 servlet Servlet（Server Applet）是Java Servlet的简称, 是运行在 Web 服务器或应用服务器上的程序，它是作为来自 Web 浏览器或其他 HTTP 客户端的请求和 HTTP 服务器上的数据库或应用程序之间的中间层。 servlet架构 下图显示servlet在web应用程序中的位置 Servlet 任务 Servlet 执行以下主要任务： 读取客户端（浏览器）发送的显式的数据。这包括网页上的 HTML 表单，或者也可以是来自 applet 或自定义的 HTTP 客户端程序的表单。 读取客户端（浏览器）发送的隐式的 HTTP 请求数据。这包括 cookies、媒体类型和浏览器能理解的压缩格式等等。 处理数据并生成结果。这个过程可能需要访问数据库，执行 RMI 或 CORBA 调用，调用 Web 服务，或者直接计算得出对应的响应。 发送显式的数据（即文档）到客户端（浏览器）。该文档的格式可以是多种多样的，包括文本文件（HTML 或 XML）、二进制文件（GIF 图像）、Excel 等。 发送隐式的 HTTP 响应到客户端（浏览器）。这包括告诉浏览器或其他客户端被返回的文档类型（例如 HTML），设置 cookies 和缓存参数，以及其他类似的任务。 jsp编译过程 jsp –&gt; jasper(jsp-&gt;java) –&gt; servlet(处理html) –&gt; complie(编译器) –&gt; bytecodes –&gt; jvm tomcat Tomcat是由Apache软件基金会下属的Jakarta项目开发的一个Servlet容器，按照Sun Microsystems提供的技术规范，实现了对Servlet和JavaServer Page（JSP）的支持，并提供了作为Web服务器的一些特有功能，如Tomcat管理和控制平台、安全域管理和Tomcat阀等。由于Tomcat本身也内含了一个HTTP服务器，它也可以被视作一个单独的Web服务器。但是，不能将 Tomcat 和 Apache Web 服务器混淆，Apache Web Server 是一个用 C 语言实现的 HTTP web server；这两个 HTTP web server 不是捆绑在一起的。Apache Tomcat 包含了一个配置管理工具，也可以通过编辑 XML 格式的配置文件来进行配置。Apache，nginx，tomcat并称为网页服务三剑客，可见其应用度之广泛。 tomcat架构体系 tomcat架构体系 Container的体系结构 tomcat核心组件tomcat was released with Catalina(a servlet container), `Coyote(an HTTP connector) and Jasper(a JSP engine) Catalina ： servlet container 容器Coyote : http connection 连接器Jasper : JSP engine JSP的翻译器，将jsp文件翻译为java文件 tomcat组件组件分类 每个组件都由“类”来实现，有些组件的实现还不止一种 顶级类组件 ： 位于配置层次的顶级，并且彼此间有着严格的对应关系 server、 service连接器组件 ： 连接客户端（可以是浏览器或Web服务器）请求至Servlet容器 connector容器类组件 ： 包含一组其它组件，即可以部署webapp的组件 engine、host、context被嵌套类组件 ： nested 位于一个容器当中，但不能包含其它组件 valve、logger、realm 组件说明顶级类组件1、服务器(server)：Tomcat的一个实例，通常一个JVM只能包含一个Tomcat实例；因此，一台物理服务器上可以在启动多个JVM的情况下在每一个JVM中启动一个Tomcat实例，每个实例分属于一个独立的管理端口。这是一个顶级组件。 2、服务(service)：一个服务组件通常包含一个引擎和与此引擎相关联的一个或多个连接器。给服务命名可以方便管理员在日志文件中识别不同服务产生的日志。一个server可以包含多个service组件，但通常情下只为一个service指派一个server。 连接器类组件3、连接器(connectors)：负责连接客户端（可以是浏览器或Web服务器）请求至Servlet容器内的Web应用程序，通常指的是接收客户发来请求的位置及服务器端分配的端口。默认端口通常是HTTP协议的8080，管理员也可以根据自己的需要改变此端口。一个引擎可以配置多个连接器，但这些连接器必须使用不同的端口。默认的连接器是基于HTTP/1.1的Coyote。同时，Tomcat也支持AJP、JServ和JK2连接器。 容器类组件4、引擎(Engine)：引擎通是指处理请求的Servlet引擎组件，即Catalina Servlet引擎，它检查每一个请求的HTTP首部信息以辨别此请求应该发往哪个host或context，并将请求处理后的结果返回的相应的客户端。严格意义上来说，容器不必非得通过引擎来实现，它也可以是只是一个容器。如果Tomcat被配置成为独立服务器，默认引擎就是已经定义好的引擎。而如果Tomcat被配置为Apache Web服务器的提供Servlet功能的后端，默认引擎将被忽略，因为Web服务器自身就能确定将用户请求发往何处。一个引擎可以包含多个host组件。 5、主机(Host)：主机组件类似于Apache中的虚拟主机，但在Tomcat中只支持基于FQDN的“虚拟主机”。一个引擎至少要包含一个主机组件。 6、上下文(Context)：Context组件是最内层次的组件，它表示Web应用程序本身。配置一个Context最主要的是指定Web应用程序的根目录，以便Servlet容器能够将用户请求发往正确的位置。Context组件也可包含自定义的错误页，以实现在用户访问发生错误时提供友好的提示信息。 被嵌套类组件这类组件通常包含于容器类组件中以提供具有管理功能的服务，它们不能包含其它组件，但有些却可以由不同层次的容器各自配置。 7、阀门(Valve)：用来拦截请求并在将其转至目标之前进行某种处理操作，类似于Servlet规范中定义的过滤器。Valve可以定义在任何容器类的组件中。Valve常被用来记录客户端请求、客户端IP地址和服务器等信息，这种处理技术通常被称作请求转储(request dumping)。请求转储valve记录请求客户端请求数据包中的HTTP首部信息和cookie信息文件中，响应转储valve则记录响应数据包首部信息和cookie信息至文件中。 8、日志记录器(Logger)：用于记录组件内部的状态信息，可被用于除Context之外的任何容器中。日志记录的功能可被继承，因此，一个引擎级别的Logger将会记录引擎内部所有组件相关的信息，除非某内部组件定义了自己的Logger组件。 9、领域(Realm)：用于用户的认证和授权；在配置一个应用程序时，管理员可以为每个资源或资源组定义角色及权限，而这些访问控制功能的生效需要通过Realm来实现。Realm的认证可以基于文本文件、数据库表、LDAP服务等来实现。Realm的效用会遍及整个引擎或顶级容器，因此，一个容器内的所有应用程序将共享用户资源。同时，Realm可以被其所在组件的子组件继承，也可以被子组件中定义的Realm所覆盖。 连接器协议Tomcat的Web服务器连接器支持两种协议：AJP和HTTP，它们均定义了以二进制格式在Web服务器和Tomcat之间进行数据传输，并提供相应的控制命令。 AJP(Apache JServ Protocol)协议 目前正在使用的AJP协议的版本是通过JK和JK2连接器提供支持的AJP13，它基于二进制的格式在Web服务器和Tomcat之间传输数据，而此前的版本AJP10和AJP11则使用文本格式传输数据。 HTTP(HyperText Transfer Protocol)超文本传输协议 HTTP协议：诚如其名称所表示，其是使用HTTP或HTTPS协议在Web服务器和Tomcat之间建立通信，此时，Tomcat就是一个完全功能的HTTP服务器，它需要监听在某端口上以接收来自于商前服务器的请求。 安装jdk和tomcatrpm安装jdk yum源自带的有jdk，可以通过yum安装，官网也提供了rpm包，可以通过rpm包安装 1234567891011[ root@centos51 tools ]# rpm -ivh jdk-7u67-linux-x64.rpm Preparing... ########################################### [100%] 1:jdk ########################################### [100%]Unpacking JAR files... rt.jar... jsse.jar... charsets.jar... tools.jar... localedata.jar... jfxrt.jar... 安装二进制版本tomcat 教室yum源提供了tomcat包，官网提供了二进制包，可以直接二进制包安装 12[ root@centos51 tools ]# tar -xvf apache-tomcat-8.0.23.tar.gz -C /usr/local/[ root@centos51 local ]# ln -sv apache-tomcat-8.0.23/ tomcat 添加环境变量 java环境依赖于JAVA_HOME这个变量，如果是手动安装的，需要添加路径变量 123456789# 二进制安装和rpm安装jdk配置路径export JAVA_HOME=/usr/java/latestexport PATH=$JAVA_HOME/bin:$PATHexport CATALINA_HOME=/usr/local/tomcatexport PATH=$CATALINA_HOME/bin:$PATH# yum安装jdk和tomcat配置路径export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.121-1.b13.el6.x86_64export CATALINA_HOME=/usr/share/tomcatexport PATH=$JAVA_HOME/bin:$CATALINA_HOME/bin:$PATH openjdk-devel安装 在使用过程中，需要使用到jar等java常用命令，经查找，这些工具在openjdk-devel包中 1[ root@centos51 bin ]# yum install java-1.8.0-openjdk-devel tomcat目录结构123456789[root@centos52 share]# ll tomcat/total 4bin # 脚本及启动时用到的类conf -&gt; /etc/tomcat # 配置文件lib -&gt; /usr/share/java/tomcat # 核心类库logs -&gt; /var/log/tomcat # 日志temp -&gt; /var/cache/tomcat/temp # 临时文件目录webapps -&gt; /var/lib/tomcat/webapps # 应用程序代码目录work -&gt; /var/cache/tomcat/work # 工作目录（编译后的.java和.class） webapps目录结构 每个应用程序webapp目录都有自己的组织结构，主要包含了jsp文件、类文件、主页文件、部署描述符等。 / ： webapp的根目录WEB-INF/ ： 当前webapp的私有资源目录，通常存放当前webapp的web.xmlMETA-INF/ ：当前webapp的私有资源目录，通常存放当前webapp的context.xmlclasses/ ：当前webapp的私有类文件lib/ ： 私有类，或被打包为jar格式类index.jsp：webapp的主页 docs帮助文档 tomcat自带的有帮助文档 1234567[root@centos52 docs] yum install tomcat-docs-webapp[ root@centos51 webapps ]# ll /usr/share/tomcat/webapps/total 16drwxr-xr-x 14 root root 4096 Oct 21 20:25 docs # 帮助文档drwxr-xr-x 5 root tomcat 4096 Oct 21 20:17 host-managerdrwxr-xr-x 5 root tomcat 4096 Oct 21 20:17 managerdrwxr-xr-x 2 root root 4096 Oct 21 06:44 ROOT Tomcat的配置文件Tomcat的配置文件默认存放在$CATALINA_HOME/conf目录中，主要有以下几个： 123456789101112[ root@centos51 conf ]# lltotal 220drwxrwxr-x 3 root tomcat 4096 Oct 21 06:32 Catalina-rw-rw-r-- 1 tomcat tomcat 13332 Dec 1 2016 catalina.policy-rw-rw-r-- 1 tomcat tomcat 6322 Dec 1 2016 catalina.properties-rw-rw-r-- 1 tomcat tomcat 1394 Dec 1 2016 context.xml-rw-rw-r-- 1 tomcat tomcat 547 Dec 1 2016 log4j.properties-rw-rw-r-- 1 tomcat tomcat 3288 Dec 1 2016 logging.properties-rw-rw-r-- 1 tomcat tomcat 6633 Oct 21 07:16 server.xml-rw-rw-r-- 1 tomcat tomcat 1534 Dec 1 2016 tomcat.conf-rw-rw---- 1 tomcat tomcat 2425 Dec 1 2016 tomcat-users.xml-rw-rw-r-- 1 tomcat tomcat 167655 Dec 1 2016 web.xml server.xml: Tomcat的主配置文件，包含Service, Connector, Engine, Realm, Valve, Hosts主组件的相关配置信息；web.xml：遵循Servlet规范标准的配置文件，用于配置servlet，并为所有的Web应用程序提供包括MIME映射等默认配置信息；tomcat-user.xml：Realm认证时用到的相关角色、用户和密码等信息；Tomcat自带的manager默认情况下会用到此文件；在Tomcat中添加/删除用户，为用户指定角色等将通过编辑此文件实现；catalina.policy：Java相关的安全策略配置文件，在系统资源级别上提供访问控制的能力；catalina.properties：Tomcat内部package的定义及访问相关的控制，也包括对通过类装载器装载的内容的控制；Tomcat6在启动时会事先读取此文件的相关设置；logging.properties: Tomcat6通过自己内部实现的JAVA日志记录器来记录操作相关的日志，此文件即为日志记录器相关的配置信息，可以用来定义日志记录的组件级别以及日志文件的存在位置等；context.xml：所有host的默认配置信息； server.xml Tomcat以面向对象的方式运行，它可以在运行时动态加载配置文件中定义的对象结构，这有点类似于apache的httpd模块的调用方式。server.xml中定义的每个主元素都会被创建为对象，并以某特定的层次结构将这些对象组织在一起。 server.xml配置结构和tomcat架构类似，包含server、service、connector、engine、host等组件信息。 123456789101112131415161718192021222324252627282930313233&lt;?xml version='1.0' encoding='utf-8'?&gt;&lt;Server port="8005" shutdown="SHUTDOWN"&gt; &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; server.xml文件中可定义的元素非常多，包括Server, Service, Connector, Engine, Cluster, Host, Alias, Context, Realm, Valve, Manager, Listener, Resources, Resource, ResourceEnvRef, ResourceLink, WatchedResource, GlobalNameingResources, Store, Transaction, Channel, Membership, Transport, Member, ClusterListener等。 下面简单介绍几个常用组件： Server组件如上面示例文件中定义的： 这会让Tomcat6启动一个server实例（即一个JVM），它监听在8005端口以接收shutdown命令。各Server的定义不能使用同一个端口，这意味着如果在同一个物理机上启动了多个Server实例，必须配置它们使用不同的端口。这个端口的定义用于为管理员提供一个关闭此实例的便捷途径，因此，管理员可以直接telnet至此端口使用SHUTDOWN命令关闭此实例。不过，基于安全角度的考虑，这通常不允许远程进行。 Server的相关属性：className: 用于实现此Server容器的完全限定类的名称，默认为org.apache.catalina.core.StandardServer；port: 接收shutdown指令的端口，默认仅允许通过本机访问，默认为8005；shutdown：发往此Server用于实现关闭tomcat实例的命令字符串，默认为SHUTDOWN； Service组件Service主要用于关联一个引擎和与此引擎相关的连接器，每个连接器通过一个特定的端口和协议接收入站请求交将其转发至关联的引擎进行处理。困此，Service要包含一个引擎、一个或多个连接器。 如上面示例中的定义： 这定义了一个名为Catalina的Service，此名字也会在产生相关的日志信息时记录在日志文件当中。 Service相关的属性： className： 用于实现service的类名，一般都是org.apache.catalina.core.StandardService。name：此服务的名称，默认为Catalina； Connector组件进入Tomcat的请求可以根据Tomcat的工作模式分为如下两类： Tomcat作为应用程序服务器：请求来自于前端的web服务器，这可能是Apache, IIS, Nginx等；Tomcat作为独立服务器：请求来自于web浏览器； Tomcat应该考虑工作情形并为相应情形下的请求分别定义好需要的连接器才能正确接收来自于客户端的请求。一个引擎可以有一个或多个连接器，以适应多种请求方式。 定义连接器可以使用多种属性，有些属性也只适用于某特定的连接器类型。一般说来，常见于server.xml中的连接器类型通常有4种： 1) HTTP连接器2) SSL连接器3) AJP 1.3连接器4) proxy连接器 如上面示例server.xml中定义的HTTP连接器：123&lt;Connector port="8080" protocol="HTTP/1.1" maxThreads="150" connectionTimeout="20000" redirectPort="8443"/&gt; 定义连接器时可以配置的属性非常多，但通常定义HTTP连接器时必须定义的属性只有“port”，定义AJP连接器时必须定义的属性只有”protocol”，因为默认的协议为HTTP。以下为常用属性的说明： 1) address：指定连接器监听的地址，默认为所有地址，即0.0.0.0；2) maxThreads：支持的最大并发连接数，默认为200；3) port：监听的端口，默认为0；4) protocol：连接器使用的协议，默认为HTTP/1.1，定义AJP协议时通常为AJP/1.3；5) redirectPort：如果某连接器支持的协议是HTTP，当接收客户端发来的HTTPS请求时，则转发至此属性定义的端口；6) connectionTimeout：等待客户端发送请求的超时时间，单位为毫秒，默认为60000，即1分钟；7) enableLookups：是否通过request.getRemoteHost()进行DNS查询以获取客户端的主机名；默认为true；8) acceptCount：设置等待队列的最大长度；通常在tomcat所有处理线程均处于繁忙状态时，新发来的请求将被放置于等待队列中； 下面是一个定义了多个属性的SSL连接器：1234&lt;Connector port="8443" maxThreads="150" minSpareThreads="25" maxSpareThreads="75" enableLookups="false" acceptCount="100" debug="0" scheme="https" secure="true" clientAuth="false" sslProtocol="TLS" /&gt; Engine组件Engine是Servlet处理器的一个实例，即servlet引擎，默认为定义在server.xml中的Catalina。Engine需要defaultHost属性来为其定义一个接收所有发往非明确定义虚拟主机的请求的host组件。如前面示例中定义的：1&lt;Engine name="Catalina" defaultHost="localhost"&gt; 常用的属性定义： defaultHost：Tomcat支持基于FQDN的虚拟主机，这些虚拟主机可以通过在Engine容器中定义多个不同的Host组件来实现；但如果此引擎的连接器收到一个发往非非明确定义虚拟主机的请求时则需要将此请求发往一个默认的虚拟主机进行处理，因此，在Engine中定义的多个虚拟主机的主机名称中至少要有一个跟defaultHost定义的主机名称同名；name：Engine组件的名称，用于日志和错误信息记录时区别不同的引擎； Engine容器中可以包含Realm、Host、Listener和Valve子容器。 Host组件位于Engine容器中用于接收请求并进行相应处理的主机或虚拟主机，如前面示例中的定义：1234&lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true" xmlValidation="false" xmlNamespaceAware="false"&gt;&lt;/Host&gt; 1) appBase：此Host的webapps目录，即存放非归档的web应用程序的目录或归档后的WAR文件的目录路径；可以使用基于$CATALINA_HOME的相对路径；2) autoDeploy：在Tomcat处于运行状态时放置于appBase目录中的应用程序文件是否自动进行deploy；默认为true；3) unpackWars：在启用此webapps时是否对WAR格式的归档文件先进行展开；默认为true； 虚拟主机定义示例： 1234567891011&lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Host name="localhost" appBase="webapps"&gt; &lt;Context path="" docBase="ROOT"/&gt; &lt;Context path="/bbs" docBase="/web/bss" reloadable="true" crossContext="true"/&gt; &lt;/Host&gt; &lt;Host name="mail.magedu.com" appBase="/web/mail"&gt; &lt;Context path="/" docBase="ROOT"/&gt; &lt;/Host&gt;&lt;/Engine&gt; 主机别名定义：如果一个主机有两个或两个以上的主机名，额外的名称均可以以别名的形式进行定义，如下：123&lt;Host name="www.magedu.com" appBase="webapps" unpackWARs="true"&gt; &lt;Alias&gt;magedu.com&lt;/Alias&gt;&lt;/Host&gt; Context组件Context在某些意义上类似于apache中的路径别名，一个Context定义用于标识tomcat实例中的一个Web应用程序；如下面的定义： 1234567891011121314&lt;!-- Tomcat Root Context --&gt;&lt;Context path="" docBase="/web/webapps"/&gt;&lt;!-- buzzin webapp --&gt;&lt;Context path="/bbs" docBase="/web/threads/bbs" reloadable="true"&gt;&lt;/Context&gt;&lt;!-- chat server --&gt; &lt;Context path="/chat" docBase="/web/chat"/&gt; &lt;!-- darian web --&gt;&lt;Context path="/darian" docBase="darian"/&gt; 在Tomcat6中，每一个context定义也可以使用一个单独的XML文件进行，其文件的目录为$CATALINA_HOME/conf//。可以用于Context中的XML元素有Loader，Manager，Realm，Resources和WatchedResource。 常用的属性定义有： 1) docBase：相应的Web应用程序的存放位置；也可以使用相对路径，起始路径为此Context所属Host中appBase定义的路径；切记，docBase的路径名不能与相应的Host中appBase中定义的路径名有包含关系，比如，如果appBase为deploy，而docBase绝不能为deploy-bbs类的名字；2) path ：相对于Web服务器根路径而言的URI；如果为空“”，则表示为此webapp的根路径；如果context定义在一个单独的xml文件中，此属性不需要定义；3) reloadable：是否允许重新加载此context相关的Web应用程序的类；默认为false； Realm组件一个Realm表示一个安全上下文，它是一个授权访问某个给定Context的用户列表和某用户所允许切换的角色相关定义的列表。因此，Realm就像是一个用户和组相关的数据库。定义Realm时惟一必须要提供的属性是classname，它是Realm的多个不同实现，用于表示此Realm认证的用户及角色等认证信息的存放位置。 JAASRealm：基于Java Authintication and Authorization Service实现用户认证；JDBCRealm：通过JDBC访问某关系型数据库表实现用户认证；JNDIRealm：基于JNDI使用目录服务实现认证信息的获取；MemoryRealm：查找tomcat-user.xml文件实现用户信息的获取；UserDatabaseRealm：基于UserDatabase文件(通常是tomcat-user.xml)实现用户认证，它实现是一个完全可更新和持久有效的MemoryRealm，因此能够跟标准的MemoryRealm兼容；它通过JNDI实现； 下面是一个常见的使用UserDatabase的配置：12&lt;Realm className=”org.apache.catalina.realm.UserDatabaseRealm” resourceName=”UserDatabase”/&gt; 下面是一个使用JDBC方式获取用户认证信息的配置：1234567&lt;Realm className="org.apache.catalina.realm.JDBCRealm" debug="99" driverName="org.gjt.mm.mysql.Driver" connectionURL="jdbc:mysql://localhost/authority" connectionName="test" connectionPassword="test" userTable="users" userNameCol="user_name" userCredCol="user_pass" userRoleTable="user_roles" roleNameCol="role_name" /&gt; Valve组件Valve类似于过滤器，它可以工作于Engine和Host/Context之间、Host和Context之间以及Context和Web应用程序的某资源之间。一个容器内可以建立多个Valve，而且Valve定义的次序也决定了它们生效的次序。 Tomcat6中实现了多种不同的Valve： AccessLogValve：访问日志ValveExtendedAccessValve：扩展功能的访问日志ValveJDBCAccessLogValve：通过JDBC将访问日志信息发送到数据库中；RequestDumperValve：请求转储Valve；RemoteAddrValve：基于远程地址的访问控制；RemoteHostValve：基于远程主机名称的访问控制；SemaphoreValve：用于控制Tomcat主机上任何容器上的并发访问数量；JvmRouteBinderValve：在配置多个Tomcat为以Apache通过mod_proxy或mod_jk作为前端的集群架构中，当期望停止某节点时，可以通过此Valve将用记请求定向至备用节点；使用此Valve，必须使用JvmRouteSessionIDBinderListener；ReplicationValve：专用于Tomcat集群架构中，可以在某个请求的session信息发生更改时触发session数据在各节点间进行复制；SingleSignOn：将两个或多个需要对用户进行认证webapp在认证用户时连接在一起，即一次认证即可访问所有连接在一起的webapp；ClusterSingleSingOn：对SingleSignOn的扩展，专用于Tomcat集群当中，需要结合ClusterSingleSignOnListener进行工作； RemoteHostValve和RemoteAddrValve可以分别用来实现基于主机名称和基于IP地址的访问控制，控制本身可以通过allow或deny来进行定义，这有点类似于Apache的访问控制功能；如下面的Valve则实现了仅允许本机访问/probe： 1234&lt;Context path="/probe" docBase="probe"&gt; &lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="127\.0\.0\.1"/&gt;&lt;/Context&gt; 其中相关属性定义有: 1) className：相关的java实现的类名，相应于分别应该为org.apache.catalina.valves.RemoteHostValve或org.apache.catalina.valves.RemoteAddrValve；2) allow：以逗号分开的允许访问的IP地址列表，支持正则表达式，因此，点号“.”用于IP地址时需要转义；仅定义allow项时，非明确allow的地址均被deny；3) deny: 以逗号分开的禁止访问的IP地址列表，支持正则表达式；使用方式同allow； GlobalNamingResources应用于整个服务器的JNDI映射，此可以避免每个Web应用程序都需要在各自的web.xml创建，这在web应用程序以WAR的形式存在时尤为有用。它通常可以包含三个子元素： 1) Environment;2) Resource;3) ResourceEnvRef; WatchedResourceWatchedResource可以用于Context中监视指定的webapp程序文件的改变，并且能够在监视到文件内容发生改变时重新装载此文件。 ListenerListener用于创建和配置LifecycleListener对象，而LifecycleListener通常被开发人员用来创建和删除容器。 LoaderJava的动态装载功能是其语言功能强大表现之一，Servlet容器使用此功能在运行时动态装载servlet和它们所依赖的类。Loader可以用于Context中控制java类的加载。 ManagerManger对象用于实现HTTP会话管理的功能，Tomcat6中有5种Manger的实现： 1) StandardManagerTomcat6的默认会话管理器，用于非集群环境中对单个处于运行状态的Tomcat实例会话进行管理。当Tomcat关闭时，这些会话相关的数据会被写入磁盘上的一个名叫SESSION.ser的文件，并在Tomcat下次启动时读取此文件。2) PersistentManager 当一个会话长时间处于空闲状态时会被写入到swap会话对象，这对于内存资源比较吃紧的应用环境来说比较有用。3) DeltaManager用于Tomcat集群的会话管理器，它通过将改变了会话数据同步给集群中的其它节点实现会话复制。这种实现会将所有会话的改变同步给集群中的每一个节点，也是在集群环境中用得最多的一种实现方式。4) `BackupManager用于Tomcat集群的会话管理器，与DeltaManager不同的是，某节点会话的改变只会同步给集群中的另一个而非所有节点。5) SimpleTcpReplicationManager Tomcat4时用到的版本，过于老旧了。 StoresPersistentManager必须包含一个Store元素以指定将会话数据存储至何处。这通常有两种实现方式：FileStore和JDBCStore。 Resources经常用于实现在Context中指定需要装载的但不在Tomcat本地磁盘上的应用资源，如Java类，HTML页面，JSP文件等。 Cluster专用于配置Tomcat集群的元素，可用于Engine和Host容器中。在用于Engine容器中时，Engine中的所有Host均支持集群功能。在Cluster元素中，需要直接定义一个Manager元素，这个Manager元素有一个其值为org.apache.catalina.ha.session.DeltaManager或org.apache.catalina.ha.session.BackupManager的className属性。同时，Cluster中还需要分别定义一个Channel和ClusterListener元素。 15.1、Channel用于Cluster中给集群中同一组中的节点定义通信“信道”。Channel中需要至少定义Membership、Receiver和Sender三个元素，此外还有一个可选元素Interceptor。 15.2、Membership用于Channel中配置同一通信信道上节点集群组中的成员情况，即监控加入当前集群组中的节点并在各节点间传递心跳信息，而且可以在接收不到某成员的心跳信息时将其从集群节点中移除。Tomcat6中Membership的实现是org.apache.catalina.tribes.membership.McastService。 15.3、Sender用于Channel中配置“复制信息”的发送器，实现发送需要同步给其它节点的数据至集群中的其它节点。发送器不需要属性的定义，但可以在其内部定义一个Transport元素。 15.4 Transport用于Sender内部，配置数据如何发送至集群中的其它节点。Tomcat6有两种Transport的实现： 1) PooledMultiSender基于Java阻塞式IO，可以将一次将多个信息并发发送至其它节点，但一次只能传送给一个节点。2)PooledParallelSener基于Java非阻塞式IO，即NIO，可以一次发送多个信息至一个或多个节点。 15.5 Receiver 用于Channel定义某节点如何从其它节点的Sender接收复制数据，Tomcat6中实现的接收方式有两种BioReceiver和NioReceiver。 web.xml文件 web.xml基于Java Servlet规范，可被用于每一个Java servlet容器，通常有两个存放位置，$CATALINA_BASE/conf和每个Web应用程序（通常是WEB-INF/web.xml）。Tomcat在deploy一个应用程序时(包括重启或重新载入)，它首先读取conf/web.xml，而后读取WEB-INF/web.xml。这个文件一般不用修改。 tomcat-users.xml 关于用户角色、管理员的信息都在这个配置文件中。登录用户默认是注释掉的，把 去掉才能生效。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[ root@centos51 conf ]# cat tomcat-users.xml &lt;?xml version='1.0' encoding='utf-8'?&gt;&lt;!-- Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.--&gt;&lt;tomcat-users&gt;&lt;!-- NOTE: By default, no user is included in the "manager-gui" role required to operate the "/manager/html" web application. If you wish to use this app, you must define such a user - the username and password are arbitrary. It is strongly recommended that you do NOT use one of the users in the commented out section below since they are intended for use with the examples web application.--&gt;&lt;!-- NOTE: The sample user and role entries below are intended for use with the examples web application. They are wrapped in a comment and thus are ignored when reading this file. If you wish to configure these users for use with the examples web application, do not forget to remove the &lt;!.. ..&gt; that surrounds them. You will also need to set the passwords to something appropriate.--&gt;&lt;!-- &lt;role rolename="tomcat"/&gt; &lt;role rolename="role1"/&gt; &lt;user username="tomcat" password="&lt;must-be-changed&gt;" roles="tomcat"/&gt; &lt;user username="both" password="&lt;must-be-changed&gt;" roles="tomcat,role1"/&gt; &lt;user username="role1" password="&lt;must-be-changed&gt;" roles="role1"/&gt;--&gt;&lt;!-- &lt;role rolename="admin"/&gt; --&gt;&lt;!-- &lt;role rolename="admin-gui"/&gt; --&gt; # 定义了角色role和user，需要根据情况相应配置&lt;!-- &lt;role rolename="admin-script"/&gt; --&gt;&lt;!-- &lt;role rolename="manager"/&gt; --&gt;&lt;!-- &lt;role rolename="manager-gui"/&gt; --&gt;&lt;!-- &lt;role rolename="manager-script"/&gt; --&gt;&lt;!-- &lt;role rolename="manager-jmx"/&gt; --&gt;&lt;!-- &lt;role rolename="manager-status"/&gt; --&gt;&lt;!-- &lt;user name="admin" password="&lt;must-be-changed&gt;" roles="admin,manager,admin-gui,admin-script,manager-gui,manager-script,manager-jmx,manager-status" /&gt; --&gt;&lt;/tomcat-users&gt; manager tomcat自带的有一套web管理界面，如果是Yum安装的话需要单独安装 安装manager1234567[root@centos52 docs] yum install tomcat-admin-webapps[ root@centos51 webapps ]# ll /usr/share/tomcat/webapps/total 16drwxr-xr-x 14 root root 4096 Oct 21 20:25 docs drwxr-xr-x 5 root tomcat 4096 Oct 21 20:17 host-managerdrwxr-xr-x 5 root tomcat 4096 Oct 21 20:17 manager # manager 管理drwxr-xr-x 2 root root 4096 Oct 21 06:44 ROOT 配置管理用户 进入后台管理，需要配置响应角色和账号，不过未配置，登录时会有提示信息 编辑tomcat-users.xml 123[ root@centos51 tomcat ] vim conf/tomcat-users.xml&lt;role rolename="manager-gui" /&gt;&lt;user username="manager" password="123456" roles="manager-gui"/&gt; 配置虚拟主机 在server.xml介绍中，已经介绍了Host虚拟主机的配置，详细参数可查看帮助文档 http://tomcat.apache.org/tomcat-8.0-doc/virtual-hosting-howto.html 123&lt;Host name="local.tomcat.cn" appBase="webapps/local" unpackWARs="true" autoDeploy="true"&gt; &lt;Context path="/" docBase="ROOT" /&gt;&lt;/Host&gt; 123456[root@centos52 webapps]# tree local/local/└── ROOT └── index.jsp1 directory, 1 file 部署deployment deploy ：tomcat的应用文件和php不同，php文件只要放入到服务器对应位置就可以访问，但是tomcat需要deploy部署才能访问，也可以单独设置某个应用下线不能访问，这一点比较实用。部署的具体实现暂时还不清楚，大致过程是：将webapp的源文件旋转与目标目录、配置tomcat服务器能基于context.xml文件中定义的路径来访问此webapp，将其特有类通过class loader装载至tomcat。 tomcat部署有两种方式： 自动部署 ： auto deploy手动部署 ： 冷部署 : 把webapp复制到指定目录，重启tomcat热部署 ：在不停止tomcat的情况下进行部署 deploy ： 部署undeploy ： 反部署，停止webappstart ： 启动处理停止状态的webappstop ：停止应用，不在提供用户服务redeploy ：重新部署]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[varnish]]></title>
    <url>%2F2017%2F10%2F31%2Flinux%2Fvarnish%2F</url>
    <content type="text"><![CDATA[nginx本身也具有缓存功能，但是缓存功能不是它的强项，真正的缓存另有其人：varnish,varnish 是squid的升级版，主要应用于http得反向代理和http缓存来提供加速功能 简介 Varnish是一款高性能的开源HTTP加速器，一般用来和Nginx、Apache等搭配使用，组建一个高效率的Web服务器。Varnish的某个负责接受新HTTP连接的线程开始等待用户，如果有新的HTTP连接过来，它总负责接收，然后叫醒某个等待中的线程。 Worker线程读入HTTP请求的URI，查找已有的object，如果命中则直接返回并回复用户。如果没有命中，则需要将所请求的内容，从后端服务器中取过来，存到缓存中，然后再回复。Varnish根据所读到object的大小，创建相应大小的缓存文件。 缓存概念 程序具有局部性 时间局部性：过去访问的的数据，过一段时间可能再次访问到 空间局部性：一个数据被访问到，离它较近的数据也可能访问到 命中 ： 获取到缓存数据 命中率:hit/(hit+miss) 文档命中率 : 从文档个数进行衡量 字节命中率 : 从内容大小进行衡量 缓存对象 ： 生命周期 定期清理 缓存空间耗尽 ： LRU （最近最少使用原则） 缓存处理步骤 接收请求 -&gt; 解析请求 -&gt; 查询缓存 -&gt; 新鲜度检测 -&gt; 创建响应报文 -&gt; 发送响应 -&gt; 写入日志 缓存分类 代理式缓存 squid varnish 旁挂式缓存 新鲜度检测机制 过期时间检测 HTTP/1.0 Expires : expires:Mon, 06 Nov 2017 12:28:49 GMT HTTP/1.1 Cache-Control : max-age=600 有效性再验证 1、文件修改时间是否发送改变2、文件内容etag 标签校验 如果原始内容未改变，则仅响应首部（不附带body部分）,响应码304（Not Modified） 如果原始内容发生改变，则正常响应，响应码200 如果原始内容消失，则响应404，此时缓存中的cache object也应该被删除 条件式请求首部 If-Modified-Sine *自从某个时间是否发送改变 If-Unmodified-Sine 自从某个时间是否为发生改变 If-Math 是否匹配 If-None-Match *是否不匹配: 123456789101112131415161718192021222324252627Cache-Control = "Cache-Control" ":" 1#cache-directive cache-directive = cache-request-directive | cache-response-directive 请求报文用于通知缓存服务器如何使用缓存响应请求 cache-request-directive = "no-cache" (不要缓存的实体，要求现在从WEB服务器去取) | "no-store" (backup) | "max-age" "=" delta-seconds | "max-stale" [ "=" delta-seconds ] （可以接受过去的对象，但是过期时间必须小于 max-stale 值） | "min-fresh" "=" delta-seconds | "no-transform" | "only-if-cached" | cache-extension 响应报文用于通知缓存服务器如何存储上级服务器响应的内容 cache-response-directive = "public" | "private" [ "=" &lt;"&gt; 1#field-name &lt;"&gt; ] | "no-cache" [ "=" &lt;"&gt; 1#field-name &lt;"&gt; ] | "no-store" | "no-transform" | "must-revalidate" | "proxy-revalidate" | "max-age" "=" delta-seconds 公共缓存+私有缓存 | "s-maxage" "=" delta-seconds 公共缓存 | cache-extension 常见缓存服务常见的缓存服务开源解决方案 varnish squid 类似于nginx 和 apache的关系 varnish结构 Varnish主要运行两个进程：Management进程和Child进程(也叫Cache进程)。 management : 编译VCL并应用新配置、监控varnish、初始化varnish、CLI接口 Command line 命令行管理工具Child process mgmt 子进程管理initialisation 初始化 child/cache Commad line 线程 : 管理接口Storage/hashing 线程 ：缓存存储Log/stats 线程：日志管理线程Backend Communication 线程：管理后端主机线程Accept : 接受新的连接请求worker threads : 处理用户请求，child进程会为每个会话启动一个worker线程Object Expiry : 清理缓存中的过期对象vcl : varnish configuration language，基于”域” 的编程语言，花括号{}括起来， varnish 安装 在centos6 varnish还是2.1.5版本，过于老了，所有需要自己编译安装，在centos7上光盘自带varnish4版本，可以直接通过yum安装 123456789[root@centos72 ~]# yum search varnishLoaded plugins: fastestmirror, langpacksLoading mirror speeds from cached hostfile==== N/S matched: varnish ======collectd-varnish.x86_64 : Varnish plugin for collectdvarnish-docs.x86_64 : Documentation files for varnishvarnish-libs.x86_64 : Libraries for varnishvarnish-libs-devel.x86_64 : Development files for varnish-libsvarnish.x86_64 : High-performance HTTP accelerator varnish程序环境/etc/varnish/varnish.params ： 配置varnish服务进程的工作特性，例如监听的地址和端口，缓存机制；/etc/varnish/default.vcl ：配置各Child/Cache线程的缓存策略； 主程序： /usr/sbin/varnishdCLI interface： /usr/bin/varnishadmShared Memory Log交互工具： /usr/bin/varnishhist /usr/bin/varnishlog /usr/bin/varnishncsa /usr/bin/varnishstat /usr/bin/varnishtop测试工具程序： /usr/bin/varnishtestVCL配置文件重载程序： /usr/sbin/varnish_reload_vclSystemd Unit File： /usr/lib/systemd/system/varnish.service #varnish服务 /usr/lib/systemd/system/varnishlog.service # 日志持久的服务 /usr/lib/systemd/system/varnishncsa.service varnish 存储 Varnish支持多种不同类型的后端存储，这可以在varnishd启动时使用-s选项指定。后端存储的类型包括： file : 单个文件缓存，不支持持久机制，Key值缓存在内存，重启丢失,所有数据放在一个黑盒中（基于文件系统上单独的一个文件系统） malloc : 全部缓存在内存中 jemalloc persistent : 基于file文件的形式持久缓存,但可以持久存储数据(即重启varnish数据时不会被清除)；仍处于测试期； varnish配置配置varnish的三种应用1、varnishd应用程序的命令行参数 监听的socket，使用的存储类型等等 -p param=value -r param,param... 设定只读参数列表 /etc/varnish/varnish.params 2、-p 选项指定的参数 运行时参数：可在程序运行中，通过其CLI进行配置 3、vcl 配置缓存系统的缓存机制 通过vcl配置文件进行配置，先编译，后应用，依赖于c编译器 varnish日志 shared memory log : 共享内存日志大小一般默认为90MB，分为两部分，前一部分为计数器，后一部分为请求相关数据。 为了与系统的其它部分进行交互，Child进程使用了可以通过文件系统接口进行访问的共享内存日志(shared memory log)，因此，如果某线程需要记录信息，其仅需要持有一个锁，而后向共享内存中的某内存区域写入数据，再释放持有的锁即可。而为了减少竞争，每个worker线程都使用了日志数据缓存。共享内存日志大小一般为90M，其分为两部分，前一部分为计数器，后半部分为客户端请求的数据。varnish提供了多个不同的工具如varnishlog、varnishncsa或varnishstat等来分析共享内存日志中的信息并能够以指定的方式进行显示。 统计数据：计数器日志区域：日志记录 123456/usr/bin/varnishhist/usr/bin/varnishlog/usr/bin/varnishncsa/usr/bin/varnishstat/usr/bin/varnishtest/usr/bin/varnishtop varnish日志有一个单独的服务varnishlog，启动该服务，可以将日志写入日志文件。查看服务脚本可以看到，默认日志文件是/var/log/varnish/varnish.log。 1234567891011121314151617181920[root@centos72 ~]# systemctl status varnishlog.service ● varnishlog.service - Varnish Cache HTTP accelerator logging daemon Loaded: loaded (/usr/lib/systemd/system/varnishlog.service; disabled; vendor preset: disabled) Active: inactive (dead)[root@centos72 ~]# cat /usr/lib/systemd/system/varnishlog.service [Unit]Description=Varnish Cache HTTP accelerator logging daemonAfter=varnish.service[Service]RuntimeDirectory=varnishlogType=forkingPIDFile=/run/varnishlog/varnishlog.pidUser=varnishGroup=varnishExecStart=/usr/bin/varnishlog -a -w /var/log/varnish/varnish.log -D -P /run/varnishlog/varnishlog.pidExecReload=/bin/kill -HUP $MAINPID[Install]WantedBy=multi-user.target vcl Varnish Configuration Language (VCL)是varnish配置缓存策略的工具，它是一种基于“域”(domain specific)的简单编程语言，它支持有限的算术运算和逻辑运算操作、允许使用正则表达式进行字符串匹配、允许用户使用set自定义变量、支持if判断语句，也有内置的函数和变量等。使用VCL编写的缓存策略通常保存至.vcl文件中，其需要编译成二进制的格式后才能由varnish调用。事实上，整个缓存策略就是由几个特定的子例程如vcl_recv、vcl_fetch等组成，它们分别在不同的位置(或时间)执行，如果没有事先为某个位置自定义子例程，varnish将会执行默认的定义。 VCL策略在启用前，会由management进程将其转换为C代码，而后再由gcc编译器将C代码编译成二进制程序。编译完成后，management负责将其连接至varnish实例，即child进程。正是由于编译工作在child进程之外完成，它避免了装载错误格式VCL的风险。因此，varnish修改配置的开销非常小，其可以同时保有几份尚在引用的旧版本配置，也能够让新的配置即刻生效。编译后的旧版本配置通常在varnish重启时才会被丢弃，如果需要手动清理，则可以使用varnishadm的vcl.discard命令完成。 vcl状态引擎 在varnish里面同iptables里面的四表五链一样，可以配置什么文件缓存，什么文件不缓存等等，在vcl里面这里的钩子我们称为状态引擎 VCL函数 函数 作用 vcl_recv 用户请求成功接收后，遇到的第一个函数，可以在这里对请求的数据进行处理，并决定选取下一步的处理策略 vcl_fetch 从后端主机获取内容，并判断是否缓冲此内容，然后发送给客户端 vcl_hash 对URL进行hash，可以自定义hash键 vcl_pass 将请求直接发给backend，而不是用缓存中的数据 vcl_hit 在缓存中找到缓存对象时，要执行的操作 vcl_miss 在缓存中未找到对象时，要执行的操作 vcl_deliver 响应给客户端时调用此方法 vcl_pipe 不经由varnish直接将请求发往后端主机的时候调用，请求和内容不做任何改变，如同为客户端和backend建立一个管道 vcl_error 在varnishi上合成错误响应页时，调用此函数 vcl_backend_fetch 向后端主机发送请求前，调用此函数，可修改发往后端的请求； vcl_backend_response 获得后端主机的响应后，可调用此函数； vcl_backend_error 当从后端主机获取源文件失败时，调用此函数； vcl_init VCL加载时调用此函数，经常用于初始化varnish模块(VMODs) vcl_fini 当所有请求都离开当前VCL，且当前VCL被弃用时，调用此函数，经常用于清理varnish模块； 这些函数类似或就是回调函数，是Vanish调用用户逻辑的接口。 内置变量 req：The request object，请求到达时可用的变量 req.urlreq.httpreq.http.headerreq.restartserver.ipserver.hostnameserver.portreq.backend bereq：The backend request object，向后端主机请求时可用的变量 bereq.urlbereq.httpbereq.http.headerbereq.protobereq.connect_timeout obj：存储在内存中时对象属性相关的可用的变量 obj.responseobj.statusobj.http.headerobj.protoobj.ttlobj.hits beresp：The backend response object，从后端主机获取内容时可用的变量 beresp.responseberesp.http.headerberesp.ttlberesp.protoberesp.do_gzipberesp.do_gunzipberesp.backend.nameberesp.backend.ip resp：The HTTP response object，对客户端响应时可用的变量 resp.responseresp.protoresp.statusresp.http.header vcl语法 (1) VCL files start with vcl 4.0;(2) //, # and / foo / for comments; # 注释(3) Subroutines are declared with the sub keyword; 例如sub vcl_recv { …}；(4) No loops, state-limited variables（受限于引擎的内建变量）；(5) Terminating statements with a keyword for next action as argument of the return() function, i.e.: return(action)；用于实现状态引擎转换；(6) Domain-specific; The VCL Finite State Machine (1) Each request is processed separately;(2) Each request is independent from others at any given time;(3) States are related, but isolated;(4) return(action); exits one state and instructs Varnish to proceed to the next state;(5) Built-in VCL code is always present and appended below your own VCL; backend后端服务器 varnish是做缓存的，如果缓存服务器获取不到数据，需要去后台真实数据服务器获取，varnish可以配置后台服务器，也可以配置后端集群。 原始数据服务器 指明后端主机backend，修改default.vcl配置文件，指明backend， 1234backend default &#123; # 为后台backend起一个名称 .host = &quot;172.18.56.52&quot;; # 设定后台backend主机地址 .port = &quot;80&quot;; # 设定后台backend主机端口&#125; 动静分离 配置多个后台backend，根据请求文件分发到不同服务器。 123456789101112131415161718backend default &#123; .host = &quot;172.18.56.50&quot;; .port = &quot;80&quot;;&#125;backend webimg &#123; .host = &quot;172.18.56.51&quot;; .port = &quot;80&quot;;&#125;# 设定两个backend后端主机，如果是php文件指定到一台服务器，如果是其他文件指定到默认服务器sub vcl_recv &#123; if (req.url ~ &quot;(?i)\.php$&quot;)&#123; set req.backend_hint = webimg; &#125;else&#123; set req.backend_hint = default; &#125;&#125; varnish负载均衡 使用前需要导入 import directors; varnish有两个特殊的引擎： vcl_init：在处理任何请求之前要执行的vcl代码：主要用于初始化VMODs；vcl_fini ：所有的请求都已经结束，在vcl配置被丢弃时调用；主要用于清理VMODs； 1234567891011121314151617 import directors backend server1 &#123; .host = "172.18.56.51"; .port = "80"; &#125; backend server2 &#123; .host = "172.18.56.52"; .port = "80"; &#125;sub vcl_init&#123; new GROUP_NAME = directors.round_robin(); GROUP_NAME.add_backend(server1); GROUP_NAME.add_backend(server2);&#125;sub vcl_recv &#123; set req.backend.hint = GROUP_NAME.backend(); &#125; deliver添加头部判断是否缓存 在deliver添加一个Http头部，标识获取的资源是缓存的还是从backend获取的 1234567891011sub vcl_deliver &#123; # Happens when we have all the pieces we need, and are about to send the # response to the client. # # You can do accounting or modifying the final object here. if(obj.hits &gt; 0) &#123; set resp.http.X-cache = &quot;Hit via &quot; + server.ip; # 如果命中次数大于0 表示是缓存过的 &#125;else&#123; set resp.http.X-cache = &quot;Miss from &quot; + server.ip; &#125;&#125; 基于cookie的session sticky init{ new h = directors.hash(); h.add_backend(one, 1); # 添加权重 1 } sub vcl_recv { set req.backend_hint = h.backend(req.http.cookie); } 后端服务器状态监测1234567891011121314151617# BE Health Checkbackend BE_NAME &#123; .host = .port = .probe = &#123; .url = .timeout = .interval= .window= .threshold= &#125;&#125;.url 监测URL 默认为"/".interval 监测间隔时间.window 最近多少次监测.threshold 最近多少次成功算成功 varnish.params varnish.params是一个重要的文件，设置varnish的环境变量，如：监听端口、配置文件、缓存位置、缓存大小、用户等。 12345678910111213141516171819202122232425[root@centos73 development]# cat /etc/varnish/varnish.params # Varnish environment configuration description. This was derived from# the old style sysconfig/defaults settings# Set this to 1 to make systemd reload try to switch VCL without restart.RELOAD_VCL=1# Main configuration file. You probably want to change it.VARNISH_VCL_CONF=/etc/varnish/default.vcl # vcl配置文件# Default address and port to bind to. Blank address means all IPv4# and IPv6 interfaces, otherwise specify a host name, an IPv4 dotted# quad, or an IPv6 address in brackets.# VARNISH_LISTEN_ADDRESS=192.168.1.5VARNISH_LISTEN_PORT=6081 # 监听端口# Admin interface listen address and portVARNISH_ADMIN_LISTEN_ADDRESS=127.0.0.1 # 监听端口VARNISH_ADMIN_LISTEN_PORT=6082# Shared secret file for admin interfaceVARNISH_SECRET_FILE=/etc/varnish/secret# Backend storage specification, see Storage Types in the varnishd(5)# man page for details.VARNISH_STORAGE="malloc,256M" # 缓存位置和大小# User and group for the varnishd worker processesVARNISH_USER=varnishVARNISH_GROUP=varnish# Other options, see the man page varnishd(1)#DAEMON_OPTS="-p thread_pool_min=5 -p thread_pool_max=500 -p thread_pool_timeout=300" varnishd1234varnishd [-a address[:port]] [-b host[:port]] [-C] [-d] [-f config] [-F] [-g group] [-h type[,options]] [-i identity] [-l shl[,free[,fill]]] [-M address:port] [-n name] [-P file] [-p param=value] [-r param[,param...] [-s [name=]kind[,options]] [-S secret-file] [-T address[:port]] [-t ttl] [-u user] [-V] 选项解释 1234-a address[:port][,address[:port][...] 默认6081 和 6082管理端口 -d Enables debugging mode-f config vcl 配置文件-s [name=]type[,options] 指明使用哪一种存储机制： malloc[,size] 、 file[,path[,size[,granularity]]] 、 persistent,path,size varnishadm所有子命令 12345678910111213141516171819202122232425help200 help [&lt;command&gt;]ping [&lt;timestamp&gt;]auth &lt;response&gt;quitbannerstatusstartstopvcl.load &lt;configname&gt; &lt;filename&gt;vcl.inline &lt;configname&gt; &lt;quoted_VCLstring&gt;vcl.use &lt;configname&gt;vcl.discard &lt;configname&gt;vcl.listparam.show [-l] [&lt;param&gt;]param.set &lt;param&gt; &lt;value&gt;panic.showpanic.clearstorage.listvcl.show [-v] &lt;configname&gt;backend.list [&lt;backend_expression&gt;]backend.set_health &lt;backend_expression&gt; &lt;state&gt;ban &lt;field&gt; &lt;operator&gt; &lt;arg&gt; [&amp;&amp; &lt;field&gt; &lt;oper&gt; &lt;arg&gt;]... # 清理缓存ban.list purges清理缓存 varnish4清楚缓存方法主要有，通过varnishadm 管理，或vcl配置。其中vcl配置可以让客户端手动请求清楚缓存，以保证局部数据及时更新，而不用重启varnish服务器。 PURGE请求清理缓存12345678910111213141516#允许清除缓存IP集acl purge_ip&#123; "127.0.0.1"; "localhost";&#125;sub vcl_recv &#123; if(req.method ~ "PURGE")&#123; if(client.ip ~ purge_ip)&#123; return(purge);//清除缓存 &#125; return (synth(404,"Not Found")); &#125;&#125;sub vcl_purge&#123; return (synth(200,"success"));&#125; ban命令清理 缓存清理部分主要使用的是ban命令，在一些老的varnish版本里是purge命令。varnishadm ban相关的处理命令非常强大，支持正则和不同的域名进行区分，还支持按文件大小进行处理。 使用ban命令，需要调用varnishadm管理命令。查看varnishadm，可以进入管理命令行，再使用ban命令。 123456789101112131415161718192021222324252627282930313233343536[root@centos72 varnish]# varnishadm 200 -----------------------------Varnish Cache CLI 1.0-----------------------------Linux,3.10.0-514.el7.x86_64,x86_64,-smalloc,-smalloc,-hcritbitvarnish-4.0.4 revision 386f712Type 'help' for command list.Type 'quit' to close CLI session.help200 help [&lt;command&gt;]ping [&lt;timestamp&gt;]auth &lt;response&gt;quitbannerstatusstartstopvcl.load &lt;configname&gt; &lt;filename&gt;vcl.inline &lt;configname&gt; &lt;quoted_VCLstring&gt;vcl.use &lt;configname&gt;vcl.discard &lt;configname&gt;vcl.listparam.show [-l] [&lt;param&gt;]param.set &lt;param&gt; &lt;value&gt;panic.showpanic.clearstorage.listvcl.show [-v] &lt;configname&gt;backend.list [&lt;backend_expression&gt;]backend.set_health &lt;backend_expression&gt; &lt;state&gt;ban &lt;field&gt; &lt;operator&gt; &lt;arg&gt; [&amp;&amp; &lt;field&gt; &lt;oper&gt; &lt;arg&gt;]...ban.list 1、清理所有域名下download下的缓存1varnishadm -T 127.0.0.1:2000 ban.url /download/ 2、清理example.com域名下所有png文件的缓存 1varnishadm -T 127.0.0.1:2000 ban req.http.host == "example.com" &amp;&amp; req.url ~ ".png$" 3、以上是清理所有大于10MB的ogg文件 1varnishadm -T 127.0.0.1:2000 req.url !~ ".ogg$" &amp;&amp; obj.size &gt; 10MB 4、清理www.example.com还是example.com下的cookile值USERID=1663的所有缓存 1req.http.host ~ "^(?i)(www.)example.com$" &amp;&amp; obj.http.set-cookie ~ "USERID=1663" varnish管理1、varnishstat - varnish -1(数字) 列出所有field name -1 -f FILD_NAME 列出单个字段 -l 2、varnishtop - varnish log entry ranking -i 指定单个标签 -x 除开某个标签 完整示例# # This is an example VCL file for Varnish. # # It does not do anything by default, delegating control to the # builtin VCL. The builtin VCL is called when there is no explicit # return statement. # # See the VCL chapters in the Users Guide at https://www.varnish-cache.org/docs/ # and http://varnish-cache.org/trac/wiki/VCLExamples for more examples. # Marker to tell the VCL compiler that this VCL has been adapted to the # new 4.0 format. vcl 4.0; import directors; probe backend_healthcheck { # 创建健康监测 .url = /health.html; .window = 5; .threshold = 2; .interval = 3s; } backend web1 { # 创建后端主机 .host = "static1.lnmmp.com"; .port = "80"; .probe = backend_healthcheck; } backend web2 { .host = "static2.lnmmp.com"; .port = "80"; .probe = backend_healthcheck; } backend img1 { .host = "img1.lnmmp.com"; .port = "80"; .probe = backend_healthcheck; } backend img2 { .host = "img2.lnmmp.com"; .port = "80"; .probe = backend_healthcheck; } vcl_init { # 创建后端主机组，即directors new web_cluster = directors.random(); web_cluster.add_backend(web1); web_cluster.add_backend(web2); new img_cluster = directors.random(); img_cluster.add_backend(img1); img_cluster.add_backend(img2); } acl purgers { # 定义可访问来源IP "127.0.0.1"; "192.168.0.0"/24; } sub vcl_recv { if (req.request == "GET" &amp;&amp; req.http.cookie) { # 带cookie首部的GET请求也缓存 return(hash); } if (req.url ~ "test.html") { # test.html文件禁止缓存 return(pass); } if (req.request == "PURGE") { # PURGE请求的处理 if (!client.ip ~ purgers) { return(synth(405,"Method not allowed")); } return(hash); } if (req.http.X-Forward-For) { # 为发往后端主机的请求添加X-Forward-For首部 set req.http.X-Forward-For = req.http.X-Forward-For + "," + client.ip; } else { set req.http.X-Forward-For = client.ip; } if (req.http.host ~ "(?i)^(www.)?lnmmp.com$") { # 根据不同的访问域名，分发至不同的后端主机组 set req.http.host = "www.lnmmp.com"; set req.backend_hint = web_cluster.backend(); } elsif (req.http.host ~ "(?i)^images.lnmmp.com$") { set req.backend_hint = img_cluster.backend(); } return(hash); } sub vcl_hit { # PURGE请求的处理 if (req.request == "PURGE") { purge; return(synth(200,"Purged")); } } sub vcl_miss { # PURGE请求的处理 if (req.request == "PURGE") { purge; return(synth(404,"Not in cache")); } } sub vcl_pass { # PURGE请求的处理 if (req.request == "PURGE") { return(synth(502,"PURGE on a passed object")); } } sub vcl_backend_response { # 自定义缓存文件的缓存时长，即TTL值 if (req.url ~ "\.(jpg|jpeg|gif|png)$") { set beresp.ttl = 7200s; } if (req.url ~ "\.(html|css|js)$") { set beresp.ttl = 1200s; } if (beresp.http.Set-Cookie) { # 定义带Set-Cookie首部的后端响应不缓存，直接返回给客户端 return(deliver); } } sub vcl_deliver { if (obj.hits &gt; 0) { # 为响应添加X-Cache首部，显示缓存是否命中 set resp.http.X-Cache = "HIT from " + server.ip; } else { set resp.http.X-Cache = "MISS"; } }]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>varnish</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keepalived]]></title>
    <url>%2F2017%2F10%2F30%2Flinux%2Fkeepalived%2F</url>
    <content type="text"><![CDATA[keepalived是集群管理中保证集群高可用的一个服务软件，其功能类似于heartbeat，用来防止单点故障。 简介 Keepalived是Linux下一个轻量级的高可用解决方案，它与HeartBeat、RoseHA实现的功能类似，都可以实现服务或者网络的高可用，但是又有差别：HeartBeat是一个专业的、功能完善的高可用软件，它提供了HA软件所需的基本功能，比如心跳检测和资源接管，监测集群中的系统服务，在群集节点间转移共享IP地址的所有者等，HeartBeat功能强大，但是部署和使用相对比较麻烦；与HeartBeat相比，Keepalived主要是通过虚拟路由冗余来实现高可用功能，虽然它没有HeartBeat功能强大，但Keepalived部署和使用非常简单，所有配置只需一个配置文件即可完成。 工作原理 keepalived是以VRRP协议为实现基础的，VRRP全称Virtual Router Redundancy Protocol，即虚拟路由冗余协议。 虚拟路由冗余协议，可以认为是实现路由器高可用的协议，即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个master和多个backup，master上面有一个对外提供服务的vip（该路由器所在局域网内其他机器的默认路由为该vip），master会发组播，当backup收不到vrrp包时就认为master宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master。这样的话就可以保证路由器的高可用了。 keepalived主要有三个模块，分别是core、check和vrrp。core模块为keepalived的核心，负责主进程的启动、维护以及全局配置文件的加载和解析。check负责健康检查，包括常见的各种检查方式。vrrp模块是来实现VRRP协议的。 WatchDog ：负载监控checkers和VRRP进程的状况 VRRP Stack ：负载负载均衡器之间的失败切换FailOver，如果只用一个负载均稀器，则VRRP不是必须的。 Checkers ：负责真实服务器的健康检查healthchecking，是keepalived最主要的功能。 IPVS wrapper ：用户发送设定的规则到内核ipvs代码 Netlink Reflector ：用来设定vrrp的vip地址等。 keepalived配置前提HA Cluster配置前提 123456781、本机主机名与hosts中定义的主机名保持一致，要与hostname(uname -n)获得的名称保持一致 centos6 : /etc/sysconfig/network centos7 : hostnamectl set-hostname HOSTNAME 各节点要能互相解析主机名：一般通过Hosts文件进行解析，不依赖于外置网络和DNS2、各节点时间同步3、确保iptables和selinux关闭4、各节点之间的root用户可以基于密钥认证的ssh服务完成互相通信（对KA并非必须） VRRP VRRP将局域网内的一组路由器划分在一起，形成一个VRRP备份组，它在功能上相当于一台虚拟路由器，使用虚拟路由器号进行标识。以下使用虚拟路由器代替VRRP备份组进行描述。 虚拟路由器有自己的虚拟IP地址和虚拟MAC地址，它的外在表现形式和实际的物理路由器完全一样。局域网内的主机将虚拟路由器的IP地址设置为默认网关，通过虚拟路由器与外部网络进行通信。 虚拟路由器是工作在实际的物理路由器之上的。它由多个实际的路由器组成，包括一个Master路由器和多个Backup路由器。Master路由器正常工作时，局域网内的主机通过Master与外界通信。当Master路由器出现故障时，Backup路由器中的一台设备将成为新的Master路由器，接替转发报文的工作。 相关术语 虚拟路由器：由一个 Master 路由器和多个 Backup 路由器组成。主机将虚拟路由器当作默认网关。VRID：虚拟路由器的标识。有相同 VRID 的一组路由器构成一个虚拟路由器。Master 路由器：虚拟路由器中承担报文转发任务的路由器。Backup 路由器：Master 路由器出现故障时，能够代替 Master 路由器工作的路由器。虚拟 IP 地址：虚拟路由器的 IP 地址。一个虚拟路由器可以拥有一个或多个IP 地址。IP 地址拥有者：接口 IP 地址与虚拟 IP 地址相同的路由器被称为 IP 地址拥有者。虚拟 MAC 地址：一个虚拟路由器拥有一个虚拟 MAC 地址。虚拟 MAC 地址的格式为 00-00-5E-00-01-{VRID}。通常情况下，虚拟路由器回应 ARP 请求使用的是虚拟 MAC 地址，只有虚拟路由器做特殊配置的时候，才回应接口的真实 MAC 地址。优先级：VRRP 根据优先级来确定虚拟路由器中每台路由器的地位。非抢占方式：如果 Backup 路由器工作在非抢占方式下，则只要 Master 路由器没有出现故障，Backup 路由器即使随后被配置了更高的优先级也不会成为Master 路由器。抢占方式：如果 Backup 路由器工作在抢占方式下，当它收到 VRRP 报文后，会将自己的优先级与通告报文中的优先级进行比较。如果自己的优先级比当前的 Master 路由器的优先级高，就会主动抢占成为 Master 路由器；否则，将保持 Backup 状态。 广播地址 master以广播的方式通知其他 自己还在工作，为了保证master的广播是实时通知给其他slave，中间没有延迟，必须保证两边时间一致 广播地址(Broadcast Address)是专门用于同时向网络中所有工作站进行发送的一个地址。在使用TCP/IP 协议的网络中，主机标识段host ID 为全1 的IP 地址为广播地址，广播的分组传送给host ID段所涉及的所有计算机。 时间同步ntp : network time protocol linux服务器时间差别为什么很大？需要经常同步 ntp调整时间，不是直接将时间调整到时间服务器当前时间，如果这样的话，当前服务器会跳过中间一段时间，没有记录，这是不合适的，ntp的做法是：加快当前服务器时间的走速，尽快跟上时间服务器的时间 1[root@centos49 keepalived]# ntpdate 172.18.0.1 # 直接调整时间，跳过中间间隔时间 keepalived keepalived主要使用了VRRP协议，基本配置参数同VRRP。下面一起安装操作一遍。 安装123456789101112131415161718192021222324[root@centos49 keepalived]# yum install keepalived[root@centos49 keepalived]# yum info keepalivedLoaded plugins: fastestmirror, securityLoading mirror speeds from cached hostfileInstalled PackagesName : keepalivedArch : x86_64Version : 1.2.13Release : 5.el6_6Size : 625 kRepo : installedFrom repo : baseSummary : Load balancer and high availability serviceURL : http://www.keepalived.org/License : GPLv2+Description : Keepalived provides simple and robust facilities for load balancing : and high availability. The load balancing framework relies on the : well-known and widely used Linux Virtual Server (IPVS) kernel module : providing layer-4 (transport layer) load balancing. Keepalived : implements a set of checkers to dynamically and adaptively maintain : and manage a load balanced server pool according their health. : Keepalived also implements the Virtual Router Redundancy Protocol : (VRRPv2) to achieve high availability with director failover. keepalived配置 keepalived主要配置文件/etc/keepalived/keepalived.conf，可以通过man keepalived.conf查看说明 keepalived配置文件主要分为三部分 123456789GLOBAL CONFIGURATION # 全局配置 Global definitions Static routes/addressesVRRPD CONFIGURATION # VRRP路由实例配置 VRRP synchronization group(s)：vrrp同步组 VRRP instance(s)：即一个vrrp虚拟路由器LVS CONFIGURATION # lvs集群配置 Virtual server group(s) Virtual server(s)：ipvs集群的vs和rs 全局配置1234567891011121314151617global_defs # Block id &#123; notification_email # To: 异常发送至指定管理员邮箱，可以多个 &#123; admin@example1.com ... &#125; notification_email_from admin@example.com # From: from address that will be in header 发送人 smtp_server 127.0.0.1 # IP 邮件服务器地址 smtp_connect_timeout 30 # integer, seconds 超时时间 router_id my_hostname # string identifying the machine, 虚拟路由Id # (doesn’t have to be hostname). vrrp_mcast_group4 224.0.0.18 # optional, default 224.0.0.18 广播地址，可以不用配置，多个虚拟路由使用同一个广播地址容易冲突 vrrp_mcast_group6 ff02::12 # optional, default ff02::12 enable_traps # enable SNMP traps &#125; 实例配置1234567891011121314151617181920212223vrrp_instance VI_1 &#123; state MASTER # 状态 MASTER|BACKUP interface eth0 # 虚拟IP绑定在哪块网卡：interface for inside_network, bound by vrrp virtual_router_id 51 # 虚拟路由器ID priority 100 # 优先级0-255，数字越大，优先级越高 advert_int 1 # 主节点 每隔多次时间 发送心跳 1s authentication &#123; # VRRP 认证方式：无认证、简单字符认证、MD5认证 auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.200.16 # 虚拟IP地址 192.168.200.17 # &lt;IPADDR&gt;/&lt;MASK&gt; brd &lt;IPADDR&gt; dev &lt;STRING&gt; scope &lt;SCOPE&gt; label &lt;LABEL&gt; 192.168.200.18 # 192.168.200.18/24 dev eth2 label eth2:1 &#125; # nopreempt # 非抢占模式，默认抢占模式 定义通知脚本： notify_master &lt;STRING&gt;|&lt;QUOTED-STRING&gt;： # 当前节点成为主节点时触发的脚本 notify_master&quot;/etc/keepalived/notify.sh master&quot; notify_backup &lt;STRING&gt;|&lt;QUOTED-STRING&gt;： # 当前节点转为备节点时触发的脚本 notify_backup&quot;/etc/keepalived/notify.sh backup&quot; notify_fault &lt;STRING&gt;|&lt;QUOTED-STRING&gt;： # 当前节点转为“失败”状态时触发的脚本 notify_fault&quot;/etc/keepalived/notify.sh fault&quot; notify &lt;STRING&gt;|&lt;QUOTED-STRING&gt;： # 通用格式的通知触发机制，一个脚本可完成以上三种状态的转换时的通知&#125; vrrp示例 利用keepalived的vrrp_instance实现ip地址高可用性 1234567891011121314vrrp_instance VI_20 &#123; state MASTER interface eth1 virtual_router_id 20 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass imkindu &#125; virtual_ipaddress &#123; 192.168.56.20/16 dev eth1 label eth1:1 &#125;&#125; master会通过广播地址想其他backup多播，声明自己的权重 和 正在运行，如果backup接受不到master的广播，就会接管vip，并开始广播 12345[ root@centos50 keepalived ]# tcpdump -i eth1 -nn vrrptcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes20:44:21.895151 IP 192.168.56.49 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 20, prio 100, authtype simple, intvl 1s, length 2020:44:22.896702 IP 192.168.56.49 &gt; 224.0.0.18: VRRPv2, Advertisement, vrid 20, prio 100, authtype simple, intvl 1s, length 20 通知脚本1234567891011121314151617181920212223#!/bin/bash#contact='root@localhost'notify() &#123; mailsubject="$(hostname) to be $1, vip floating" mailbody="$(date +'%F %T'): vrrp transition, $(hostname) changed to be $1" echo "$mailbody" | mail -s "$mailsubject" $contact&#125;case $1 in master) notify master ;; backup) notify backup ;; fault) notify fault ;; *) echo "Usage: $(basename $0) &#123;master|backup|fault&#125;" exit 1 ;;esac 同步组 lvs+keepalived里面 如果Lvs 使用NAT模式，real server 需要指向director的DIP 如果配置了keepalived，VIP迁移了，dip也需要迁移，这里就需要使用到 同步组 virtual_server fwmark int 一起调度 12345678910111213141516vrrp_sync_group VG_1 &#123; group &#123; VI_1 # vip和dip一起漂移 VI_2 &#125;&#125;vrrp_instance VI_1 &#123; eth0 vip&#125;vrrp_instance VI_2 &#123; eth1 dip&#125; 多个虚拟路由，多播地址不能全局指定，都用一个多播地址，就混乱了 脚本控制优先级 keepalived调用外部的辅助脚本进行资源监控，并根据监控的结果状态能实现优先动态调整 vrrp_script:自定义资源监控脚本，vrrp实例根据脚本返回值，公共定义，可被多个实例调用，定义在vrrp实例之外 12345vrrp_script chk_down &#123; script "[[ -f /etc/keepalived/down ]] &amp;&amp; exit 1 || exit 0" # 定义脚本，如果down文件存在，退出1，并权重减2 interval 1 # 间隔时间 weight -20 # 如何失败执行，权重减20&#125; track_script:调用vrrp_script定义的脚本去监控资源，定义在实例之内，调用事先定义的vrrp_script 123track_script &#123; chk_down&#125; keepalived 日志123456789101112131415[ root@centos50 keepalived ]# cat /etc/sysconfig/keepalived # Options for keepalived. See `keepalived --help' output and keepalived(8) and# keepalived.conf(5) man pages for a list of all options. Here are the most# common ones :## --vrrp -P Only run with VRRP subsystem.# --check -C Only run with Health-checker subsystem.# --dont-release-vrrp -V Dont remove VRRP VIPs &amp; VROUTEs on daemon stop.# --dont-release-ipvs -I Dont remove IPVS topology on daemon stop.# --dump-conf -d Dump the configuration data.# --log-detail -D Detailed log messages.# --log-facility -S 0-7 Set local syslog facility (default=LOG_DAEMON)#KEEPALIVED_OPTIONS="-D" 指定keepalived日志通过修改keepalived的参数选项 -S 自定义日志 1KEEPALIVED_OPTIONS="-D -S 3" 修改rsyslog配置12[ root@centos50 keepalived ]# vim /etc/rsyslog.conflocal3.* /var/log/keepalived.log 查看日志1234567891011[ root@centos50 keepalived ]# tail -f /var/log/keepalived.log Oct 30 21:17:00 centos50 Keepalived_vrrp[24305]: VRRP_Instance(VI_20) Entering BACKUP STATEOct 30 21:17:00 centos50 Keepalived_healthcheckers[24304]: Configuration is using : 7679 BytesOct 30 21:17:00 centos50 Keepalived_healthcheckers[24304]: Using LinkWatch kernel netlink reflector...Oct 30 21:17:00 centos50 Keepalived_vrrp[24305]: VRRP sockpool: [ifindex(2), proto(112), unicast(0), fd(10,11)]Oct 30 21:17:01 centos50 Keepalived_vrrp[24305]: VRRP_Instance(VI_21) Transition to MASTER STATEOct 30 21:17:02 centos50 Keepalived_vrrp[24305]: VRRP_Instance(VI_21) Entering MASTER STATEOct 30 21:17:02 centos50 Keepalived_vrrp[24305]: VRRP_Instance(VI_21) setting protocol VIPs.Oct 30 21:17:02 centos50 Keepalived_vrrp[24305]: VRRP_Instance(VI_21) Sending gratuitous ARPs on eth0 for 172.18.56.21Oct 30 21:17:02 centos50 Keepalived_healthcheckers[24304]: Netlink reflector reports IP 172.18.56.21 addedOct 30 21:17:07 centos50 Keepalived_vrrp[24305]: VRRP_Instance(VI_21) Sending gratuitous ARPs on eth0 for 172.18.56.21 KeepAlived支持IPVS1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071man keepalived.confVirtual server(s) A virtual_server can be a declaration of one ofdelay_loop &lt;INT&gt;： 检查后端服务器的时间间隔lb_algorr|wrr|lc|wlc|lblc|sh|dh： 定义调度方法lb_kind NAT|DR|TUN： 集群的类型persistence_timeout &lt;INT&gt;： 持久连接时长protocol TCP： 服务协议，仅支持TCPsorry_server&lt;IPADDR&gt; &lt;PORT&gt;： 所有RS故障时，备用服务器地址virtualhost &lt;STRING&gt; 定义虚拟主机real_server&lt;IPADDR&gt; &lt;PORT&gt;&#123; weight &lt;INT&gt; RS权重 notify_up&lt;STRING&gt;|&lt;QUOTED-STRING&gt; RS上线通知脚本 notify_down&lt;STRING&gt;|&lt;QUOTED-STRING&gt; RS下线通知脚本 HTTP_GET|SSL_GET|TCP_CHECK|SMTP_CHECK|MISC_CHEC K &#123; ... &#125;：定义当前主机的健康状态检测方法&#125; HTTP_GET|SSL_GET # real server 健康状态检测机制 &#123; # A url to test # can have multiple entries here url &#123; #eg path / , or path /mrtg2/ path &lt;STRING&gt; # 检测路径 # healthcheck needs status_code # or status_code and digest # Digest computed with genhash # eg digest 9b3a0c85a887a256d6939da88aabd8cd digest &lt;STRING&gt; # 检测校验码 # status code returned in the HTTP header # eg status_code 200 status_code &lt;INT&gt; # 返回状态 &#125; # number of get retry nb_get_retry &lt;INT&gt; # delay before retry delay_before_retry &lt;INT&gt; # 每次重试之前间隔时间 # ======== generic connection options # Optional IP address to connect to. # The default is real server’s IP connect_ip &lt;IP ADDRESS&gt; # 指明IP地址 # Optional port to connect to if not # The default is real server’s port connect_port &lt;PORT&gt; # Optional interface to use to # originate the connection bindto &lt;IP ADDRESS&gt; # 从本机哪个地址发送检测 # Optional source port to # originate the connection from bind_port &lt;PORT&gt; # Optional connection timeout in seconds. # The default is 5 seconds connect_timeout &lt;INTEGER&gt; # 连接超时时间 # Optional fwmark to mark all outgoing # checker pakets with fwmark &lt;INTEGER&gt; # Optional random delay to begin initial check for # maximum N seconds. # Useful to scatter multiple simultaneous # checks to the same RS. Enabled by default, with # the maximum at delay_loop. Specify 0 to disable warmup &lt;INT&gt; &#125; #HTTP_GET|SSL_GET]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ldirectord高可用负载]]></title>
    <url>%2F2017%2F10%2F21%2Flinux%2Fldirectord%2F</url>
    <content type="text"><![CDATA[为了从主Director将LVS负载均衡资源故障转移到备用Director，并从集群中自动移除节点，我们需要使用ldirectord程序，这个程序在启动时自动建立IPVS表，然后监视集群节点的健康情况，在发现失效节点时将其自动从IPVS表中移除。 工作原理 ldirectord守护进程通过向每台真实服务器真实IP（RIP）上的集群资源发送访问请求来实现对真实服务器的监控，这对所有类型的LVS集群都是成立的：LVS-DR，LVS-NAT和LVS-TUN。正常情况下，为每个Director上的VIP地址运行一个ldirectord守护进程，当真实服务器不响应运行在Director上的ldirectord守护进程时，ldirectord守护进程运行适当的ipvsadm命令将VIP地址从IPVS表中移除。（以后，当真实服务器回到在线状态时，ldirectord使用适当的ipvsadm命令将真实服务器重新添加到IPVS表中） 为了监视web集群内的真实服务器，ldirectord守护进程使用HTTP协议向每个真实服务器请求一个专用的web页面，如果真实服务器是健康的，Director知道将从真实服务器接收到什么内容，如果从真实服务器返回应答字串或web页面的时间太长，或根本没有返回任何内容，或返回的内容不是预期的，Director就知道该真实服务器出错了，并从IPVS表中将这个真实服务器移除。 准备下载ldirectordldirectord-centos 6版本下载地址 http://download.opensuse.org/repositories/network:/ha-clustering:/Stable/CentOS_CentOS-6/x86_64/ 安装因为ldirectord依赖其他安装包，最好使用yum安装解决依赖性 1yum localinstall ldirectord-centos6-3.9.6-0rc1.1.1.x86_64.rpm 查看包列表文件12345678910111213[ root@centos10x ~ ]# rpm -ql ldirectord /etc/ha.d/etc/had.d/ldirectord.cf # 主配置文件，需自己添加，可以拷贝配置模板文件/etc/ha.d/resource.d/etc/ha.d/resource.d/ldirectord/etc/init.d/ldirectord # 服务脚本/etc/logrotate.d/ldirectord/usr/lib/ocf/resource.d/heartbeat/ldirectord/usr/sbin/ldirectord # 命令/usr/share/doc/ldirectord-3.9.6/usr/share/doc/ldirectord-3.9.6/COPYING/usr/share/doc/ldirectord-3.9.6/ldirectord.cf # 模板配置文件 /usr/share/man/man8/ldirectord.8.gz 配置 ldirectord的主要配置文件在ldirectord.cf文件 全局配置12345678910111213[ root@centos10x ha.d ]# cat ldirectord.cf # Global Directiveschecktimeout=3 # 超时时间checkinterval=1 # 检测间隔时间 #fallback=127.0.0.1:80 # 当RS全部故障，由此生效#fallback6=[::1]:80autoreload=yes # 修改配置文件自动生效#logfile="/var/log/ldirectord.log" # 日志文件#logfile="local0"#emailalert="admin@x.y.z"#emailalertfreq=3600#emailalertstatus=allquiescent=no 简单http虚拟服务配置示例123456789101112131415# Sample for an http virtual service # 简单http虚拟服务器示例virtual=172.18.56.100:80 real=172.18.56.50:80 gate 1 # real server : gate表示dr模型 后面接数字表示 权重 real=172.18.56.51:80 gate 1 fallback=127.0.0.1:80 gate service=http scheduler=rr # 调度算法 #persistent=600 #netmask=255.255.255.255 protocol=tcp # 协议 checktype=negotiate checkport=80 # 检测端口 request="index.html" # 检测文件 receive="Test Page" # 检测回应内容 virtualhost=www.x.y.z # 虚拟网址 重启服务 1234[ root@centos10x ha.d ]# service ldirectord restartRestarting ldirectord... success[ root@centos10x ha.d ]# service ldirectord statusldirectord for /etc/ha.d/ldirectord.cf is running with pid: 3941 检查 1234567[ root@centos10x ha.d ]# ipvsadm -L -nIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 172.18.56.100:80 wrr -&gt; 172.18.56.50:80 Route 1 0 2 -&gt; 172.18.56.51:80 Route 1 0 3 1234imkindu@ubuntu:~$ curl 172.18.56.100 192.168.56.50imkindu@ubuntu:~$ curl 172.18.56.100 192.168.56.51 fallback自动断开恢复 ldirectord当某台real server断开，或者全部断开后，会自动从ipvsadm列表中剔除，当恢复时，自动加入。全部断开时，会返回配置的fallback页面。 断开Real server112[ root@centos50 www ]# service httpd stopStopping httpd: [ OK ] 查看directory状态123456[ root@centos10x ha.d ]# ipvsadm -L -nIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 172.18.56.100:80 wrr -&gt; 172.18.56.51:80 Route 1 0 0 real server1会自动从ipvsadm中去除 去除所有的real server,查看directory情况123456[ root@centos10x ha.d ]# ipvsadm -L -nIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 172.18.56.100:80 wrr -&gt; 127.0.0.1:80 Local 1 0 0 此时客户端请求，返回的就是fallback123192.168.56.51imkindu@ubuntu:~$ curl 172.18.56.100 192.168.56.10 mysql集群环境配置1234567891011121314#Sample configuration for a MySQL virtual service.#virtual = 192.168.10.74:3306# real=sql01-&gt;sql03:3306 gate 10# fallback=127.0.0.1:3306# service=mysql# scheduler=wrr# #persistent=600# #netmask=255.255.255.255# protocol=tcp# checktype=negotiate# login="readuser"# passwd="genericpassword"# database="portal"# request="SELECT * FROM link"]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>lvs</tag>
        <tag>ipvsadm</tag>
        <tag>ldirectord</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php-mongo和php-mongodb扩展]]></title>
    <url>%2F2017%2F10%2F11%2Fphp%2F%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85php-mongo%E5%92%8Cphp-mongodb%E6%8B%93%E5%B1%95%2F</url>
    <content type="text"><![CDATA[php要使用mongodb需要安装php对应的mongo扩展包，这一篇将介绍php-mongo和php-mongodb的相关简介和差别。并编译安装两个拓展。 php-mongo和php-mongodb差别 php-mongo和php-mongodb都是php对应mongo的扩展接口，在原本的php5.6等版本上，我们都是习惯用的php-mongo这个扩展，使用语法简单，但是在最新的PHP7版本上，现在都是使用的php-mongodb这个扩展，同时还加入了mongodb新版的特性。 php-mongo这个扩展现在已经废弃了，不过bug和security 方面的问题还会继续修复，这个可以查看pecl的官网信息。 http://pecl.php.net/package/mongo http://pecl.php.net/package/mongodb 安装PHP-mongo扩展 1.首先上http://pecl.php.net上面搜索mongo,得到下载地址 12wget http://pecl.php.net/get/mongo-1.6.11.tgztar zxvf ./mongo-1.6.11.tgz 2.解压进入,phpize后进行编译 1234cd ./mongo-1.6.11phpize #有可能要写全phpize的地址./configure --with-php-config=/usr/local/php/bin/php-configmake &amp;&amp; make install 3.编译成功后出现: 12[ root@centos50 mongo-1.6.16 ]# make installInstalling shared extensions: /usr/local/php5.6/lib/php/extensions/no-debug-zts-20131226/ 4.得其地址写入php.ini 1extension = mongo.so #有可能要写全mongo.so的路径,也就是上面的提示 5.安装完以后,看phpinfo()中有没有这个扩展,有就表示安装成功; 编译安装PHP-mongodb扩展 1.首先上http://pecl.php.net上面搜索mongo,得到下载地址 12wget http://pecl.php.net/get/mongodb-1.3.11.tgztar zxvf ./mongodb-1.3.11.tgz 2.解压进入,phpize后进行编译 1234cd ./mongodb-1.3.11phpize #有可能要写全phpize的地址./configure --with-php-config=/usr/local/php/bin/php-configmake &amp;&amp; make install 3.编译成功后出现: 12[ root@centos50 mongo-1.3.16 ]# make installInstalling shared extensions: /usr/local/php5.6/lib/php/extensions/no-debug-zts-20131226/ 4.得其地址写入php.ini 1extension = mongodb.so #有可能要写全mongodb.so的路径,也就是上面的提示 5.安装完以后,看phpinfo()中有没有这个扩展,有就表示安装成功;]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php-mongo</tag>
        <tag>php-mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql_secure_installation]]></title>
    <url>%2F2017%2F09%2F22%2Fmysql%2Fmysql_secure_installation%2F</url>
    <content type="text"><![CDATA[mysql安装完成后，系统自带了几个用户和匿名用户可以登录，但是为了安全考虑，我们需要执行一遍mysql_secure_installation安全向导初始化一下我们的数据库。 123456789101112MariaDB [mysql]&gt; select User,Host,Password from user;+------+-----------+----------+| User | Host | Password |+------+-----------+----------+| root | localhost | || root | centos69 | || root | 127.0.0.1 | || root | ::1 | || | localhost | || | centos69 | |+------+-----------+----------+6 rows in set (0.00 sec) 刚安装完mysql，我们直接执行mysql命令就可以登录，默认使用的是root@localhost 空密码登录的，安全的第一件事就是给root这个超级霸主设置密码，使用mysql_secure_installation可以初始化让我们设置密码，还能限制root从远程登录。 文件位置 初始化脚本mysql_secure_installation放在哪里呢？默认在安装目录下的/bin目录下。 1&gt; /usr/local/mysql/bin/mysql_secure_installation 初始化 再来看一下这个脚本帮我们做了什么事，我们执行一遍 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[ root@centos69 bin ]# ./mysql_secure_installation ./mysql_secure_installation: line 393: find_mysql_client: command not foundNOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB SERVERS IN PRODUCTION USE! PLEASE READ EACH STEP CAREFULLY!In order to log into MariaDB to secure it, we&apos;ll need the currentpassword for the root user. If you&apos;ve just installed MariaDB, andyou haven&apos;t set the root password yet, the password will be blank,so you should just press enter here.####################################################################Enter current password for root (enter for none): # 询问当前root密码，默认为空OK, successfully used password, moving on...Setting the root password ensures that nobody can log into the MariaDBroot user without the proper authorisation.####################################################################Set root password? [Y/n] Y # 设置root密码New password: Re-enter new password: Password updated successfully!Reloading privilege tables.. ... Success!By default, a MariaDB installation has an anonymous user, allowing anyoneto log into MariaDB without having to have a user account created forthem. This is intended only for testing, and to make the installationgo a bit smoother. You should remove them before moving into aproduction environment.####################################################################Remove anonymous users? [Y/n] y # 移除匿名账号 ... Success!Normally, root should only be allowed to connect from &apos;localhost&apos;. Thisensures that someone cannot guess at the root password from the network.####################################################################Disallow root login remotely? [Y/n] n # 禁止root远程登录 ... skipping.By default, MariaDB comes with a database named &apos;test&apos; that anyone canaccess. This is also intended only for testing, and should be removedbefore moving into a production environment.####################################################################Remove test database and access to it? [Y/n] n # 删除test数据库 ... skipping.Reloading the privilege tables will ensure that all changes made so farwill take effect immediately.####################################################################Reload privilege tables now? [Y/n] y # 刷新授权表 ... Success!Cleaning up...All done! If you&apos;ve completed all of the above steps, your MariaDBinstallation should now be secure.Thanks for using MariaDB! 效果]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql安全</tag>
        <tag>mysql初始化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二进制安装mariadb-5.5.57]]></title>
    <url>%2F2017%2F09%2F21%2Fmysql%2FCentOS-6.9%E5%AE%89%E8%A3%85%E4%BA%8C%E8%BF%9B%E5%88%B6Mariadb5.5.57%2F</url>
    <content type="text"><![CDATA[mariadb官方网站上提供了三种不同形式的程序包：源码包版、程序包管理器版、和二进制版，如下图所示。二进制版是由官方编译好的绿色版，相比源码包版安装更简单，比起程序包管理器版又多一点自由度，算是二者的折中方案。另外要注意它依赖于glibc，需要注意glibc的版本。 准备 1、确认glibc 12[ root@centos69 etc ]# rpm -qa glibcglibc-2.12-1.209.el6.x86_64 2、关闭iptables和selinux 1234[ root@centos69 etc ]# getenforcePermissive[ root@centos69 etc ]# service iptables statusiptables: Firewall is not running. 3、创建mysql系统用户 1useradd -r mysql 4、下载二进制mariadb包 点击进入mariadb官网 5、解压至目录/usr/local/ /usr/local/mysql是默认指定安装目录 1tar -xvf mariadb-5.5.57-linux-x86_64.tar.gz -C /usr/local/ 6、创建软链接mysql 123ln -s mariadb-5.5.57/ mysqldrwxr-xr-x. 12 root root 4096 Sep 11 12:58 mariadb-5.5.57lrwxrwxrwx. 1 root root 15 Sep 11 12:58 mysql -&gt; mariadb-5.5.57/ 安装 mysql的进程默认是使用mysql用户，所以mysql目录以及数据库目录data都应该给与mysql用户对应权限 1、修改目录属主属组 1[ root@centos69 mysql ]# chown -R mysql:mysql /usr/local/mysql/ 2、创建数据库目录，如果不单独指定则默认使用mysql下面的data目录 1[ root@centos69 mysql ]# mkdir -p /var/mysql/data 3、更改数据库目录的属主属组 1[ root@centos69 mysql ]# chown -R mysql:mysql /var/mysql/data 4、安装数据库 初始化数据库，脚本在scripts目录下的mysql_install_db 1[ root@centos69 data ] scripts/mysql_install_db --user=mysql --datadir=/var/mysql/data/ 查看数据库存放目录，一个数据库就是一个目录 12345[ root@centos69 mysql ]# ll /var/mysql/data/total 28744drwx------. 2 mysql mysql 4096 Sep 11 13:13 mysqldrwx------. 2 mysql mysql 4096 Sep 11 13:13 performance_schemadrwx------. 2 mysql mysql 4096 Sep 11 13:13 test 配置 二进制安装后，需要自己添加service脚本、chkconfig开机启动、man帮助手册等 1、将bin目录路径导入PATH环境变量 1234vim /etc/profile.d/mysql.shexport PATH=/usr/local/mysql/bin:$PATH# 启动生效exec bash 2、创建头文件符号链接 12cd /usr/local/include/ln -s ../mysql/include/mysql/ mysql 3、将man路径导入系统man手册 12vim /etc/man.configMANPATH /usr/local/mysql/man 4、服务脚本拷贝至/etc/rc.d/init.d 123cd /usr/local/mysqlcp support-files/mysql.server /etc/rc.d/init.d/mysqldchkconfig --add mysqld 5、复制模板配置文件至/etc/目录 通用二进制格式安装的服务程序其配置文件查找次序： /etc/my.cnf --&gt; /etc/mysql/my.cnf --&gt; --default-extra-file=/PATH/TO/CONF_FILE --&gt; ~/.my.cnf 1cp support-files/my-large.cnf /etc/my.cnf 6、更改配置文件，关闭域名反解 123vim /etc/my.cnf[mysqld]后面加一句skip-name-resolve=TRUE 7、更改配置文件，指定data目录 12[mysqld]datadir=/var/mysql/data 启动 启动mysql查看进程 12345[ root@centos69 ~ ]# service mysqld restartShutting down MySQL... SUCCESS! Starting MySQL.170911 14:29:57 mysqld_safe Logging to &apos;/var/mysql/data/centos69.err&apos;.170911 14:29:58 mysqld_safe Starting mysqld daemon with databases from /var/mysql/data. SUCCESS! 1234567891011121314151617[ root@centos69 data ]# service mysqld status SUCCESS! MySQL running (11118)[ root@centos69 data ]# netstat -antpActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN 11118/mysqld tcp 0 0 0.0.0.0:111 0.0.0.0:* LISTEN 1466/rpcbind tcp 0 0 0.0.0.0:37941 0.0.0.0:* LISTEN 1523/rpc.statd tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1754/sshd tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1844/master tcp 0 0 172.18.56.69:22 172.18.252.123:53848 ESTABLISHED 10704/sshd tcp 0 0 172.18.56.69:22 172.18.252.123:51284 ESTABLISHED 6298/sshd tcp 0 0 :::111 :::* LISTEN 1466/rpcbind tcp 0 0 :::56402 :::* LISTEN 1523/rpc.statd tcp 0 0 :::22 :::* LISTEN 1754/sshd tcp 0 0 :::23 :::* LISTEN 1765/xinetd tcp 0 0 ::1:25 :::* LISTEN 1844/master 匿名登录mysql 1234567[ root@centos69 ~ ]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 2Server version: 5.5.57-MariaDB MariaDB ServerCopyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.MariaDB [(none)]&gt;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql二进制安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译安装mariadb-5.5.57]]></title>
    <url>%2F2017%2F09%2F21%2Fmysql%2F%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85mariadb-5.5.57%2F</url>
    <content type="text"><![CDATA[编译安装mariadb-5.5.57，mysql5.5之后mysql编译基于cmake，所以需要填编译安装cmake. cmake的重要特性之一是其独立于源码(out-of-source)的编译功能，即编译工作可以在另一个指定的目录中而非源码目录中进行，这可以保证源码目录不受任何一次编译的影响，因此在同一个源码树上可以进行多次不同的编译，如针对于不同平台编译。 安装cmake 跨平台编译器 12345# tar xf cmake-2.8.8.tar.gz# cd cmake-2.8.8# ./bootstrap# gmake # gmake install cmake查看编译选项1cmake . -LH # . 表示当前目录 -LH 编译完后打印出选项 cmake指定编译选项的方式不同于make，其实现方式对比如下： 12./configure cmake ../configure --help cmake . -LH or ccmake . 编译查看编译选项123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354[ root@centos50 mariadb-5.5.57 ]# cmake . -LH-- Running cmake version 2.8.8-- MariaDB 5.5.57-- Packaging as: mariadb-5.5.57-Linux-x86_64-- Could NOT find Curses (missing: CURSES_LIBRARY CURSES_INCLUDE_PATH) CMake Error at cmake/readline.cmake:85 (MESSAGE): Curses library not found. Please install appropriate package, remove CMakeCache.txt and rerun cmake.On Debian/Ubuntu, package name is libncurses5-dev, on Redhat and derivates it is ncurses-devel.Call Stack (most recent call first): cmake/readline.cmake:196 (FIND_CURSES) CMakeLists.txt:351 (MYSQL_CHECK_READLINE)-- Configuring incomplete, errors occurred!-- Cache values// Choose the type of build, options are: None(CMAKE_CXX_FLAGS or CMAKE_C_FLAGS used) Debug Release RelWithDebInfo MinSizeRelCMAKE_BUILD_TYPE:STRING=RelWithDebInfo// install prefixCMAKE_INSTALL_PREFIX:PATH=/usr/local/mysql # 编译安装位置// Set to true if this is a community buildCOMMUNITY_BUILD:BOOL=ON # 社区// Enable profilingENABLED_PROFILING:BOOL=ON # Query 诊断分析工具// Enable gcov (debug, Linux builds only)ENABLE_GCOV:BOOL=OFF # 是否包含 Gcov 支持// Installation directory layout. Options are: STANDALONE (as in zip or tar.gz installer) RPM DEB SVR4INSTALL_LAYOUT:STRING=STANDALONE # 选择预定义的安装// default MySQL data directoryMYSQL_DATADIR:PATH=/usr/local/mysql/data # 数据存放位置// Allow linking with GPLv2-incompatible system libraries. Only set it you never plan to distribute the resulting binariesNOT_FOR_DISTRIBUTION:BOOL=OFF// PATH to MySQL TMP dir. Defaults to the P_tmpdir macro in &lt;stdio.h&gt;TMPDIR:PATH= # 临时目录// Enable address sanitizerWITH_ASAN:BOOL=OFF// Options are: none complex allWITH_EXTRA_CHARSETS:STRING=all # 额外的字符集，包括 all// Build with jemalloc (possible values are &apos;yes&apos;, &apos;no&apos;, &apos;auto&apos;)WITH_JEMALLOC:STRING=auto// Compile with tcp wrappers supportWITH_LIBWRAP:BOOL=OFF// Use bundled readlineWITH_READLINE:BOOL=OFF # 使用捆绑的readline// Use safemalloc memory debugger. Will result in slower execution. Options are: ON OFF AUTO.WITH_SAFEMALLOC:STRING=AUTO// Options are: no bundled yes(prefer os library if present otherwise use bundled) system(use os library)WITH_SSL:STRING=no # 是否支持SSL// Compile MySQL with unit testsWITH_UNIT_TESTS:BOOL=ON// Valgrind instrumentationWITH_VALGRIND:BOOL=OFF// Which zlib to use (possible values are &apos;bundled&apos; or &apos;system&apos;)WITH_ZLIB:STRING=system # 是否支持Zlib 编译安装mariadb安装依赖包1yum install ncurses-devel 添加用户12# groupadd -r mysql# useradd -g mysql -r -d /mydata/data mysql 编译12345678910111213141516171819202122# tar xf mysql-5.5.33.tar.gz # cd mysql-5.5.33# cmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mariadb-5.5/ \-DMYSQL_DATADIR=/usr/local/mariadb-5.5/data \-DSYSCONFDIR=/etc \-DMYSQL_USER=mysql \-DMYSQL_TCP_PORT=3306 \-DWITH_INNOBASE_STORAGE_ENGINE=1 \-DWITH_ARCHIVE_STORAGE_ENGINE=1 \-DWITH_BLACKHOLE_STORAGE_ENGINE=1 \-DWITH_READLINE=1 \-DWITH_SSL=system \-DWITH_SSL=bundled \-DWITH_ZLIB=system \-DWITH_LIBWRAP=0 \-DMYSQL_UNIX_ADDR=/tmp/mysql.sock \-DDEFAULT_CHARSET=utf8 \-DDEFAULT_COLLATION=utf8_general_ci-DWITH_DEBUG=0 \-DEXTRA_CHARSETS=all \# make # make install 如果想清理此前的编译所生成的文件，则需要使用如下命令： 12make cleanrm CMakeCache.txt 编译选项解释 指定安装文件的安装路径时常用的选项： 123-DCMAKE_INSTALL_PREFIX=/usr/local/mysql-DMYSQL_DATADIR=/data/mysql-DSYSCONFDIR=/etc 默认编译的存储引擎包括：csv、myisam、myisammrg和heap。若要安装其它存储引擎，可以使用类似如下编译选项： 1234-DWITH_INNOBASE_STORAGE_ENGINE=1-DWITH_ARCHIVE_STORAGE_ENGINE=1-DWITH_BLACKHOLE_STORAGE_ENGINE=1-DWITH_FEDERATED_STORAGE_ENGINE=1 若要明确指定不编译某存储引擎，可以使用类似如下的选项： 12345-DWITHOUT_&lt;ENGINE&gt;_STORAGE_ENGINE=1比如：-DWITHOUT_EXAMPLE_STORAGE_ENGINE=1-DWITHOUT_FEDERATED_STORAGE_ENGINE=1-DWITHOUT_PARTITION_STORAGE_ENGINE=1 如若要编译进其它功能，如SSL等，则可使用类似如下选项来实现编译时使用某库或不使用某库： 1234-DWITH_READLINE=1-DWITH_SSL=system-DWITH_ZLIB=system-DWITH_LIBWRAP=0 其它常用的选项： 12345678-DMYSQL_TCP_PORT=3306-DMYSQL_UNIX_ADDR=/tmp/mysql.sock-DENABLED_LOCAL_INFILE=1-DEXTRA_CHARSETS=all-DDEFAULT_CHARSET=utf8-DDEFAULT_COLLATION=utf8_general_ci-DWITH_DEBUG=0-DENABLE_PROFILING=1 编译安装后续步骤同二进制安装 初始化数据库 配置文件my.cnf mysql环境变量 service服务脚本]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>编译安装mariadb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[存储引擎]]></title>
    <url>%2F2017%2F09%2F21%2Fmysql%2F%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[MySql也是客户/服务器系统并且是单进程多线程架构的数据库。MySql区别于其它数据库系统的一个重要特点是支持插入式存储引擎。 什么是存储引擎 存储引擎说白了就是如何存储数据、如何为存储的数据建立索引和如何更新、查询数据等技术的实现方法。因为在关系数据库中数据的存储是以表的形式存储的，所以存储引擎也可以称为表类型（即存储和操作此表的类型）。 在Oracle 和SQL Server等数据库中只有一种存储引擎，所有数据存储管理机制都是一样的。而MySql数据库提供了多种存储引擎。用户可以根据不同的需求为数据表选择不同的存储引擎，用户也可以根据自己的需要编写自己的存储引擎。 mariadb架构 存储引擎分类 查看所有引擎 : show engines; 123456789101112131415MariaDB [(none)]&gt; show engines;+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+| Engine | Support | Comment | Transactions | XA | Savepoints |+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+| MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO || CSV | YES | CSV storage engine | NO | NO | NO || PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO || BLACKHOLE | YES | /dev/null storage engine (anything you write to it disappears) | NO | NO | NO || MyISAM | YES | MyISAM storage engine | NO | NO | NO || MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO || ARCHIVE | YES | Archive storage engine | NO | NO | NO || FEDERATED | YES | FederatedX pluggable storage engine | YES | NO | YES || InnoDB | DEFAULT | Percona-XtraDB, Supports transactions, row-level locking, and foreign keys | YES | YES | YES || Aria | YES | Crash-safe tables with MyISAM heritage | NO | NO | NO |+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+ 引擎详解MyISAM支持全文索引（fulltext index）、压缩、空间函数（GIS），但是不支持事务，也不支持行级锁 锁粒度：表级锁 崩溃后无法安全恢复，后来改进为Aria 支持崩溃后安全恢复 修复需要手工或自动修复，但是可能丢失数据 索引：非聚集索引 延迟更新索引键： 压缩表：把表压缩后存放 使用场景：只读（或者写较少）、表较小（可接受长时间进行恢复操作） 每个表对应三个文件 不支持事务，也不支持外键、行级锁，访问速度快。 每个MyIsam在磁盘上存储为3个文件，其中文件名和表名都相同，拓展名分别为： .frm 存储表定义 .MYD (MYData) 存储数据 .MYI (MYIndex) 存储索引 123-rw-rw----. 1 mysql mysql 8586 Sep 15 23:17 my_db.frm-rw-rw----. 1 mysql mysql 20 Sep 15 23:18 my_db.MYD-rw-rw----. 1 mysql mysql 2048 Sep 15 23:18 my_db.MYI 数据文件和索引文件可以放置在不同的目录，平均分配IO，获取更快的速度。要指定数据文件和索引文件的路径，需要在创建表的时候通过DATA DIRECTORY和INDEX DIRECTORY语句指定，文件路径需要使用绝对路径。 MyISAM：这种引擎是mysql最早提供的。这种引擎又可以分为静态MyISAM、动态MyISAM 和压缩MyISAM三种： 静态MyISAM：如果数据表中的各数据列的长度都是预先固定好的，服务器将自动选择这种表类型。因为数据表中每一条记录所占用的空间都是一样的，所以这种表存取和更新的效率非常高。当数据受损时，恢复工作也比较容易做。 动态MyISAM：如果数据表中出现varchar、xxxtext或xxxBLOB字段时，服务器将自动选择这种表类型。相对于静态MyISAM，这种表存储空间比较小，但由于每条记录的长度不一，所以多次修改数据后，数据表中的数据就可能离散的存储在内存中，进而导致执行效率下降。同时，内存中也可能会出现很多碎片。因此，这种类型的表要经常用optimize table 命令或优化工具来进行碎片整理。 压缩MyISAM：以上说到的两种类型的表都可以用myisamchk工具压缩。这种类型的表进一步减小了占用的存储，但是这种表压缩之后不能再被修改。另外，因为是压缩数据，所以这种表在读取的时候要先时行解压缩。 innodb 处理大量的短期事务，数据存储于“表空间”(table space)中， 1、所有InnoDB表的数据和索引放置于同一个表空间中 .idb 表空间文件 InnoDB Data,可能存在多个 -rw-rw----. 1 mysql mysql 98304 Sep 15 20:33 user.ibd .frm 表格式定义文件 2、每个表单独使用一个表空间存储表的数据和索引 innodb_file_per_table 配置 innodb_file_per_table=ON 数据存储：表空间并发：基于MVCC，支持所有的四个隔离级别，默认界别为REPEATABLE READ，间隙锁防止 幻读索引：聚集所有、辅助索引性能：预计操作、自适应hash、插入缓存区来提升性能备份：支持热备 锁粒度：行级锁 InnoDB存储引擎提供了具有提交、回滚和崩溃恢复能力的事务安全。但是对比MyISAM的存储引擎，InnoDB写的处理效率差一些并且会占用更多的磁盘空间以保留数据和索引。 外键约束 MySQL支持外键的存储引擎只有InnoDB，在创建外键的时候，父表必须有对应的索引，子表在创建外键的时候也会自动创建对应的索引。 在创建索引的时候，可以指定在删除、更新父表时，对子表进行的相应操作，包括restrict、cascade、set null和no action。其中restrict和no action相同，是指限制在子表有关联的情况下，父表不能更新；casecade表示父表在更新或删除时，更新或者删除子表对应的记录；set null 则表示父表在更新或者删除的时候，子表对应的字段被set null。 当某个表被其它表创建了外键参照，那么该表对应的索引或主键被禁止删除。 可以使用set foreign_key_checks=0;临时关闭外键约束，set foreign_key_checks=1;打开约束。 memory memory使用存在内存中的内容来创建表。每个MEMORY表实际对应一个磁盘文件，格式是.frm。MEMORY类型的表访问非常快，因为它到数据是放在内存中的，并且默认使用HASH索引，但是一旦服务器关闭，表中的数据就会丢失，但表还会继续存在。 默认情况下，memory数据表使用散列索引，利用这种索引进行“相等比较”非常快，但是对“范围比较”的速度就慢多了。因此，散列索引值适合使用在”=”和”&lt;=&gt;”的操作符中，不适合使用在”&lt;”或”&gt;”操作符中，也同样不适合用在order by字句里。如果确实要使用”&lt;”或”&gt;”或betwen操作符，可以使用btree索引来加快速度。 存储在MEMORY数据表里的数据行使用的是长度不变的格式，因此加快处理速度，这意味着不能使用BLOB和TEXT这样的长度可变的数据类型。VARCHAR是一种长度可变的类型，但因为它在MySQL内部当作长度固定不变的CHAR类型，所以可以使用。 mysql的临时表都是memory, CSV以普通csv格式文件，逗号分隔 MRG_MYISAM将多个myisam存储引擎合并为一个虚拟表 BKACKHOLE 黑洞 ，类似于/dev/nullPERFORMANCE_SCHEMA伪存储引擎，其内部数据只有在Mysql启动起来才存在，关闭后消失 ARCHIVE 归档只支持Insert 和 select操作，支持行级锁和专用缓存区，不支持事务]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql存储引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DHCP]]></title>
    <url>%2F2017%2F09%2F16%2Flinux%2FDHCP%2F</url>
    <content type="text"><![CDATA[DHCP（Dynamic Host Configuration Protocol，动态主机配置协议）是一个局域网的网络协议，使用UDP协议工作， 主要有两个用途：给内部网络或网络服务供应商自动分配IP地址，给用户或者内部网络管理员作为对所有计算机作中央管理的手段。DHCP主要2个端口，其中UDP67为DHCP Server的服务端口，UDP68为DHCP Client的服务端口； 简介 dhcp的前身是bootp ： BOOTP（Bootstrap Protocol，引导程序协议）是一种引导协议，基于IP/UDP协议，也称自举协议，是DHCP协议的前身。BOOTP用于无盘工作站的局域网中，可以让无盘工作站从一个中心服务器上获得IP地址。通过BOOTP协议可以为局域网中的无盘工作站分配动态IP地址，这样就不需要管理员去为每个用户去设置静态IP地址。 BOOTP使用UDP报文传输，并使用保留端口号67（BOOTP服务器）和68（BOOTP客户端）工作。使用BOOTP协议的时候，一般包括Bootstrap Protocol Server（自举协议服务端）和Bootstrap Protocol Client（自举协议客户端）两部分。 BOOTP的一般工作流程就是BOOTP客户端和BOOTP服务器之间的交互，其流程如下： 由BOOTP启动代码来启动BOOTP客户端，这个时候BOOTP客户端还没有IP地址。 BOOTP客户端使用广播形式的IP地址255.255.255.255向网络中发出IP地址查询要求。 运行BOOTP协议的服务器接收到这个请求，会根据请求中提供的MAC地址找到BOOTP客户端，并发送一个含有IP地址、服务器IP地址、网关等信息的回应帧。 BOOTP客户端会根据该回应帧来获得自己的IP地址并通过专用文件服务器（如TFTP服务器）下载启动镜像文件，模拟成磁盘来完成启动。 DHCP由来 BOOTP实现了对于主机地址的静态配置，根据主机mac地址，分配一个静态ip。而DHCP实现了动态配置。 我们熟知的DHCP协议是从BOOTP的基础上发展而来的，它们都是主机配置协议，都可以大大减少管理员的工作量。BOOTP可以看成是简单版的DHCP，是对主机的静态配置，而DHCP可以依据一些策略对主机进行动态配置。BOOTP用于无盘工作站的启动和配置，而DHCP更适用于客户端接入变化的网络，即客户端接入时间、接入地点不固定。 在DHCP中为了实现动态配置引入了租约的概念，申请IP地址使用时长，时间到了续租或者重新分配。 DHCPRARP：MAC-&gt;IPARP：IP-&gt;MAC 八种报文DHCP共有八种报文 DHCP DISCOVER：客户端到服务器DHCP OFFER ：服务器到客户端DHCP REQUEST：客户端到服务器DHCP ACK ：服务器到客户端DHCP NAK：服务器到客户端,通知用户无法分配合适的IP地址DHCP DECLINE ：客户端到服务器，指示地址已被使用DHCP RELEASE：客户端到服务器，放弃网络地址和取消剩余的租约时间DHCP INFORM：客户端到服务器,客户端如果需要从DHCP服务器端获取更为详细的配置信息，则发送Inform报文向服务器进行请求 DHCP流程 1、dhcp discover 在本网络内询问谁是dhcp服务器，广播方式2、dhcp offer：dhcp服务器 分配ip/netmask gateway给客户端3、dhcp request 请求使用报文，广播告诉使用哪一台dhcp server提供的ip，其他的dhcp server回收ip 多台dhcp服务器响应，先到先得，决定使用哪个如果分配的ip已被使用 4、dhcp server ack 确认，广播方式 续租 client : dhcp request 单播server : dhcp ack 继续租server : dhcp nak 不继续给租了，就需要discover 广播重新找地址了 安装配置 下面，来看看DHCP如何安装配置 包列表 查看一下dhcp包里包含哪里文件 1234567891011121314151617181920[ root@centos69 ~ ]# rpm -ql dhcp/etc/dhcp/etc/dhcp/dhcpd.conf # dhcp 配置文件/etc/dhcp/dhcpd6.conf # ipv6 dhcp配置文件/etc/openldap/schema/dhcp.schema/etc/portreserve/dhcpd/etc/rc.d/init.d/dhcpd # 脚本/etc/rc.d/init.d/dhcpd6 # IPV6 dhcp服务器服务脚本/etc/rc.d/init.d/dhcrelay # 中继器服务脚本/etc/rc.d/init.d/dhcrelay6/etc/sysconfig/dhcpd/etc/sysconfig/dhcpd6/etc/sysconfig/dhcrelay/etc/sysconfig/dhcrelay6/usr/bin/omshell/usr/sbin/dhcpd # 服务器/usr/sbin/dhcrelay # 中继器/var/lib/dhcpd/var/lib/dhcpd/dhcpd.leases/var/lib/dhcpd/dhcpd6.leases 配置文件示例 配置 都要以 分号&quot;;&quot;结尾 否则语法错误 subnet 地址池分配IP filename “vmunix.passacaglia”; 指明引导文件名称和路径 next-server # server-name 指明主机地址 从哪台主机加载引导文件 123456789101112131415161718192021222324252627282930313233343536373839[ root@centos69 ~ ]# cat /usr/share/doc/dhcp*/dhcpd.conf.sample# 全局配置default-lease-time 600; # 默认租约期限 单位秒max-lease-time 7200; # 最大租约期限option domain-name "example.org"; # 搜索域，ping www 自动补全# 可选项 可以定义在全局，也可以定义在subnet中，也可以放在Host中# 作用范围越小的，优先级越高option domain-name-servers ns1.example.org, ns2.example.org; # 域名服务器# option domain-name-servers 172.18.0.1 写成ip地址# 地址池# 当前主机所在网络，subnet 10.254.239.32 netmask 255.255.255.224 &#123; range dynamic-bootp 10.254.239.40 10.254.239.60; # 地址池，起始地址，结束地址 option broadcast-address 10.254.239.31; # 广播地址 option routers rtr-239-32-1.example.org; # 网关，告诉客户端网关地址（IP地址）&#125;# 保留地址（某些主机固定分配地址）host passacaglia &#123; hardware ethernet 0:0:c0:5d:bd:95; filename "vmunix.passacaglia"; # 指明引导文件名称和路径 server-name "toccata.fugue.com";&#125;# 超级“作用域”（多个作用域，一个服务器分配）shared-network 224-29 &#123; subnet 10.17.224.0 netmask 255.255.255.0 &#123; option routers rtr-224.example.org; &#125; subnet 10.0.29.0 netmask 255.255.255.0 &#123; option routers rtr-29.example.org; &#125; pool &#123; allow members of "foo"; range 10.17.224.10 10.17.224.250; &#125; pool &#123; deny members of "foo"; range 10.0.29.10 10.0.29.230; &#125;&#125; dhclient dhclient - Dynamic Host Configuration Protocol Client 能启动，只能启动一次 dhclient -d # 前台查看 dhclient 监听在 udp 68号端口 查看某个ip分配给谁了 cat /var/lib/dhcpd/dhcpd.leases * 租约文件，记录地址分配结果 1234567891011121314151617181920212223[ imkindu@centos69x ~ ]$ cat /var/lib/dhcpd/dhcpd.leases# The format of this file is documented in the dhcpd.leases(5) manual page.# This lease file was written by isc-dhcp-4.1.1-P1server-duid "\000\001\000\001!P z\000\014)\374\276\323";lease 192.168.10.5 &#123; # 分配的IP starts 6 2017/09/16 17:51:07; # 开始时间 ends 0 2017/09/17 05:51:07; # 到期时间 cltt 6 2017/09/16 17:51:07; binding state active; next binding state free; hardware ethernet 00:0c:29:fc:3f:56; # Mac地址&#125;lease 192.168.10.6 &#123; starts 6 2017/09/16 18:06:13; ends 0 2017/09/17 06:06:13; cltt 6 2017/09/16 18:06:13; binding state active; next binding state free; hardware ethernet 00:0c:29:fc:3f:56;&#125; 检查语法 service dhcpd configtest 12[ root@centos69x CentOS7 ]# service dhcpd configtestSyntax: OK dnsmasq12345678910111213141516171819202122[ root@centos69 ~ ]# yum info dnsmasqLoaded plugins: fastestmirror, securityLoading mirror speeds from cached hostfileInstalled PackagesName : dnsmasqArch : x86_64Version : 2.48Release : 17.el6Size : 293 kRepo : installedFrom repo : mediaSummary : A lightweight DHCP/caching DNS serverURL : http://www.thekelleys.org.uk/dnsmasq/License : GPLv2 or GPLv3Description : Dnsmasq is lightweight, easy to configure DNS forwarder and DHCP server. : It is designed to provide DNS and, optionally, DHCP, to a small network. : It can serve the names of local machines which are not in the global : DNS. The DHCP server integrates with the DNS server and allows machines : with DHCP-allocated addresses to appear in the DNS with names configured : either in each host or in a central configuration file. Dnsmasq supports : static and dynamic DHCP leases and BOOTP for network booting of diskless : machines.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>DHCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运维自动化之系统安装]]></title>
    <url>%2F2017%2F09%2F15%2Flinux%2F%E8%87%AA%E5%8A%A8%E5%8C%96%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[刚学习Linux时，安装一个虚拟机操作系统，都是光盘启动，手动选项各个配置项，时区、主机名、网络等等，装个系统要等半小时。运维自动化就是将人从这些繁杂的事情中解放出来，利用kickstart实现自动化系统安装，现在就来看看是怎么实现的。 光盘内容 首先让我们来看看，我们用光盘启动安装一个系统，那么光盘里面到底有什么呢？ 光盘isolinux是核心目录，里面有我们装系统所使用的内核、引导菜单等 12345678910111213[ root@centos69 isolinux ]# lltotal 45306-r--r--r--. 1 root root 2048 Aug 9 20:26 boot.cat # 类似bootloader-r--r--r--. 1 root root 84 Mar 29 02:19 boot.msg-r--r--r--. 1 root root 321 Mar 29 02:19 grub.conf -r--r--r--. 1 root root 41587792 Mar 29 02:19 initrd.img # 虚拟伪文件系统,是ramfs (先cpio，再gzip压缩)-r--r--r--. 1 root root 24576 Mar 29 02:19 isolinux.bin # stage2 第二阶段-r--r--r--. 1 root root 923 Mar 29 02:19 isolinux.cfg # 菜单-r--r--r--. 1 root root 183012 Mar 29 02:19 memtest-r--r--r--. 1 root root 151230 Mar 29 02:19 splash.jpg # 菜单背景图片-r--r--r--. 1 root root 2215 Aug 9 20:26 TRANS.TBL-r--r--r--. 1 root root 163728 Mar 29 02:19 vesamenu.c32 # 启动菜单背景界面（cfg第一行）-r-xr-xr-x. 1 root root 4274992 Mar 29 02:19 vmlinuz # 内核，只有4M，还是很小的 isolinux.cfg 首先，我们来看看配置文件isolinux.cfg 我们开启看到的光盘菜单界面就是这个配置文件配置的，这里面配置了背景图片、菜单列表、菜单对应内核和参数、默认选择时间、标题等，一一对应。涉及到的文件也都在isolinux这个文件夹中。 1234567891011121314151617181920212223242526272829303132333435[ root@centos69 isolinux ]# cat isolinux.cfg default vesamenu.c32 # 启动菜单背景风格#prompt 1timeout 600 # 倒计时，十分之一display boot.msgmenu background splash.jpg # 背景图片menu title Welcome to CentOS 6.9! # 标题menu color border 0 #ffffffff #00000000menu color sel 7 #ffffffff #ff000000menu color title 0 #ffffffff #00000000menu color tabmsg 0 #ffffffff #00000000menu color unsel 0 #ffffffff #00000000menu color hotsel 0 #ff000000 #ffffffffmenu color hotkey 7 #ffffffff #ff000000menu color scrollbar 0 #ffffffff #00000000label linux # 菜单选项 ^ 是可以快捷键字母选中菜单 menu label ^Install or upgrade an existing system menu default kernel vmlinuz # 加载内核 append initrd=initrd.img # 向内核传递参数label vesa menu label Install system with ^basic video driver # 基本图形显卡驱动 kernel vmlinuz append initrd=initrd.img nomodesetlabel rescue menu label ^Rescue installed system kernel vmlinuz append initrd=initrd.img rescuelabel local menu label Boot from ^local drive localboot 0xfffflabel memtest86 menu label ^Memory test kernel memtest append - 内核参数 再来看，不同菜单有什么区别呢？区别在于append后面对内核传递不同参数,多传递了一个rescue就代表救援模式。 但是咱们使用光盘启动，光盘是只读的，我们如何自定义使用哪些参数呢？其实，在我们进入到菜单界面后，根据启动界面提示Press [Tab] to edit options使用tab键，我们可以编辑内核参数。这里是编辑当前选中的菜单。 另外还有一种办法编辑菜单，而这种方式是完全自定义，类似新增一个菜单。esc 可以切换不同菜单，填写label名，进入不同菜单,也可以在后面接其他参数。 boot : linux rescue （菜单 参数） 文字安装 默认使用的图形界面anaconda，我们可以字符界面安装，向内核传递text参数 boot : linux text 自动化安装 下面就是重头戏了，让我们来看一下，我们是如何一步步实现，自动化安装系统的。 askmethod 利用aksmethod手动指定安装源 利用光盘安装时，安装用到的程序包默认是光盘里面自带的Packages,其实是可以不走光盘安装，而走网络安装的yum源，将程序包从光盘中提出来了。 boot : linux askmethod 之后就会让我们选择安装源的位置，可以本地光盘，本地硬盘，NFS，URL 后续，就和原先光盘安装一样，实现了第一步，安装源的分离。 kickstart 回顾，我们anaconda图形化安装过程，分为三个阶段 安装前配置阶段 安装过程使用的语言 键盘类型 安装目标存储设备 Basic Storage：本地磁盘 特殊设备：iSCSI 设定主机名 配置网络接口 时区 管理员密码 设定分区方式及MBR的安装位置 创建一个普通用户 选定要安装的程序包 安装阶段 在目标磁盘创建分区，执行格式化操作等 将选定的程序包安装至目标位置 安装bootloader和initramfs 图形模式首次启动 iptables selinux core dump 重头戏来了，这么我们手动选择项，是否可以先写入一个配置文件，当安装系统时，自动帮我们选择呢？答案 就是我们的kickstart文件了，在我们用光盘安装完系统后，在root的家目录，就会生成这个anaconda-ks.cfg kickstart 现在就让我们来看看kickstart文件里面包含了哪些选项、又是怎么才能生成这个文件的。 ks.cfg配置 我们先来看一个用光盘anaconda图形化安装后生成了的ks.cfg配置文件里面包含哪些选项 ks.cfg包含三大段： 命令段：指明各种安装前配置，如键盘类型等 程序包段：指明要安装的程序包组或程序包，不安装的程序包等 %packages@group_namepackage-package%end 脚本段： %pre: 安装前脚本运行环境：运行于安装介质上的微型Linux环境%post: 安装后脚本运行环境：安装完成的系统 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[ root@centos69 ~ ]# cat anaconda-ks.cfg #================================================脚命令段=========================================# Kickstart file automatically generated by anaconda.#version=DEVELinstall # 安装cdrom lang en_US.UTF-8 # 语言keyboard us # 键盘network --onboot no --device eth0 --bootproto dhcp --noipv6rootpw --iscrypted $6$OL4YFm8thjoyIQV3$OFs0x4jfVc9wH6O32l1SzrLAqoYG5mmDKCIQHPjfczjW/GUIw.H9QDOWsdJeg4xHRcE1qDfrrbY82azrsnNHm/firewall --service=sshauthconfig --enableshadow --passalgo=sha512selinux --enforcing # selinuxtimezone Asia/Shanghai # 时区bootloader --location=mbr --driveorder=sda --append="crashkernel=auto rhgb quiet"# The following is the partition information you requested# Note that any partitions you deleted are not expressed# here so unless you clear all partitions first, this is# not guaranteed to work# Clear the Master Boot Recordzerombr # 清除引导#clearpart --none # 清除分区表#part /boot --fstype=ext4 --size=200 # 分区信息#part / --fstype=ext4 --size=40960#part /app --fstype=ext4 --size=5120#part swap --size=2000repo --name="CentOS" --baseurl=cdrom:sr0 --cost=100#================================================程序包段========================================%packages@base # 包组名@core @debugging@development@server-policy # -package 表示排除，不安装（制定包组里面某个包不安装）@workstation-policy # @ 开头表示包组python-dmidecode # 一般的包sgpiodevice-mapper-persistent-datasystemtap-client%end#================================================脚本段=========================================%postecho -e 'Mage Education Learning Services\nhttp://www.magedu.com\n' &gt;&gt; /etc/issuesed -i '1,$s@id:[0-9]:initdefault:@id:3:initdefault:@g' /etc/inittab[ ! -d /root/.ssh ] &amp;&amp; mkdir /root/.ssh &amp;&amp; chmod og=--- /root/.ssh# set hostsecho '172.16.0.1 server.magelinux.com server' &gt;&gt; /etc/hosts%end 这些内容不就是我们用图形化安装时，手动选择的选项嘛。 system-config-kickstart ks.cfg这么多配置选项，手动写，Oh my god，我可记不住，还是让我们请出system-config-kickstart工具来帮我们自动生成吧。但是，这个工具是图形化的，这就意味着，我们需要请出图形化系统来帮我们完成啦，最小化安装的字符界面可完成不了。 yum install system-config-kickstart # 安装system-config-kickstart 现在来看看他是怎么帮我们生产ks.cfg文件的 1[root@centos69x fs] system-config-kickstart # 调用system-config-kickstart命令 我擦，这不就是我们装系统时，所有的选择项嘛。在这里提前将所有的选项都配置完，保存就可以了。就会生成ks.cfg文件，里面包含所有的配置项。 ksvalidator ks.cfg也许咱还不小心查看一下，或者是别人发给我的呢，我得先检查一下语法是否有问题啊，再看看配置项是否正确啊。来，请出ksvalidator帮我们检查语法格式。 咱先故意去掉最后的%end 的结束符号%，用ksvalidator帮我们检查一下，看嘛：so easy [root@centos69x fs]# ksvalidatory ks.cfg 1234[root@centos69x fs]# ksvalidator 50-ks.cfg File uses a deprecated option or command.%packages does not end with %end. This syntax has been deprecated. It may be removed from future releases, which will result in a fatal error from kickstart. Please modify your kickstart file to use this updated syntax. ks.cfg安装系统 boot : linux ks=ftp://172.18.56.10/pub/fs/50-ks.cfg 菜单编辑指明kickstart文件的位置：ks= DVD drive: ks=cdrom:/PATH/TO/KICKSTART_FILEHard drive: ks=hd:device:/directory/KICKSTART_FILEHTTP server: ks=http://host:port/path/to/KICKSTART_FILEFTP server: ks=ftp://host:port/path/to/KICKSTART_FILEHTTPS server: ks=https://host:port/path/to/KICKSTART_FILENFS server:ks=nfs:host:/path/to/KICKSTART_FILE 剩下的事情就是：我擦，我解放啦！ U盘启动 前面咱们将程序包分离出来了，但是我们要启动安装程序，还是需要一个引导，咱们可以将这个引导做在U盘里，就不用随身携带一个光盘了。 制作U盘，总体思路比较简单，将光盘的isolinux里面的文件，利用mkisofs打包成一个可引导镜像即可。 12345678910111213141516[root@centos69x centos69]# tree.└── isolinux ├── bg.jpg ├── boot.cat ├── boot.msg ├── grub.conf ├── initrd.img ├── isolinux.bin ├── isolinux.cfg ├── isolinux.cfg.bak ├── memtest ├── splash.jpg ├── TRANS.TBL ├── vesamenu.c32 └── vmlinuz 注意：以上命令的路径都是相对于光盘的根，而和工作目录无关（这句话还是不太懂，下面两个都可以，应该是-b指定的根目录） mkisofs选项 -o 指定映像文件的名称。-b 指定在制作可开机光盘时所需的开机映像文件。-c 制作可开机光盘时，会将开机映像文件中的no-eltorito-catalog 全部内容作成一个文件。-no-emul-boot 非模拟模式启动。-boot-load-size 4 设置载入部分的数量-boot-info-table 在启动的图像中现实信息-R 或-rock 使用Rock RidgeExtensions-J 或-joliet 使用Joliet 格式的目录与文件名称-v 或-verbose 执行时显示详细的信息-T 或-translation-table 建立文件名的转换表，适用于不支持Rock Ridge Extensions 的系统上 12# 进入了isolinuxmkisofs -R -J -T -v --no-emul-boot --boot-load-size 4 --boot-info-table -V "CentOS 6.9 imkindu boot" -b isolinux.bin -c boot.cat -o /root/CentOS6.9-imkindu.iso isolinux/ 12# 在外层目录 centos69mkisofs -R -J -T -v --no-emul-boot --boot-load-size 4 --boot-info-table -V "CentOS 6.9 imkindu boot" -b isolinux/isolinux.bin -c boot.cat -o /root/CentOS6.9-imkindu.iso ../centos69/ 利用ISO包，安装一个系统试试。 问题 1、centos7 system-config-kickstart配置安装程序时，如果使用的程序源是我们自己设定的，有个奇葩的问题，需要设置yum源名称为development,这样才能配置选项需要安装的程序包。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>自动化</tag>
        <tag>系统安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSH端口转发]]></title>
    <url>%2F2017%2F09%2F13%2Flinux%2FSSH%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91%2F</url>
    <content type="text"><![CDATA[ssh是个多用途的工具，不仅可以远程登录，还可以搭建socks代理、进行内网穿透，这是利用它的端口转发功能来实现的。 概述 SSH除了可以实现密钥登录以外，还提供了一个非常实用的功能：端口转发。它能够将其他TCP端口的网络数据通过SSH链接来转发，并自动提供了加密和解密服务。这一过程我们称为隧道（tunneling）。如果平时工作环境中防火墙限制了某些端口的使用，但是允许SSH链接，就能通过将TCP端口转发来使用SSH通讯。 SSH端口转发提供了两大功能： 123突破防火墙的限制，建立隧道，实现一些原本无法建立的TCP连接加密SSH Client 和 SSH Server 之间的数据加密 分类 本地转发 ssh -L &lt;local port&gt;:&lt;remote host&gt;:&lt;remote port&gt; &lt;SSH hostname&gt;远程转发 ssh -R &lt;local port&gt;:&lt;remote host&gt;:&lt;remote port&gt; &lt;SSH hostname&gt;动态转发 ssh -D &lt;local port&gt; &lt;SSH Server&gt; 选项 -f 后台启用-N 不打开远程shell,处于等待状态,留在本机，不登录上代理服务器（默认会ssh上SSH Server）-g 启用网关功能 本地转发 ssh -L &lt;local port&gt;:&lt;remote host&gt;:&lt;remote port&gt; &lt;SSH hostname&gt;本地端口:目标主机:目标主机端口 SSH serverssh -L 9527:172.18.56.150:23 -Nf 172.18.251.20 用户访问不了内部服务器，但是其中有一台服务器可以让我们访问，我们可以将这台服务器看做代理服务器，这台代理服务器是可以和内部服务器连接。注意：非管理员账号是无权绑定1-1023端口的，所以一般选用1024-65535之间尚未使用的端口号。 这里9527是本地监听端口，在SSH Server上会随机监听一个端口，建议一个隧道。所有发送到本机9527端口的数据，都会通过这一条隧道走向SSH Server 并发送到远程remote主机port端口。 172.18.56.69 本地主机 本机监听9527开启了一个端口，和SSH Server建立隧道，使用了ssh 22端口 172.18.251.20 SSH Server SSH Server 开启了22端口和 本地主机 56.69建立隧道，在隧道建立后，用户telnet 上远程主机时，会开启一个随机端口和远程主机建立连接 172.18.56.150 远程主机 本地主机telnet上时，远程主机开启23端口和 SSH Server响应 总结： 本地端口转发，是在本地主机操作，和SSH Server建立隧道，两边必须都有SSH，SSH Server是一个中间代理作业，会临时开启两个随机端口，响应两边的请求。同时，本地主机转发是一个点对点，端口对端口的转发。 远程转发 ssh -R &lt;local port&gt;:&lt;remote host&gt;:&lt;remote port&gt; &lt;SSH hostname&gt;远程主机端口:目标主机:目标主机端口 远程主机ssh -L 9527:172.18.56.150:23 -Nf 172.18.56.69 用户访问不了所有服务器，但是SSH Server可以访问外网，连接到本地主机，同时可以和目录主机连接。此时，我们所在的位置就是SSH Server。 动态转发 ssh -D &lt;local port&gt; &lt;SSH Server&gt;本地端口:目标主机:目标主机端口ssh -f -N -D 1080 root@172.18.251.20 不管是本地转发，还是远程转发，都是点对点的转发，如翻墙工具，我们希望的是本机指定端口，可以访问所有外网，这是点对面的需求，动态转发就实现了这种效果。不管我们访问哪个目标主机任意端口，通通由远程代理主机处理。 后台进程处理 通过ssh建立的隧道，如果放在后台执行，要关闭这个隧道连接，只能Kill进程。 参考阮一峰 SSH原理与运用（二）：远程操作与端口转发IBM 实战SSH端口转发 备注: 时间紧张，此篇博客补全，稍后补上。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安全和加密（三）：CA]]></title>
    <url>%2F2017%2F09%2F08%2Flinux%2FCA%2F</url>
    <content type="text"><![CDATA[CA认证 搭建私有CAopenssl 配置文件：/etc/pki/tls/openssl.cnf 该配置文件中以 “[配置段]”,的形式配置相关信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566[ root@centos69 ~ ]# cat /etc/pki/tls/openssl.cnf ####################################################################[ ca ]default_ca = CA_default # The default ca section 默认CA配置段####################################################################[ CA_default ]dir = /etc/pki/CA # Where everything is kept CA工作目录certs = $dir/certs # Where the issued certs are kept 签发过的证书crl_dir = $dir/crl # Where the issued crl are kept 吊销列表database = $dir/index.txt # database index file. 数据库索引文件#unique_subject = no # Set to &apos;no&apos; to allow creation of # several ctificates with same subject.new_certs_dir = $dir/newcerts # default place for new certs. 新颁发的证书存放位置certificate = $dir/cacert.pem # The CA certificate CA自己的证书serial = $dir/serial # The current serial number CA证书序列号（颁发到第几个了）crlnumber = $dir/crlnumber # the current crl number 吊销证书序列号 # must be commented out to leave a V1 CRLcrl = $dir/crl.pem # The current CRL private_key = $dir/private/cakey.pem# The private key CA自己的私钥RANDFILE = $dir/private/.rand # private random number filex509_extensions = usr_cert # The extentions to add to the cert# Comment out the following two lines for the &quot;traditional&quot;# (and highly broken) format.name_opt = ca_default # Subject Name optionscert_opt = ca_default # Certificate field options# Extension copying option: use with caution.# copy_extensions = copy# Extensions to add to a CRL. Note: Netscape communicator chokes on V2 CRLs# so this is commented out by default to leave a V1 CRL.# crlnumber must also be commented out to leave a V1 CRL.# crl_extensions = crl_extdefault_days = 365 # how long to certify for 证书有限期default_crl_days= 30 # how long before next CRL 吊销列表的有限期限default_md = default # use public key default MDpreserve = no # keep passed DN ordering# A few difference way of specifying how similar the request should look# For type CA, the listed attributes must be the same, and the optional# and supplied fields are just that :-)policy = policy_match# For the CA policy[ policy_match ]countryName = matchstateOrProvinceName = matchorganizationName = matchorganizationalUnitName = optionalcommonName = suppliedemailAddress = optional# For the &apos;anything&apos; policy# At this point in time, you must list all acceptable &apos;object&apos;# types.[ policy_anything ]countryName = optionalstateOrProvinceName = optionallocalityName = optionalorganizationName = optionalorganizationalUnitName = optionalcommonName = suppliedemailAddress = optional#################################################################### 创建所需要的文件123456789101112131415161718192021[ root@centos69 ~ ]# cd /etc/pki/CA/[ root@centos69 CA ]# lltotal 16drwxr-xr-x. 2 root root 4096 Mar 23 05:46 certsdrwxr-xr-x. 2 root root 4096 Mar 23 05:46 crldrwxr-xr-x. 2 root root 4096 Mar 23 05:46 newcertsdrwx------. 2 root root 4096 Mar 23 05:46 private[ root@centos69 CA ]# touch index.txt # 生成证书索引数据库文件[ root@centos69 CA ]# [ root@centos69 CA ]# echo 01 &gt; serial # 指定第一个颁发证书的序列号[ root@centos69 CA ]# [ root@centos69 CA ]# lltotal 20drwxr-xr-x. 2 root root 4096 Mar 23 05:46 certsdrwxr-xr-x. 2 root root 4096 Mar 23 05:46 crl-rw-r--r--. 1 root root 0 Sep 1 14:26 index.txtdrwxr-xr-x. 2 root root 4096 Mar 23 05:46 newcertsdrwx------. 2 root root 4096 Mar 23 05:46 private-rw-r--r--. 1 root root 3 Sep 1 14:26 serial 生成私钥12345678[ root@centos69 CA ]# (umask 066; openssl genrsa -out private/cakey.pem 2048)Generating RSA private key, 2048 bit long modulus...................+++..................................................................................................+++e is 65537 (0x10001)[ root@centos69 CA ]# ll private/total 4-rw-------. 1 root root 1675 Sep 1 14:30 cakey.pem 生成自签名证书openssl req 用于生成证书请求，以让第三方权威机构CA来签发，生成我们需要的证书。 openssl req -new -x509 –key /etc/pki/CA/private/cakey.pem-days 7300 -out /etc/pki/CA/cacert.pem -new: 生成新证书签署请求 -X509: 专用于CA生成自签证书 -key: 生成请求时用到的私钥文件 -days n：证书的有效期限 -out /PATH/TO/SOMECERTFILE: 证书的保存路径 123456789101112131415[ root@centos69 CA ]# openssl req -new -x509 -key private/cakey.pem -days 3650 -out cacert.pem You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter &apos;.&apos;, the field will be left blank.-----Country Name (2 letter code) [XX]:CN # 国家State or Province Name (full name) []:hubei # 省名Locality Name (eg, city) [Default City]:wuhan # 城市Organization Name (eg, company) [Default Company Ltd]:tianyu # 公司Organizational Unit Name (eg, section) []:development # 部门Common Name (eg, your name or your server&apos;s hostname) []:ca.imkindu.com # 服务器名，要和自己的域名保持一次，这里是给自己颁的Email Address []:caadmin@imkindu.com # 邮箱 查看证书证书的文件名和配置文件相同 12345678910111213141516171819202122232425[ root@centos69 CA ]# cat cacert.pem -----BEGIN CERTIFICATE-----MIID9zCCAt+gAwIBAgIJAIWv3Pdkig3GMA0GCSqGSIb3DQEBBQUAMIGRMQswCQYDVQQGEwJDTjEOMAwGA1UECAwFaHViZWkxDjAMBgNVBAcMBXd1aGFuMQ8wDQYDVQQKDAZ0aWFueXUxFDASBgNVBAsMC2RldmVsb3BtZW50MRcwFQYDVQQDDA5jYS5pbWtpbmR1LmNvbTEiMCAGCSqGSIb3DQEJARYTY2FhZG1pbkBpbWtpbmR1LmNvbTAeFw0xNzA5MDEwNjQzNThaFw0yNzA4MzAwNjQzNThaMIGRMQswCQYDVQQGEwJDTjEOMAwGA1UECAwFaHViZWkxDjAMBgNVBAcMBXd1aGFuMQ8wDQYDVQQKDAZ0aWFueXUxFDASBgNVBAsMC2RldmVsb3BtZW50MRcwFQYDVQQDDA5jYS5pbWtpbmR1LmNvbTEiMCAGCSqGSIb3DQEJARYTY2FhZG1pbkBpbWtpbmR1LmNvbTCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBANnYPqqf0TykyCgUm6Y2HYdrtRmiDLd1UZPMCniF+S95Vr4E9RFCXZ89q9jZG1wIPK05EF4v56KSNUH3jTjWx021l99r3iXxvipUm3fnDlCAyVh6CZqDRy0uPEI87lxZPQ0lYk1O3g/IGRTZJDBD1RBhE1A4sz87jabgmVhAmeFmiwfSSIcOz1gXVotcfTJYv3FCK85XqbpkKVt9jlPd0KsOaXdzR5h7IxksQaVJ7YBZ/bSK8BnCN3oUF4MrzKghYB+nrqwlA+f3Im8pJQzh1YQM09asEuj/O9PxfywiWn/95kMnfn1CXtfw1BCrjj5bMjtBs9XJbO834OKAJ6vw//kCAwEAAaNQME4wHQYDVR0OBBYEFHYIkdBVCGVRzOHXk7XtOFYFto2ZMB8GA1UdIwQYMBaAFHYIkdBVCGVRzOHXk7XtOFYFto2ZMAwGA1UdEwQFMAMBAf8wDQYJKoZIhvcNAQEFBQADggEBAD1inoC2bRbzm2xJ/Ev8oNn4oXtoS6taabHx6juCKWbN42XtsBHEpsxyDTBq4nzn6cHO6yzdc81+HTYMzywGzpNrSOemS7hnlWVr0bSJZFgVgblakt4vLQO+PB8CDnUd6Atao+sjFRnT5yyFnyrXILOxyKxraYatwj0VhvAqx0uYqftxsHYA8sARwuzrqfKEdM7I/re7A/TGSRgWBuK9fanoQ7hcuRAt4dt2ukly8a3+3RGCxnkCU99/cnzS8nANdBTb0QxR6+VLAaALuOFolqw5T3Ks8kQQpCFk287X4cTgFEME278nIMtAUtFsFoBHfoC36EKTevQ4wjERSJrOiWU=-----END CERTIFICATE----- cer查看导出到windows，注意后缀是cer可以查看证书内容 申请CA创建密钥对1234567891011121314151617181920212223242526272829303132333435363738394041424344[ root@centos69 CA ]# (umask 066; openssl genrsa -out imkindu.prikey 2048)Generating RSA private key, 2048 bit long modulus..................+++......................................+++e is 65537 (0x10001)[ root@centos69 CA ]# lltotal 28-rw-r--r--. 1 root root 1436 Sep 1 14:43 cacert.pemdrwxr-xr-x. 2 root root 4096 Mar 23 05:46 certsdrwxr-xr-x. 2 root root 4096 Mar 23 05:46 crl-rw-------. 1 root root 1675 Sep 1 15:12 imkindu.prikey-rw-r--r--. 1 root root 0 Sep 1 14:26 index.txtdrwxr-xr-x. 2 root root 4096 Mar 23 05:46 newcertsdrwx------. 2 root root 4096 Sep 1 14:30 private-rw-r--r--. 1 root root 3 Sep 1 14:26 serial[ root@centos69 CA ]# cat imkindu.prikey-----BEGIN RSA PRIVATE KEY-----MIIEogIBAAKCAQEApwdAA2rKYkwmRbp3qOI/k1OdwrSVXARghdKuAId+LODMQ5lBmEZ8Ucw2n03vvZ4YAMgATdxA8n+xkgkCUMBqsjTnV4D+Ame3Wi0YcZmI71UW3pod75lpCUwkK5TD4UFvD5PchvfziWx0rh7doWOe0cD6/BaL+5BlGHebEF+8iemFS7Xj6tPNz9wuoYP5QkJ1wxnO6k6LyXWtHOk4bg4leFt/Oy7wSLLj4cM6frvYoV0r1t8stpvLSWnsCt9/PT2kzcqNq03pCDwuQTotoWX176Y9Vcd7sZl7RXLjGmQ6zRF0o5FxJq2GfRJIn5NkDN/kXwwe3WuiG7tgrwogV4qb5QIDAQABAoIBAAasGXiJeZA3roe2jTUn5JZEDtdKU3Ubj6eI5P6MaxPr3v0MUDx/BFRYLg5rFJqkiBzv4GM72zRUuYk15uvG4/w+dMdgFcWO0xo9Fu7izT+STJmT2oJJxJJkgkVjaffDn2Yl5/dUTFw/AuI5xWy/CAclCGGtnOXtvLwfewhKasOvieYPs2To9z/WtdbKwma9CsFTE0H+Mq+vqCokgyiVHf7CCpySxDp3OJqVCHErsBVq0BMrkr/9FnOCZY+Kd4Qcz2IlHDMER4f3+jS8pCJdjBOBf1qb9ENAFOCswsYe6g1fTItGGuxr9kmDBorTZSG5RdjCGArf/Eql9tswItPMkDkCgYEA1Y5WlCZywGVR6B8afyMQ5wjFWlluEfemFaiSXv66GHiXj5K02lnB2SV3bSyNR9taFZFK/+KBNVRPOQESbtHcmQoaSWmsb2nml7Tp/UDW+A8tn8yWw0kHAJK6eFUqGWKjJu8XuMv0H97BqV4So+rhde8CprB23bFeEjnKDoIn/ZsCgYEAyDmZDsdHBrAqrHMZX2DDgGpb1HxlM20PKorDdWRZeGD1rCBr7SJuGgJYafO1lMW6lJxyJ2U7ZfwP1qNR8qLjijRJwTZvvzeDVYyfHRzsPCkRqXSHE58aMRcVK7YAz9XcnNq+WHlXjAYIpblkl7x0NL3hGplMdrZqdUN6ixe+JH8CgYB9zMF3uEZ0y7q6MEhdiHyWfHY1SOUsNGRj8c93ojph2/f8HYHn9mPY1NdLOqlnIPIqLlKt9fIDRkz82YLQQVPf2zGs+VEYuJub1njYNO/tZJONxOky1LwJPGYYKKMKHS7a6pFgzNRcSc5vRPlaEi0KWeeH5f+/jJJLzjsW3NlN7QKBgFtfja3k21D+DDtuu2F/czijUQ0DR9vUJVuwv8pO5VW+Sd8nXJl3YO+VqmuPwIoIQkGXs7CuzhCYm1HEbp1gIJ7thcsa4JxO5SyhY+uRS22ZAGpot0wJC5bjhdHQ2UX/vxIF8V/G4GEST9fxZyqn4hA/pv7QfsieLq8dAEuBplBZAoGAdHnKQFlwSdy2oDCo9dWHiVWusHLBdZ218BU/hkfCzBMi/M1OrAWyeFU3/267deY+uKhEUJgUfrqQw5n+nmZyUOqzcYY1yMXMHbyiXhH1kEkwtPlEDAa7w9we+o59IxSMuUNtBTg5tl1oYLULoEwIj27RKVOn43UQvqPXfGKfXVw=-----END RSA PRIVATE KEY----- 创建申请证书与CA自己认证不同的是，没有-x509，表示申请 CSR是Certificate Signing Request的英文缩写，即证书请求文件 1234567891011121314151617181920[ root@centos69 CA ]# openssl req -new -key imkindu.prikey -days 365 -out imkindu.csrYou are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter &apos;.&apos;, the field will be left blank.-----Country Name (2 letter code) [XX]:CN 国家State or Province Name (full name) []:hubei 省份Locality Name (eg, city) [Default City]:wuhan 城市Organization Name (eg, company) [Default Company Ltd]:douyu 公司Organizational Unit Name (eg, section) []:hr 部门Common Name (eg, your name or your server&apos;s hostname) []:www.douyu.tv # 注意证书和网址域名Email Address []:douyu@email.comPlease enter the following &apos;extra&apos; attributesto be sent with your certificate requestA challenge password []: 加密证书请求（证书会在网上传输）An optional company name []: 请求发送给CA scp 到CA服务器 CA签证openssl ca 命令就是用于签证证书 openssl ca -in /file.csr -out /file -days 365 in 申请 out 签售之后证书存放位置 days 签证期限 crt是标准的证书后缀 签证时，需要确认证书信息，在openssl.cnf 中配置的有CA必须符合的标准，满足时才能签证 123456789101112131415161718192021222324252627282930313233[ root@centos69 CA ]# openssl ca -in imkindu.csr -out newcerts/imkindu.crt -days 365Using configuration from /etc/pki/tls/openssl.cnfCheck that the request matches the signatureSignature okCertificate Details: Serial Number: 1 (0x1) Validity Not Before: Sep 1 07:25:38 2017 GMT Not After : Sep 1 07:25:38 2018 GMT Subject: countryName = CN stateOrProvinceName = hubei organizationName = douyu organizationalUnitName = hr commonName = www.douyu.tv emailAddress = douyu@email.com X509v3 extensions: X509v3 Basic Constraints: CA:FALSE Netscape Comment: OpenSSL Generated Certificate X509v3 Subject Key Identifier: 98:BB:45:C4:12:7E:DE:75:29:70:DB:35:E1:19:2D:D5:3B:72:37:F2 X509v3 Authority Key Identifier: keyid:76:08:91:D0:55:08:65:51:CC:E1:D7:93:B5:ED:38:56:05:B6:8D:99Certificate is to be certified until Sep 1 07:25:38 2018 GMT (365 days)Sign the certificate? [y/n]:y1 out of 1 certificate requests certified, commit? [y/n]yWrite out database with 1 new entriesData Base Updated 数据库更新 12[ root@centos69 CA ]# cat index.txtV 180901072538Z 01 unknown /C=CN/ST=hubei/O=douyu/OU=hr/CN=www.douyu.tv/emailAddress=douyu@email.com 查看证书123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384[ root@centos69 CA ]# cat newcerts/imkindu.crt Certificate: Data: Version: 3 (0x2) Serial Number: 1 (0x1) Signature Algorithm: sha1WithRSAEncryption Issuer: C=CN, ST=hubei, L=wuhan, O=tianyu, OU=development, CN=ca.imkindu.com/emailAddress=caadmin@imkindu.com Validity Not Before: Sep 1 07:25:38 2017 GMT Not After : Sep 1 07:25:38 2018 GMT Subject: C=CN, ST=hubei, O=douyu, OU=hr, CN=www.douyu.tv/emailAddress=douyu@email.com Subject Public Key Info: Public Key Algorithm: rsaEncryption Public-Key: (2048 bit) Modulus: 00:a7:07:40:03:6a:ca:62:4c:26:45:ba:77:a8:e2: 3f:93:53:9d:c2:b4:95:5c:04:60:85:d2:ae:00:87: 7e:2c:e0:cc:43:99:41:98:46:7c:51:cc:36:9f:4d: ef:bd:9e:18:00:c8:00:4d:dc:40:f2:7f:b1:92:09: 02:50:c0:6a:b2:34:e7:57:80:fe:02:67:b7:5a:2d: 18:71:99:88:ef:55:16:de:9a:1d:ef:99:69:09:4c: 24:2b:94:c3:e1:41:6f:0f:93:dc:86:f7:f3:89:6c: 74:ae:1e:dd:a1:63:9e:d1:c0:fa:fc:16:8b:fb:90: 65:18:77:9b:10:5f:bc:89:e9:85:4b:b5:e3:ea:d3: cd:cf:dc:2e:a1:83:f9:42:42:75:c3:19:ce:ea:4e: 8b:c9:75:ad:1c:e9:38:6e:0e:25:78:5b:7f:3b:2e: f0:48:b2:e3:e1:c3:3a:7e:bb:d8:a1:5d:2b:d6:df: 2c:b6:9b:cb:49:69:ec:0a:df:7f:3d:3d:a4:cd:ca: 8d:ab:4d:e9:08:3c:2e:41:3a:2d:a1:65:f5:ef:a6: 3d:55:c7:7b:b1:99:7b:45:72:e3:1a:64:3a:cd:11: 74:a3:91:71:26:ad:86:7d:12:48:9f:93:64:0c:df: e4:5f:0c:1e:dd:6b:a2:1b:bb:60:af:0a:20:57:8a: 9b:e5 Exponent: 65537 (0x10001) X509v3 extensions: X509v3 Basic Constraints: CA:FALSE Netscape Comment: OpenSSL Generated Certificate X509v3 Subject Key Identifier: 98:BB:45:C4:12:7E:DE:75:29:70:DB:35:E1:19:2D:D5:3B:72:37:F2 X509v3 Authority Key Identifier: keyid:76:08:91:D0:55:08:65:51:CC:E1:D7:93:B5:ED:38:56:05:B6:8D:99 Signature Algorithm: sha1WithRSAEncryption 3f:58:52:d6:c5:39:d8:df:12:2f:d6:9a:81:71:4e:ca:2c:25: d5:04:fb:e8:f2:f7:20:92:7d:82:8a:6c:64:55:b9:4d:ff:05: ff:5c:f7:ea:3d:e9:de:d9:1b:54:54:ab:37:db:2f:e9:48:57: d0:47:d1:22:40:fc:e9:b8:dd:f9:b0:be:0c:f1:e1:72:b7:f1: fc:bd:5c:00:17:a1:be:fb:28:33:2a:f6:c3:0b:6b:a8:bd:a6: c2:ec:bf:7a:71:68:07:12:28:d2:69:a0:42:cf:21:c3:94:ef: b7:a9:51:67:a1:b0:27:ef:de:d6:72:1f:4a:67:92:dd:a9:f8: 27:27:60:62:5d:32:ef:5e:02:5e:49:7c:24:79:f5:14:5a:65: 3c:d3:df:8b:03:09:5a:fe:05:36:cc:2c:7e:b0:89:aa:78:8a: bc:9e:96:72:47:17:91:23:fc:54:9d:23:b6:1f:0f:8d:6d:55: a5:6f:81:6f:ec:fd:2d:cc:75:3c:7f:27:c0:3c:d7:fd:ef:fb: 38:34:ab:f4:74:df:8a:d4:bb:a3:ad:81:f8:54:95:57:60:94: bd:22:c6:a1:56:6b:c9:11:ba:00:96:44:62:98:1d:06:64:94: 7a:d3:46:83:bf:f6:3c:92:4d:60:7e:28:b2:c0:29:aa:07:0a: 2a:98:1d:2e-----BEGIN CERTIFICATE-----MIID+TCCAuGgAwIBAgIBATANBgkqhkiG9w0BAQUFADCBkTELMAkGA1UEBhMCQ04xDjAMBgNVBAgMBWh1YmVpMQ4wDAYDVQQHDAV3dWhhbjEPMA0GA1UECgwGdGlhbnl1MRQwEgYDVQQLDAtkZXZlbG9wbWVudDEXMBUGA1UEAwwOY2EuaW1raW5kdS5jb20xIjAgBgkqhkiG9w0BCQEWE2NhYWRtaW5AaW1raW5kdS5jb20wHhcNMTcwOTAxMDcyNTM4WhcNMTgwOTAxMDcyNTM4WjBxMQswCQYDVQQGEwJDTjEOMAwGA1UECAwFaHViZWkxDjAMBgNVBAoMBWRvdXl1MQswCQYDVQQLDAJocjEVMBMGA1UEAwwMd3d3LmRvdXl1LnR2MR4wHAYJKoZIhvcNAQkBFg9kb3V5dUBlbWFpbC5jb20wggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCnB0ADaspiTCZFuneo4j+TU53CtJVcBGCF0q4Ah34s4MxDmUGYRnxRzDafTe+9nhgAyABN3EDyf7GSCQJQwGqyNOdXgP4CZ7daLRhxmYjvVRbemh3vmWkJTCQrlMPhQW8Pk9yG9/OJbHSuHt2hY57RwPr8Fov7kGUYd5sQX7yJ6YVLtePq083P3C6hg/lCQnXDGc7qTovJda0c6ThuDiV4W387LvBIsuPhwzp+u9ihXSvW3yy2m8tJaewK3389PaTNyo2rTekIPC5BOi2hZfXvpj1Vx3uxmXtFcuMaZDrNEXSjkXEmrYZ9Ekifk2QM3+RfDB7da6Ibu2CvCiBXipvlAgMBAAGjezB5MAkGA1UdEwQCMAAwLAYJYIZIAYb4QgENBB8WHU9wZW5TU0wgR2VuZXJhdGVkIENlcnRpZmljYXRlMB0GA1UdDgQWBBSYu0XEEn7edSlw2zXhGS3VO3I38jAfBgNVHSMEGDAWgBR2CJHQVQhlUczh15O17ThWBbaNmTANBgkqhkiG9w0BAQUFAAOCAQEAP1hS1sU52N8SL9aagXFOyiwl1QT76PL3IJJ9gopsZFW5Tf8F/1z36j3p3tkbVFSrN9sv6UhX0EfRIkD86bjd+bC+DPHhcrfx/L1cABehvvsoMyr2wwtrqL2mwuy/enFoBxIo0mmgQs8hw5Tvt6lRZ6GwJ+/e1nIfSmeS3an4JydgYl0y714CXkl8JHn1FFplPNPfiwMJWv4FNswsfrCJqniKvJ6WckcXkSP8VJ0jth8PjW1VpW+Bb+z9Lcx1PH8nwDzX/e/7ODSr9HTfitS7o62B+FSVV2CUvSLGoVZryRG6AJZEYpgdBmSUetNGg7/2PJJNYH4ossApqgcKKpgdLg==-----END CERTIFICATE----- 证书吊销 1、获取要吊销证书的serial,客户端申请，服务端不能随便吊销 2、CA根据客户端提交的serial与subject信息，对比检验与index.txt文件信息是否一致 3、吊销证书在签售证书时，会在newcerts目录下生成对应序列号的pem文件openssl ca -revoke /etc/pki/CA/newcerts/SERIAL.pem 4、生成吊销证书编号(第一次申请一个序列号)echo 01 &gt; /etc/pki/CA/crlnumber 5、更新证书的吊销列表openssl ca -gencrl -out FILENAME.crl查看crl文件openssl crl -in /PATH/CRL_FILE.crl -noout -text]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>CA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sphinx.conf]]></title>
    <url>%2F2016%2F11%2F09%2Fmysql%2Fsphinx.conf%2F</url>
    <content type="text"><![CDATA[sphinx配置文件：sphinx.conf 术语source：数据源，数据是从什么地方来的。index：索引，当有数据源之后，从数据源处构建索引。索引实际上就是相当于一个字典检索。有了整本字典内容以后，才会有字典检索。searchd：提供搜索查询服务。它一般是以deamon的形式运行在后台的。indexer：构建索引的服务。当要重新构建索引的时候，就是调用indexer这个命令。attr：属性，属性是存在索引中的，它不进行全文索引，但是可以用于过滤和排序。 sphinx.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517## 数据源src1source src1&#123; ## 说明数据源的类型。数据源的类型可以是：mysql，pgsql，mssql，xmlpipe，odbc，python ## 有人会奇怪，python是一种语言怎么可以成为数据源呢？ ## python作为一种语言，可以操作任意其他的数据来源来获取数据，更多数据请看：（http://www.coreseek.cn/products-install/python/） type = mysql ## 下面是sql数据库特有的端口，用户名，密码，数据库名等。 sql_host = localhost sql_user = test sql_pass = sql_db = test sql_port = 3306 ## 如果是使用unix sock连接可以使用这个。 # sql_sock = /tmp/mysql.sock ## indexer和mysql之间的交互，需要考虑到效率和安全性。 ## 比如考虑到效率，他们两者之间的交互需要使用压缩协议；考虑到安全，他们两者之间的传输需要使用ssl ## 那么这个参数就代表这个意思，0/32/2048/32768 无/使用压缩协议/握手后切换到ssl/Mysql 4.1版本身份认证。 # mysql_connect_flags = 32 ## 当mysql_connect_flags设置为2048（ssl）的时候，下面几个就代表ssl连接所需要使用的几个参数。 # mysql_ssl_cert = /etc/ssl/client-cert.pem # mysql_ssl_key = /etc/ssl/client-key.pem # mysql_ssl_ca = /etc/ssl/cacert.pem ## mssql特有，是否使用windows登陆 # mssql_winauth = 1 ## mssql特有，是使用unicode还是单字节数据。 # mssql_unicode = 1 # request Unicode data from server ## odbc的dsn串 # odbc_dsn = DBQ=C:\data;DefaultDir=C:\data;Driver=&#123;Microsoft Text Driver (*.txt; *.csv)&#125;; ## sql某一列的缓冲大小，一般是针对字符串来说的。 ## 为什么要有这么一种缓冲呢？ ## 有的字符串，虽然长度很长，但是实际上并没有使用那么长的字符，所以在Sphinx并不会收录所有的字符，而是给每个属性一个缓存作为长度限制。 ## 默认情况下非字符类型的属性是1KB，字符类型的属性是1MB。 ## 而如果想要配置这个buffer的话，就可以在这里进行配置了。 # sql_column_buffers = content=12M, comments=1M ## indexer的sql执行前需要执行的操作。 # sql_query_pre = SET NAMES utf8 # sql_query_pre = SET SESSION query_cache_type=OFF ## indexer的sql执行语句 sql_query = \ SELECT id, group_id, UNIX_TIMESTAMP(date_added) AS date_added, title, content \ FROM documents ## 有的时候有多个表，我们想要查询的字段在其他表中。这个时候就需要对sql_query进行join操作。 ## 而这个join操作可能非常慢，导致建立索引的时候特别慢，那么这个时候，就可以考虑在sphinx端进行join操作了。 ## sql_joined_field是增加一个字段，这个字段是从其他表查询中查询出来的。 ## 这里封号后面的查询语句是有要求的，如果是query，则返回id和查询字段，如果是payload-query，则返回id，查询字段和权重。 ## 并且这里的后一个查询需要按照id进行升序排列。 # sql_joined_field = tags from query; SELECT docid, CONCAT('tag',tagid) FROM tags ORDER BY docid ASC # sql_joined_field = wtags from payload-query; SELECT docid, tag, tagweight FROM tags ORDER BY docid ASC ## 外部文件字段，意思就是一个表中，有一个字段存的是外部文件地址，但是实际的字段内容在文件中。比如这个字段叫做content_file_path。 ## 当indexer建立索引的时候，查到这个字段，就读取这个文件地址，然后加载，并进行分词和索引建立等操作。 # sql_file_field = content_file_path ## 当数据源数据太大的时候，一个sql语句查询下来往往很有可能锁表等操作。 ## 那么我么就可以使用多次查询，那么这个多次查询就需要有个范围和步长，sql_query_range和sql_range_step就是做这个使用的。 ## 获取最大和最小的id，然后根据步长来获取数据。比如下面的例子，如果有4500条数据，这个表建立索引的时候就会进行5次sql查询。 ## 而5次sql查询每次的间隔时间是使用sql_ranged_rhrottle来进行设置的。单位是毫秒。 # sql_query_range = SELECT MIN(id),MAX(id) FROM documents # sql_range_step = 1000 # sql_ranged_throttle = 0 ## 下面都是些不同属性的数据了 ## 先要了解属性的概念：属性是存在索引中的，它不进行全文索引，但是可以用于过滤和排序。 ## uint无符号整型属性 sql_attr_uint = group_id ## bool属性 # sql_attr_bool = is_deleted ## 长整型属性 # sql_attr_bigint = my_bigint_id ## 时间戳属性，经常被用于做排序 sql_attr_timestamp = date_added ## 字符串排序属性。一般我们按照字符串排序的话，我们会将这个字符串存下来进入到索引中，然后在查询的时候比较索引中得字符大小进行排序。 ## 但是这个时候索引就会很大，于是我们就想到了一个方法，我们在建立索引的时候，先将字符串值从数据库中取出，暂存，排序。 ## 然后给排序后的数组分配一个序号，然后在建立索引的时候，就将这个序号存入到索引中去。这样在查询的时候也就能完成字符串排序的操作。 ## 这，就是这个字段的意义。 # sql_attr_str2ordinal = author_name ## 浮点数属性，经常在查询地理经纬度的时候会用到。 # sql_attr_float = lat_radians # sql_attr_float = long_radians ## 多值属性（MVA） ## 试想一下，有一个文章系统，每篇文章都有多个标签，这个文章就叫做多值属性。 ## 我要对某个标签进行查询过滤，那么在建立查询的时候就应该把这个标签的值放入到索引中。 ## 这个字段，sql_attr_multi就是用来做这个事情的。 # sql_attr_multi = uint tag from query; SELECT docid, tagid FROM tags # sql_attr_multi = uint tag from ranged-query; \ # SELECT docid, tagid FROM tags WHERE id&gt;=$start AND id&lt;=$end; \ # SELECT MIN(docid), MAX(docid) FROM tags ## 字符串属性。 # sql_attr_string = stitle ## 文档词汇数记录属性。比如下面就是在索引建立的时候增加一个词汇数的字段 # sql_attr_str2wordcount = stitle ## 字符串字段，可全文搜索，可返回原始文本信息。 # sql_field_string = author ## 文档词汇数记录字段，可全文搜索，可返回原始信息 # sql_field_str2wordcount = title ## 取后查询，在sql_query执行后立即操作。 ## 它和sql_query_post_index的区别就是执行时间不同 ## sql_query_post是在sql_query执行后执行，而sql_query_post_index是在索引建立完成后才执行。 ## 所以如果要记录最后索引执行时间，那么应该在sql_query_post_index中执行。 # sql_query_post = ## 参考sql_query_post的说明。 # sql_query_post_index = REPLACE INTO counters ( id, val ) \ # VALUES ( 'max_indexed_id', $maxid ) ## 命令行获取信息查询。 ## 什么意思呢？ ## 我们进行索引一般只会返回主键id，而不会返回表中的所有字段。 ## 但是在调试的时候，我们一般需要返回表中的字段，那这个时候，就需要使用sql_query_info。 ## 同时这个字段只在控制台有效，在api中是无效的。 sql_query_info = SELECT * FROM documents WHERE id=$id ## 比如有两个索引，一个索引比较旧，一个索引比较新，那么旧索引中就会有数据是旧的。 ## 当我要对两个索引进行搜索的时候，哪些数据要按照新的索引来进行查询呢。 ## 这个时候就使用到了这个字段了。 ## 这里的例子（http://www.coreseek.cn/docs/coreseek_4.1-sphinx_2.0.1-beta.html#conf-sql-query-killlist）给的非常清晰了。 # sql_query_killlist = SELECT id FROM documents WHERE edited&gt;=@last_reindex ## 下面几个压缩解压的配置都是为了一个目的：让索引重建的时候不要影响数据库的性能表现。 ## SQL数据源解压字段设置 # unpack_zlib = zlib_column ## MySQL数据源解压字段设置 # unpack_mysqlcompress = compressed_column # unpack_mysqlcompress = compressed_column_2 ## MySQL数据源解压缓冲区设置 # unpack_mysqlcompress_maxsize = 16M ## xmlpipe的数据源就是一个xml文档 # type = xmlpipe ## 读取数据源的命令 # xmlpipe_command = cat /home/yejianfeng/instance/coreseek/var/test.xml ## 字段 # xmlpipe_field = subject # xmlpipe_field = content ## 属性 # xmlpipe_attr_timestamp = published # xmlpipe_attr_uint = author_id ## UTF-8修复设置 ## 只适用xmlpipe2数据源，数据源中有可能有非utf-8的字符，这个时候解析就有可能出现问题 ## 如果设置了这个字段，非utf-8序列就会全部被替换为空格。 # xmlpipe_fixup_utf8 = 1&#125;## sphinx的source是有继承这么一种属性的，意思就是除了父source之外，这个source还有这个特性source src1throttled : src1&#123; sql_ranged_throttle = 100&#125;## 索引test1index test1&#123; ## 索引类型，包括有plain，distributed和rt。分别是普通索引/分布式索引/增量索引。默认是plain。 # type = plain ## 索引数据源 source = src1 ## 索引文件存放路径 path = /home/yejianfeng/instance/coreseek/var/data/test1 ## 文档信息的存储模式，包括有none,extern,inline。默认是extern。 ## docinfo指的就是数据的所有属性（field）构成的一个集合。 ## 首先文档id是存储在一个文件中的（spa） ## 当使用inline的时候，文档的属性和文件的id都是存放在spa中的，所以进行查询过滤的时候，不需要进行额外操作。 ## 当使用extern的时候，文档的属性是存放在另外一个文件（spd）中的，但是当启动searchd的时候，会把这个文件加载到内存中。 ## extern就意味着每次做查询过滤的时候，除了查找文档id之外，还需要去内存中根据属性进行过滤。 ## 但是即使这样，extern由于文件大小小，效率也不低。所以不是有特殊要求，一般都是使用extern docinfo = extern ## 缓冲内存锁定。 ## searchd会讲spa和spi预读取到内存中。但是如果这部分内存数据长时间没有访问，则它会被交换到磁盘上。 ## 设置了mlock就不会出现这个问题，这部分数据会一直存放在内存中的。 mlock = 0 ## 词形处理器 ## 词形处理是什么意思呢？比如在英语中，dogs是dog的复数，所以dog是dogs的词干，这两个实际上是同一个词。 ## 所以英语的词形处理器会讲dogs当做dog来进行处理。 morphology = none ## 词形处理有的时候会有问题，比如将gps处理成gp，这个设置可以允许根据词的长度来决定是否要使用词形处理器。 # min_stemming_len = 1 ## 词形处理后是否还要检索原词？ # index_exact_words = 1 ## 停止词，停止词是不被索引的词。 # stopwords = /home/yejianfeng/instance/coreseek/var/data/stopwords.txt ## 自定义词形字典 # wordforms = /home/yejianfeng/instance/coreseek/var/data/wordforms.txt ## 词汇特殊处理。 ## 有的一些特殊词我们希望把它当成另外一个词来处理。比如，c++ =&gt; cplusplus来处理。 # exceptions = /home/yejianfeng/instance/coreseek/var/data/exceptions.txt ## 最小索引词长度，小于这个长度的词不会被索引。 min_word_len = 1 ## 字符集编码类型，可以为sbcs,utf-8。对于Coreseek，还可以有zh_cn.utf-8,zh_ch.gbk,zh_ch.big5 charset_type = sbcs ## 字符表和大小写转换规则。对于Coreseek，这个字段无效。 # 'sbcs' default value is # charset_table = 0..9, A..Z-&gt;a..z, _, a..z, U+A8-&gt;U+B8, U+B8, U+C0..U+DF-&gt;U+E0..U+FF, U+E0..U+FF # # 'utf-8' default value is # charset_table = 0..9, A..Z-&gt;a..z, _, a..z, U+410..U+42F-&gt;U+430..U+44F, U+430..U+44F ## 忽略字符表。在忽略字符表中的前后词会被连起来当做一个单独关键词处理。 # ignore_chars = U+00AD ## 是否启用通配符，默认为0，不启用 # enable_star = 1 ## min_prefix_len,min_infix_len,prefix_fields,infix_fields都是在enable_star开启的时候才有效果。 ## 最小前缀索引长度 ## 为什么要有这个配置项呢？ ## 首先这个是当启用通配符配置启用的前提下说的，前缀索引使得一个关键词产生了多个索引项，导致索引文件体积和搜索时间增加巨大。 ## 那么我们就有必要限制下前缀索引的前缀长度，比如example，当前缀索引长度设置为5的时候，它只会分解为exampl，example了。 # min_prefix_len = 0 ## 最小索引中缀长度。理解同上。 # min_infix_len = 0 ## 前缀索引和中缀索引字段列表。并不是所有的字段都需要进行前缀和中缀索引。 # prefix_fields = filename # infix_fields = url, domain ## 词汇展开 ## 是否尽可能展开关键字的精确格式或者型号形式 # expand_keywords = 1 ## N-Gram索引的分词技术 ## N-Gram是指不按照词典，而是按照字长来分词，这个主要是针对非英文体系的一些语言来做的（中文、韩文、日文） ## 对coreseek来说，这两个配置项可以忽略。 # ngram_len = 1 # ngram_chars = U+3000..U+2FA1F ## 词组边界符列表和步长 ## 哪些字符被看做分隔不同词组的边界。 # phrase_boundary = ., ?, !, U+2026 # horizontal ellipsis # phrase_boundary_step = 100 ## 混合字符列表 # blend_chars = +, &amp;, U+23 # blend_mode = trim_tail, skip_pure ## html标记清理，是否从输出全文数据中去除HTML标记。 html_strip = 0 ## HTML标记属性索引设置。 # html_index_attrs = img=alt,title; a=title; ## 需要清理的html元素 # html_remove_elements = style, script ## searchd是预先打开全部索引还是每次查询再打开索引。 # preopen = 1 ## 字典文件是保持在磁盘上还是将他预先缓冲在内存中。 # ondisk_dict = 1 ## 由于在索引建立的时候，需要建立临时文件和和副本，还有旧的索引 ## 这个时候磁盘使用量会暴增，于是有个方法是临时文件重复利用 ## 这个配置会极大减少建立索引时候的磁盘压力，代价是索引建立速度变慢。 # inplace_enable = 1 # inplace_hit_gap = 0 # preallocated hitlist gap size # inplace_docinfo_gap = 0 # preallocated docinfo gap size # inplace_reloc_factor = 0.1 # relocation buffer size within arena # inplace_write_factor = 0.1 # write buffer size within arena ## 在经过过短的位置后增加位置值 # overshort_step = 1 ## 在经过 停用词 处后增加位置值 # stopword_step = 1 ## 位置忽略词汇列表 # hitless_words = all # hitless_words = hitless.txt ## 是否检测并索引句子和段落边界 # index_sp = 1 ## 字段内需要索引的HTML/XML区域的标签列表 # index_zones = title, h*, th&#125;index test1stemmed : test1&#123; path = /home/yejianfeng/instance/coreseek/var/data/test1stemmed morphology = stem_en&#125;index dist1&#123; type = distributed local = test1 local = test1stemmed ## 分布式索引（distributed index）中的远程代理和索引声明 agent = localhost:9313:remote1 agent = localhost:9314:remote2,remote3 # agent = /var/run/searchd.sock:remote4 ## 分布式索引（ distributed index）中声明远程黑洞代理 # agent_blackhole = testbox:9312:testindex1,testindex2 ## 远程代理的连接超时时间 agent_connect_timeout = 1000 ## 远程查询超时时间 agent_query_timeout = 3000&#125;index rt&#123; type = rt path = /home/yejianfeng/instance/coreseek/var/data/rt ## RT索引内存限制 # rt_mem_limit = 512M ## 全文字段定义 rt_field = title rt_field = content ## 无符号整数属性定义 rt_attr_uint = gid ## 各种属性定义 # rt_attr_bigint = guid # rt_attr_float = gpa # rt_attr_timestamp = ts_added # rt_attr_string = author&#125;indexer&#123; ## 建立索引的时候，索引内存限制 mem_limit = 32M ## 每秒最大I/O操作次数，用于限制I/O操作 # max_iops = 40 ## 最大允许的I/O操作大小，以字节为单位，用于I/O节流 # max_iosize = 1048576 ## 对于XMLLpipe2数据源允许的最大的字段大小，以字节为单位 # max_xmlpipe2_field = 4M ## 写缓冲区的大小，单位是字节 # write_buffer = 1M ## 文件字段可用的最大缓冲区大小，字节为单位 # max_file_field_buffer = 32M&#125;## 搜索服务配置searchd&#123; # listen = 127.0.0.1 # listen = 192.168.0.1:9312 # listen = 9312 # listen = /var/run/searchd.sock ## 监听端口 listen = 9312 listen = 9306:mysql41 ## 监听日志 log = /home/yejianfeng/instance/coreseek/var/log/searchd.log ## 查询日志 query_log = /home/yejianfeng/instance/coreseek/var/log/query.log ## 客户端读超时时间 read_timeout = 5 ## 客户端持久连接超时时间，即客户端读一次以后，持久连接，然后再读一次。中间这个持久连接的时间。 client_timeout = 300 ## 并行执行搜索的数目 max_children = 30 ## 进程id文件 pid_file = /home/yejianfeng/instance/coreseek/var/log/searchd.pid ## 守护进程在内存中为每个索引所保持并返回给客户端的匹配数目的最大值 max_matches = 1000 ## 无缝轮转。防止 searchd 轮换在需要预取大量数据的索引时停止响应 ## 当进行索引轮换的时候，可能需要消耗大量的时间在轮换索引上。 ## 但是启动了无缝轮转，就以消耗内存为代价减少轮转的时间 seamless_rotate = 1 ## 索引预开启，是否强制重新打开所有索引文件 preopen_indexes = 1 ## 索引轮换成功之后，是否删除以.old为扩展名的索引拷贝 unlink_old = 1 ## 属性刷新周期 ## 就是使用UpdateAttributes()更新的文档属性每隔多少时间写回到磁盘中。 # attr_flush_period = 900 ## 索引字典存储方式 # ondisk_dict_default = 1 ## 用于多值属性MVA更新的存储空间的内存共享池大小 mva_updates_pool = 1M ## 网络通讯时允许的最大的包的大小 max_packet_size = 8M ## 崩溃日志文件 # crash_log_path = /home/yejianfeng/instance/coreseek/var/log/crash ## 每次查询允许设置的过滤器的最大个数 max_filters = 256 ## 单个过滤器允许的值的最大个数 max_filter_values = 4096 ## TCP监听待处理队列长度 # listen_backlog = 5 ## 每个关键字的读缓冲区的大小 # read_buffer = 256K ## 无匹配时读操作的大小 # read_unhinted = 32K ## 每次批量查询的查询数限制 max_batch_queries = 32 ## 每个查询的公共子树文档缓存大小 # subtree_docs_cache = 4M ## 每个查询的公共子树命中缓存大小 # subtree_hits_cache = 8M ## 多处理模式（MPM）。 可选项；可用值为none、fork、prefork，以及threads。 默认在Unix类系统为form，Windows系统为threads。 workers = threads # for RT to work ## 并发查询线程数 # dist_threads = 4 ## 二进制日志路径 # binlog_path = # disable logging # binlog_path = /home/yejianfeng/instance/coreseek/var/data # binlog.001 etc will be created there ## 二进制日志刷新 # binlog_flush = 2 ## 二进制日志大小限制 # binlog_max_log_size = 256M ## 线程堆栈 # thread_stack = 128K ## 关键字展开限制 # expansion_limit = 1000 ## RT索引刷新周期 # rt_flush_period = 900 ## 查询日志格式 ## 可选项，可用值为plain、sphinxql，默认为plain。 # query_log_format = sphinxql ## MySQL版本设置 # mysql_version_string = 5.0.37 ## 插件目录 # plugin_dir = /usr/local/sphinx/lib ## 服务端默认字符集 # collation_server = utf8_general_ci ## 服务端libc字符集 # collation_libc_locale = ru_RU.UTF-8 ## 线程服务看守 # watchdog = 1 ## 兼容模式 # compat_sphinxql_magics = 1&#125;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>sphinx.conf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sphinx]]></title>
    <url>%2F2016%2F11%2F09%2Fmysql%2Fsphinx%2F</url>
    <content type="text"><![CDATA[Sphinx是一个基于SQL的全文检索引擎，可以结合MySQL,PostgreSQL做全文搜索，它可以提供比数据库本身更专业的搜索功能，使得应用程序更容易实现专业化的全文检索。Sphinx特别为一些脚本语言设计搜索API接口，如PHP,Python,Perl,Ruby等，同时为MySQL也设计了一个存储引擎插件。 全文索引两过程索引建立（Indexing） 索引建立：将现实世界中所有的结构化和非结构化数据提取信息，创建索引的过程。 搜索索引（Search） 搜索索引：得到用户的查询请求，搜索创建的索引，然后返回结果的过程。 三个问题：1、索引里面究竟存些什么？（Index）2、如何创建索引？（Indexing） 一些需要创建索引的文档（Documents） 将原文档传给分词组件（Tokenizer） 将得到的词元（Token）传给语言处理组件（Linguistic Processor） 将得到的词（Team）传给索引组件（Indexer） 文档频率：Document Frequency 表示总共有多少文件包含此词（Term） 词频率：Frequency 此文件包含了几个此词（Term） 3、如何对索引进行搜索？（Search） 1、用户输入查询语句 2、对查询语句进行词法分析、语法分析、语言处理 3、搜索索引，得到符号语法树的文档 4、根据得到的文档和查询语句的相关性，对结果进行排序 安装sphinx 官网下载sphinx安装包 http://sphinxsearch.com/ Sphinx在mysql上的应用有两种方式： 1.采用API调用，如使用PHP、java等的API函数或方法查询。优点是可不必对mysql重新编译，服务端进程“低耦合”，且程序可灵活、方便的调用；缺点是如已有搜索程序的条件下，需修改部分程序。推荐程序员使用。 2.使用插件方式（sphinxSE）把sphinx编译成一个mysql插件并使用特定的sql语句进行检索。其特点是，在sql端方便组合，且能直接返回数据给客户端。不必二次查询,在程序上仅需要修改对应的sql，但这对使用框架开发的程序很不方便，比如使用了ORM。另外还需要对mysql进行重新编译，且需要mysql-5.1以上版本支持插件存储。 这里的安装主要介绍的是第一种通过api调用的方式。Sphinx的安装如下： 12345678#下载最新稳定版wget http://www.sphinxsearch.com/downloads/sphinx-0.9.9.tar.gztar xzvf sphinx-0.9.9.tar.gzcd sphinx-0.9.9./configure --prefix=/usr/local/sphinx/ --with-mysql --enable-id64makemake install注意：采用这种方式安装不支持中文分词。 bin indexer search searchd 服务 etc 配置文件 var 形成的索引表 配置主数据源 source main { type = mysql sql_host = localhost sql_user = test sql_pass = sql_db = test sql_port = 3306 # optional, default is 3306 sql_query = \ # 获取数据的sql语句 SELECT id, group_id, UNIX_TIMESTAMP(date_added) AS date_added, title, content FROM documents sql_query_info = select * from post where id=$id } 增量数据源 source delta:main{ } 主数据索引 index main{ } 增量数据索引 index delta:main{ } 分布式索引 index dist1{ } 索引器 indexer{ } 服务进程 searchd { } 创建索引indexer -c 指定配置文件 -all 对所有索引重新编制索引 php-sphinx扩展 编译安装php sphinx扩展包 libsphinxclient php模块需要 1234# 在sphinx安装包中，包含的有libsphinxclientcd sphinx-2.2.3/api/libsphinxclient ./configure --prefix=/usr/local/sphinx make &amp;&amp; make install PHP Sphinx 扩展模块12345678#如果没有扩展安装包，先下载 wget http://pecl.php.net/get/sphinx-1.3.2.tgz tar zxvf sphinx-1.3.2.tgz cd sphinx-1.3.2 phpize ./configure --with-php-config=/usr/local/php/bin/php-config --with-sphinx=/usr/local/sphinx make make install 修改php.ini12[sphinx] extension=sphinx.so sphinxapi.php php-sphinx还提供了一种API方式的查询方法，在sphinx安装包文件中/api目录下，有一个sphinxapi.php文件，在使用php代码查询时，只需要引入这个文件即可。 Sphinx中文分词 中文的全文检索和英文等latin系列不一样，后者是根据空格等特殊字符来断词，而中文是根据语义来分词。中文分词主要有2个插件 1.Coreseek Coreseek是现在用的最多的sphinx中文全文检索，它提供了为Sphinx设计的中文分词包LibMMSeg ，是基于sphinx的基础上开发的。 2.sfc(Sphinx-for-chinese) sfc（sphinx-for-chinese）是由网友happy兄提供的另外一个中文分词插件。其中文词典采用的是xdict。 coreseek Coreseek发布了3.2.14版本和4.1版本，其中的3.2.14版本是2010年发布的，它是基于Sphinx0.9.9搜索引擎的。而4.1版本是2011年发布的，它是基于Sphinx2.0.2的。Sphinx从0.9.9到2.0.2还是有改变了很多的，有很多功能，比如sql_attr_string等是在0.9.9上面不能使用的。所以在安装之前请判断清楚你需要安装的是哪个版本，在google问题的时候也要弄清楚这个问题的问题和答案是针对哪个版本的。我个人强烈建议使用4.1版本。 oreseek里有2个文件夹 一个是mmseg中文分词包 还有一个是csft(其实就是sphinx)包 都要安装 安装mmseg中文分词1./configure --prefix=/usr/local/mmseg 编译时可能会报错config.status: error: cannot find input file: src/Makefile.in 通过automake来解决首先检查是否安装了libtool如果没有yum -y install libtoolautomake如果automake报错 原因可能是下列 12345Libtool library used but `LIBTOOL' is undefinedThe usual way to define `LIBTOOL' is to add `AC_PROG_LIBTOOL'to `configure.ac' and run `aclocal' and `autoconf' again.If `AC_PROG_LIBTOOL' is in `configure.ac', make sureits definition is in aclocal's search path. 如果以上步骤都没成功，那么试下以下办法（把下面的命令都执行一遍，就好了） 123456aclocallibtoolize --forceautomake --add-missingautoconfautoheadermake clean 编译安装csft-4.1123456./buildconf.sh ./configure --prefix=/usr/local/coreseek --with-mysql-includes=/usr/includes/mysql --with-mysql-libs=/usr/lib64/mysql/ --with-mmseg=/usr/local/mmseg --with-mmseg-includes=/usr/local/mmseg/include/mmseg/ --with-mmseg-libs=/usr/local/mmseg/lib/ yum安装的mysql的include和libs文件夹一般是安装在/usr/include/mysql和/usr/lib64/mysql下面 所以这里的–with-mysql可以使用–with-mysql-includes和–with-mysql-libs来进行替换。 在buildconf.sh 时报错，以下网站有提示 http://blog.csdn.net/jcjc918/article/details/39032689 实时索引http://www.wuzexin.cn/post-58.html]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>sphinx</tag>
      </tags>
  </entry>
</search>
